{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a95a1eec",
   "metadata": {
    "id": "a95a1eec"
   },
   "source": [
    "# ðŸŽ“ FrugalGPT Experiment on OVERRULING: Performance and Cost Tradeoffs\n",
    "\n",
    "This notebook illustrates the FrugalGPT framework for _building LLM Applications with budget constraints._\n",
    "\n",
    "In particular, we will focus on evaluating the performance and cost tradeoffs enabled by FrugalGPT.\n",
    "\n",
    "NB: You are highly suggested to use accelerated hardware (GPU/TPU) to run this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea3b2c7",
   "metadata": {
    "id": "cea3b2c7"
   },
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2777650",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1726726500022,
     "user": {
      "displayName": "Lingjiao Chen",
      "userId": "02137656603654057828"
     },
     "user_tz": 420
    },
    "id": "b2777650"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys, json, copy\n",
    "import pandas as pd\n",
    "import logging\n",
    "logging.disable(logging.CRITICAL)\n",
    "sys.path.append(\"src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebe0919d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'FrugalGPT' from '/home/feiy/My_FrugalGPT/src/FrugalGPT/__init__.py'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(FrugalGPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef14cb0",
   "metadata": {
    "id": "3ef14cb0"
   },
   "source": [
    "## Setup\n",
    "Next, let us set up the environment and API keys. You do _not_ need API keys to run the notebook! They are only needed if you want to use FrugalGPT for your own queries.\n",
    "\n",
    "NB: For your own queries, not all API keys are needed, too. If you only want to leverage LLMs from, e.g., OpenAI and AI21, setting up API keys for them is sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2855163",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "executionInfo": {
     "elapsed": 18501,
     "status": "ok",
     "timestamp": 1726726518520,
     "user": {
      "displayName": "Lingjiao Chen",
      "userId": "02137656603654057828"
     },
     "user_tz": 420
    },
    "id": "c2855163",
    "outputId": "5dded56f-73b9-43bf-bc4b-2ff70f27788a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supported LLMs: ['google/gemini-1.5-flash-002', 'google/gemini-1.5-pro-002', 'google/gemini-1.0-pro', 'openaichat/gpt-4o-mini', 'openaichat/gpt-4o', 'azure/Phi-3-mini-4k-instruct', 'azure/Phi-3.5-mini-instruct', 'azure/Phi-3-small-8k-instruct', 'azure/Phi-3-medium-4k-instruct', 'deepinfra/llama-3-8B', 'deepinfra/llama-3-70B', 'deepinfra/mixtral-8x7B']\n",
      "supported_LLM_names: ['gemini-1.5-flash-002', 'gemini-1.5-pro-002', 'gemini-1.0-pro', 'gpt-4o-mini', 'gpt-4o', 'Phi-3-mini-4k-instruct', 'Phi-3.5-mini-instruct', 'Phi-3-small-8k-instruct', 'Phi-3-medium-4k-instruct', 'llama-3-8B', 'llama-3-70B', 'mixtral-8x7B']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from IPython.display import display\n",
    "import FrugalGPT\n",
    "import numpy\n",
    "from tqdm import tqdm\n",
    "\n",
    "supported_LLM = FrugalGPT.getservicename()\n",
    "print(\"supported LLMs:\",supported_LLM)\n",
    "supported_LLM_names = [llm.split(\"/\")[1] for llm in supported_LLM]\n",
    "print(\"supported_LLM_names:\", supported_LLM_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_mVREVjUkOeo",
   "metadata": {
    "id": "_mVREVjUkOeo"
   },
   "source": [
    "## Generating the tradeoffs involves three major steps: (i) prepare the dataset, (ii) train the FrugalGPT strategy, and (iii) evaluate and save the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LV_z9eaWknSN",
   "metadata": {
    "id": "LV_z9eaWknSN"
   },
   "source": [
    "## Step 1: Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "zFHCG0j94qAD",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1726726518520,
     "user": {
      "displayName": "Lingjiao Chen",
      "userId": "02137656603654057828"
     },
     "user_tz": 420
    },
    "id": "zFHCG0j94qAD"
   },
   "outputs": [],
   "source": [
    "# dataname = \"HEADLINES\"\n",
    "dataname = \"OVERRULING\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dad6a7f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_raw</th>\n",
       "      <th>query</th>\n",
       "      <th>ref_answer</th>\n",
       "      <th>gpt-4o-mini</th>\n",
       "      <th>gpt-4o</th>\n",
       "      <th>llama-3-8B</th>\n",
       "      <th>llama-3-70B</th>\n",
       "      <th>mixtral-8x7B</th>\n",
       "      <th>gemini-1.5-flash-002</th>\n",
       "      <th>gemini-1.0-pro</th>\n",
       "      <th>gemini-1.5-pro-002</th>\n",
       "      <th>Phi-3.5-mini-instruct</th>\n",
       "      <th>Phi-3-small-8k-instruct</th>\n",
       "      <th>Phi-3-mini-4k-instruct</th>\n",
       "      <th>Phi-3-medium-4k-instruct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Context: to the extent that these cases are in...</td>\n",
       "      <td>Please determine whether a sentence is overrul...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Context: we therefore reverse the order denyin...</td>\n",
       "      <td>Please determine whether a sentence is overrul...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Context: see brown v. state,\\nQuestion: Is it ...</td>\n",
       "      <td>Please determine whether a sentence is overrul...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Context: at the very least, this court ought t...</td>\n",
       "      <td>Please determine whether a sentence is overrul...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Context: the federal immigration judge and the...</td>\n",
       "      <td>Please determine whether a sentence is overrul...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           query_raw  \\\n",
       "0  Context: to the extent that these cases are in...   \n",
       "1  Context: we therefore reverse the order denyin...   \n",
       "2  Context: see brown v. state,\\nQuestion: Is it ...   \n",
       "3  Context: at the very least, this court ought t...   \n",
       "4  Context: the federal immigration judge and the...   \n",
       "\n",
       "                                               query ref_answer gpt-4o-mini  \\\n",
       "0  Please determine whether a sentence is overrul...        yes         yes   \n",
       "1  Please determine whether a sentence is overrul...        yes         yes   \n",
       "2  Please determine whether a sentence is overrul...         no          no   \n",
       "3  Please determine whether a sentence is overrul...         no          no   \n",
       "4  Please determine whether a sentence is overrul...        yes          no   \n",
       "\n",
       "  gpt-4o llama-3-8B llama-3-70B mixtral-8x7B gemini-1.5-flash-002  \\\n",
       "0    yes        yes         yes          yes                  yes   \n",
       "1    yes        yes         yes          yes                  yes   \n",
       "2     no         no          no           no                   no   \n",
       "3     no         no          no           no                   no   \n",
       "4     no        yes          no           no                  yes   \n",
       "\n",
       "  gemini-1.0-pro gemini-1.5-pro-002 Phi-3.5-mini-instruct  \\\n",
       "0            yes                yes                   yes   \n",
       "1            yes                yes                   yes   \n",
       "2             no                 no                    no   \n",
       "3             no                 no                   yes   \n",
       "4             no                 no                   yes   \n",
       "\n",
       "  Phi-3-small-8k-instruct Phi-3-mini-4k-instruct Phi-3-medium-4k-instruct  \n",
       "0                     yes                    yes                      yes  \n",
       "1                     yes                    yes                      yes  \n",
       "2                      no                     no                       no  \n",
       "3                      no                     no                       no  \n",
       "4                      no                    yes                      yes  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read from data/{dataname}/Queried_{dataname}_all_models_clean_train.csv and data/{dataname}/Queried_{dataname}_all_models_clean_test.csv\n",
    "dataset_df = pd.read_csv(f'data/{dataname}/Queried_{dataname}_all_models_clean_train.csv', header=0)\n",
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "388c390b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for index, row in dataset_df.iterrows():\n",
    "    query = row['query']\n",
    "    ref_answer = row['ref_answer']\n",
    "    _id = index\n",
    "    model_answer = {}\n",
    "    for model_name in supported_LLM_names:\n",
    "        model_answer[model_name] = row[model_name]\n",
    "    train_data.append([query, ref_answer, _id, model_answer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c10f95bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Please determine whether a sentence is overruling a prior decision (Yes or No) in the following statements.\\n\\nContext: because jones/walker relates only to sufficiency of the evidence, we hereby disavow the language holding otherwise in sandoval.\\nQuestion: Is it overruling?\\nAnswer: Yes\\n\\nContext: according to napa auto parts, the straws drove the vehicle \"\"\"\"for approximately six [] weeks and [] for between 500 to 600 miles prior to the accident with no incidents.\"\"\"\"\\nQuestion: Is it overruling?\\nAnswer: No\\n\\nContext: at the very least, this court ought to address the problem created by kar because, as this case illustrates, kar is distorting the burden of proof in this important area of the law.\\nQuestion: Is it overruling?\\nAnswer:',\n",
       " 'no',\n",
       " 3,\n",
       " {'gemini-1.5-flash-002': 'no',\n",
       "  'gemini-1.5-pro-002': 'no',\n",
       "  'gemini-1.0-pro': 'no',\n",
       "  'gpt-4o-mini': 'no',\n",
       "  'gpt-4o': 'no',\n",
       "  'Phi-3-mini-4k-instruct': 'no',\n",
       "  'Phi-3.5-mini-instruct': 'yes',\n",
       "  'Phi-3-small-8k-instruct': 'no',\n",
       "  'Phi-3-medium-4k-instruct': 'no',\n",
       "  'llama-3-8B': 'no',\n",
       "  'llama-3-70B': 'no',\n",
       "  'mixtral-8x7B': 'no'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07661cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the answer of the model llama-3-8B\n",
    "train_data[3][3]['llama-3-8B']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MRmg8bV6ljKa",
   "metadata": {
    "id": "MRmg8bV6ljKa"
   },
   "source": [
    "## Step 2: Train the FrugalGPT strategy for different budgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e25bbfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_names = ['openaichat/gpt-4o-mini',\n",
    "                'openaichat/gpt-4o',\n",
    "                'google/gemini-1.5-flash-002',\n",
    "                'google/gemini-1.5-pro-002',\n",
    "                'google/gemini-1.0-pro',\n",
    "                'azure/Phi-3-mini-4k-instruct',\n",
    "                'azure/Phi-3.5-mini-instruct',\n",
    "                'azure/Phi-3-small-8k-instruct',\n",
    "                'azure/Phi-3-medium-4k-instruct',\n",
    "                'deepinfra/llama-3-8B',\n",
    "                'deepinfra/llama-3-70B',\n",
    "                'deepinfra/mixtral-8x7B',\n",
    "                ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Mwk3Z34Umyot",
   "metadata": {
    "id": "Mwk3Z34Umyot"
   },
   "source": [
    "### 2-1. Now let us train FrugalGPT on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7d88254",
   "metadata": {},
   "outputs": [],
   "source": [
    "genparams=FrugalGPT.GenerationParameter(max_tokens=50, temperature=0.1, stop=['\\n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6NFj3Il6m2KP",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1726726612367,
     "user": {
      "displayName": "Lingjiao Chen",
      "userId": "02137656603654057828"
     },
     "user_tz": 420
    },
    "id": "6NFj3Il6m2KP"
   },
   "outputs": [],
   "source": [
    "def compute_tradeoffs(\n",
    "    train_data,\n",
    "    budget_list,\n",
    "    name = \"HEADLINES\", # test\n",
    "    service_names = ['openaichat/gpt-4o-mini',\n",
    "                      'openaichat/gpt-4o',\n",
    "                      'openaichat/gpt-4-turbo',\n",
    "                      'togetherai/meta-llama/Meta-Llama-3-70B-Instruct-Turbo',\n",
    "                      'togetherai/google/gemma-2-9b-it',\n",
    "                    ],\n",
    "    prefix=\"\",\n",
    "    skip=0,\n",
    "    MyCascade = FrugalGPT.LLMCascade(\n",
    "          score_noise_injection=False,\n",
    "          db_path=\"db/SCIQ.sqlite\",\n",
    "          ),\n",
    "    cascade_depth=3,\n",
    "    ):\n",
    "\n",
    "  for idx,budget in tqdm(enumerate(budget_list)):\n",
    "    # train the model\n",
    "    user_budget = budget\n",
    "    # MyCascade.load(loadpath=f\"strategy/{name}/\",budget=user_budget)\n",
    "\n",
    "    try:\n",
    "      MyCascade.load(loadpath=f\"strategy/{name}/\",budget=user_budget)\n",
    "      print(\"Already trained. Skipped.\")\n",
    "      continue\n",
    "    except:\n",
    "      print(\"cannot find, start new training\")\n",
    "    if(idx<skip):\n",
    "      continue\n",
    "    if(idx==0):\n",
    "        result = MyCascade.train(train_data,budget=user_budget,\n",
    "                                 service_names=service_names,\n",
    "                                 no_scorer_train=False,\n",
    "                                 prefix=prefix,\n",
    "                                 cascade_depth=cascade_depth,\n",
    "                                 )\n",
    "    else:\n",
    "      result = MyCascade.train(train_data,budget=user_budget,\n",
    "                               service_names=service_names,\n",
    "                               no_scorer_train=True,\n",
    "                               prefix=prefix,\n",
    "                               cascade_depth=cascade_depth,\n",
    "                               )\n",
    "    MyCascade.save(savepath=f\"strategy/{name}/\")\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "sMNX98QknqM8",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1726726612367,
     "user": {
      "displayName": "Lingjiao Chen",
      "userId": "02137656603654057828"
     },
     "user_tz": 420
    },
    "id": "sMNX98QknqM8"
   },
   "outputs": [],
   "source": [
    "# start_budget = 5e-05 # 0.0035 \n",
    "# end_budget = 0.0001\n",
    "# num_eval = 2\n",
    "# budget_list = numpy.linspace(start_budget, end_budget, num_eval)\n",
    "\n",
    "name = f'{dataname}_1125'\n",
    "budget_list = [0.00001, 0.00005, 0.0001, 0.0005, 0.001] # , 0.0015\n",
    "\n",
    "MyCascade= FrugalGPT.LLMCascade(\n",
    "          score_noise_injection=False,\n",
    "  db_path=f\"db/{dataname}.sqlite\",\n",
    "  batch_build=True,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "798268ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728\n"
     ]
    }
   ],
   "source": [
    "train_data_sample = train_data[0:] # [0:100]\n",
    "print(len(train_data_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6MCKdsao1Sa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "executionInfo": {
     "elapsed": 89592,
     "status": "ok",
     "timestamp": 1726726973432,
     "user": {
      "displayName": "Lingjiao Chen",
      "userId": "02137656603654057828"
     },
     "user_tz": 420
    },
    "id": "c6MCKdsao1Sa",
    "outputId": "976710f4-e287-4d6f-aae6-ff1e2332ce7e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot find, start new training\n",
      "train and test size 1382 346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='312' max='312' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [312/312 00:51, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.326700</td>\n",
       "      <td>0.231811</td>\n",
       "      <td>0.962025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.162600</td>\n",
       "      <td>0.161168</td>\n",
       "      <td>0.962025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.186500</td>\n",
       "      <td>0.156454</td>\n",
       "      <td>0.962025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.155600</td>\n",
       "      <td>0.148686</td>\n",
       "      <td>0.963834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.081200</td>\n",
       "      <td>0.153994</td>\n",
       "      <td>0.962025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.073200</td>\n",
       "      <td>0.146168</td>\n",
       "      <td>0.956600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='312' max='312' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [312/312 00:51, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.388900</td>\n",
       "      <td>0.277256</td>\n",
       "      <td>0.956600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.158300</td>\n",
       "      <td>0.178027</td>\n",
       "      <td>0.956600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.251000</td>\n",
       "      <td>0.178351</td>\n",
       "      <td>0.956600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>0.185697</td>\n",
       "      <td>0.956600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.091500</td>\n",
       "      <td>0.202329</td>\n",
       "      <td>0.956600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.114900</td>\n",
       "      <td>0.162677</td>\n",
       "      <td>0.956600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='312' max='312' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [312/312 00:51, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.373200</td>\n",
       "      <td>0.280314</td>\n",
       "      <td>0.954792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.207000</td>\n",
       "      <td>0.184101</td>\n",
       "      <td>0.954792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.188056</td>\n",
       "      <td>0.954792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.070600</td>\n",
       "      <td>0.196560</td>\n",
       "      <td>0.954792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.204700</td>\n",
       "      <td>0.196053</td>\n",
       "      <td>0.954792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.148100</td>\n",
       "      <td>0.179789</td>\n",
       "      <td>0.954792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='312' max='312' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [312/312 00:51, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.382300</td>\n",
       "      <td>0.290204</td>\n",
       "      <td>0.947559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.169100</td>\n",
       "      <td>0.223408</td>\n",
       "      <td>0.947559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.293500</td>\n",
       "      <td>0.208478</td>\n",
       "      <td>0.947559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.069100</td>\n",
       "      <td>0.223197</td>\n",
       "      <td>0.947559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.197900</td>\n",
       "      <td>0.207151</td>\n",
       "      <td>0.947559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.193200</td>\n",
       "      <td>0.190727</td>\n",
       "      <td>0.952984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='312' max='312' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [312/312 00:51, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.374200</td>\n",
       "      <td>0.283830</td>\n",
       "      <td>0.952984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.178400</td>\n",
       "      <td>0.190928</td>\n",
       "      <td>0.952984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.297000</td>\n",
       "      <td>0.210642</td>\n",
       "      <td>0.952984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.076200</td>\n",
       "      <td>0.198290</td>\n",
       "      <td>0.952984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.285300</td>\n",
       "      <td>0.189767</td>\n",
       "      <td>0.952984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.165700</td>\n",
       "      <td>0.197102</td>\n",
       "      <td>0.952984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='312' max='312' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [312/312 00:51, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.398200</td>\n",
       "      <td>0.321093</td>\n",
       "      <td>0.929476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.299900</td>\n",
       "      <td>0.262154</td>\n",
       "      <td>0.929476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.341000</td>\n",
       "      <td>0.277192</td>\n",
       "      <td>0.929476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.219000</td>\n",
       "      <td>0.255981</td>\n",
       "      <td>0.929476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.294900</td>\n",
       "      <td>0.243736</td>\n",
       "      <td>0.929476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.240200</td>\n",
       "      <td>0.252384</td>\n",
       "      <td>0.929476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='312' max='312' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [312/312 00:51, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.394900</td>\n",
       "      <td>0.304569</td>\n",
       "      <td>0.942134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>0.231565</td>\n",
       "      <td>0.942134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.311600</td>\n",
       "      <td>0.226528</td>\n",
       "      <td>0.942134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.268200</td>\n",
       "      <td>0.223304</td>\n",
       "      <td>0.942134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.272300</td>\n",
       "      <td>0.219612</td>\n",
       "      <td>0.942134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.245000</td>\n",
       "      <td>0.220953</td>\n",
       "      <td>0.942134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='312' max='312' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [312/312 00:51, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.413800</td>\n",
       "      <td>0.319208</td>\n",
       "      <td>0.929476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.198500</td>\n",
       "      <td>0.259654</td>\n",
       "      <td>0.929476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.280100</td>\n",
       "      <td>0.257296</td>\n",
       "      <td>0.929476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.264400</td>\n",
       "      <td>0.251981</td>\n",
       "      <td>0.929476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.183900</td>\n",
       "      <td>0.258410</td>\n",
       "      <td>0.929476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.266700</td>\n",
       "      <td>0.234862</td>\n",
       "      <td>0.933092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='312' max='312' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [312/312 00:51, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.386400</td>\n",
       "      <td>0.286070</td>\n",
       "      <td>0.952984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.203300</td>\n",
       "      <td>0.190354</td>\n",
       "      <td>0.952984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.240100</td>\n",
       "      <td>0.189822</td>\n",
       "      <td>0.952984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.139300</td>\n",
       "      <td>0.189512</td>\n",
       "      <td>0.952984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.214500</td>\n",
       "      <td>0.184257</td>\n",
       "      <td>0.952984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.187800</td>\n",
       "      <td>0.182618</td>\n",
       "      <td>0.952984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='312' max='312' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [312/312 00:51, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.374400</td>\n",
       "      <td>0.283992</td>\n",
       "      <td>0.952984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.183900</td>\n",
       "      <td>0.191729</td>\n",
       "      <td>0.952984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.259800</td>\n",
       "      <td>0.189552</td>\n",
       "      <td>0.952984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.070700</td>\n",
       "      <td>0.198991</td>\n",
       "      <td>0.952984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.242900</td>\n",
       "      <td>0.189486</td>\n",
       "      <td>0.952984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.219000</td>\n",
       "      <td>0.200949</td>\n",
       "      <td>0.952984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='312' max='312' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [312/312 00:51, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.378500</td>\n",
       "      <td>0.287276</td>\n",
       "      <td>0.951175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.158200</td>\n",
       "      <td>0.195256</td>\n",
       "      <td>0.951175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.280100</td>\n",
       "      <td>0.194722</td>\n",
       "      <td>0.951175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.118400</td>\n",
       "      <td>0.197726</td>\n",
       "      <td>0.951175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.204300</td>\n",
       "      <td>0.184361</td>\n",
       "      <td>0.951175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.166500</td>\n",
       "      <td>0.164840</td>\n",
       "      <td>0.951175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='312' max='312' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [312/312 00:51, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.370100</td>\n",
       "      <td>0.292052</td>\n",
       "      <td>0.947559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.217100</td>\n",
       "      <td>0.205687</td>\n",
       "      <td>0.947559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.257800</td>\n",
       "      <td>0.211337</td>\n",
       "      <td>0.947559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.111800</td>\n",
       "      <td>0.219037</td>\n",
       "      <td>0.947559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.230500</td>\n",
       "      <td>0.202005</td>\n",
       "      <td>0.947559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.164900</td>\n",
       "      <td>0.198796</td>\n",
       "      <td>0.947559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/feiy/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Training LLM Chains: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:03<00:00, 423.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [19:21, 1161.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot find, start new training\n",
      "train and test size 1382 346\n",
      "scores {'openaichat/gpt-4o-mini': {182: 0.9966456, 825: 0.9964353, 1240: 0.9913633, 505: 0.9891929, 1482: 0.99687624, 1549: 0.9892406, 842: 0.9928832, 1605: 0.9941712, 386: 0.9895188, 1622: 0.99058443, 1182: 0.9965084, 1212: 0.99715734, 487: 0.9967289, 148: 0.9917401, 661: 0.9966461, 950: 0.99700123, 393: 0.9962669, 1056: 0.9966329, 259: 0.99258065, 1415: 0.9916762, 523: 0.9968368, 353: 0.99689263, 1391: 0.99710554, 874: 0.99658966, 12: 0.99646336, 1700: 0.9903628, 527: 0.98659736, 496: 0.9911186, 483: 0.92773587, 365: 0.99653745, 674: 0.99253947, 93: 0.99381196, 729: 0.9899939, 370: 0.99668044, 714: 0.9937198, 898: 0.9917321, 1344: 0.9965552, 831: 0.9964833, 1723: 0.99044526, 203: 0.9913645, 345: 0.9896756, 67: 0.99201137, 1383: 0.99082446, 319: 0.99067163, 852: 0.98886955, 1311: 0.9857268, 45: 0.9943699, 582: 0.9907488, 791: 0.991375, 781: 0.9969313, 221: 0.9674942, 316: 0.9731549, 857: 0.88231444, 578: 0.99684614, 137: 0.9963142, 639: 0.98952734, 1257: 0.99595946, 390: 0.9927678, 5: 0.9961771, 628: 0.9962837, 1402: 0.9930837, 806: 0.9961456, 243: 0.9958454, 720: 0.9943792, 919: 0.99638176, 491: 0.99635446, 768: 0.9929925, 35: 0.9918765, 462: 0.9852149, 414: 0.99326706, 475: 0.9968449, 301: 0.99210936, 923: 0.99253136, 815: 0.9964497, 558: 0.9969688, 1458: 0.991163, 25: 0.98351353, 810: 0.9965532, 557: 0.9925585, 1368: 0.9962896, 369: 0.9930019, 1470: 0.9869306, 57: 0.9902457, 152: 0.9964444, 307: 0.99638426, 1598: 0.9948723, 1380: 0.99234456, 159: 0.99682283, 1382: 0.9922283, 509: 0.5470696, 1665: 0.991381, 615: 0.9864542, 404: 0.9896053, 396: 0.99683905, 1423: 0.98359317, 1179: 0.9963159, 224: 0.99660766, 1084: 0.9963116, 1359: 0.9892811, 660: 0.9909815, 1099: 0.9924441, 590: 0.9962895, 290: 0.99604565, 1548: 0.9961475, 1420: 0.99665004, 1410: 0.9890966, 967: 0.99678874, 979: 0.9915098, 1421: 0.99159884, 512: 0.9943658, 198: 0.24333182, 102: 0.9965216, 479: 0.99683446, 678: 0.9944089, 970: 0.44882816, 1135: 0.99616736, 1583: 0.99601054, 1028: 0.9909314, 397: 0.99156976, 1522: 0.996463, 555: 0.9905317, 293: 0.9928018, 1504: 0.29758793, 1167: 0.98532885, 1360: 0.99651873, 1469: 0.9907582, 1081: 0.9961902, 1192: 0.99569315, 538: 0.98990554, 924: 0.996564, 394: 0.9901522, 1606: 0.9965836, 1397: 0.28698388, 105: 0.9926359, 997: 0.98868096, 144: 0.9918848, 1288: 0.99680746, 1272: 0.9965475, 100: 0.9968911, 1579: 0.99645597, 1557: 0.99674785, 564: 0.99230254, 501: 0.990204, 613: 0.9964964, 757: 0.99617887, 1475: 0.99634725, 865: 0.9956528, 1571: 0.99660933, 1511: 0.9967542, 785: 0.9907707, 1251: 0.9922321, 1490: 0.99652344, 1481: 0.99649066, 24: 0.99613947, 648: 0.99672216, 149: 0.9964461, 1339: 0.9970214, 843: 0.9942123, 253: 0.9963916, 379: 0.99651647, 1575: 0.9878198, 272: 0.9893721, 670: 0.9931525, 1502: 0.9941578, 1657: 0.99160576, 996: 0.9964843, 702: 0.9970511, 276: 0.9964636, 1070: 0.9906769, 1462: 0.98838705, 603: 0.98872966, 588: 0.9961945, 733: 0.99653196, 220: 0.9954703, 542: 0.99675083, 1355: 0.99670035, 1352: 0.9924544, 197: 0.99196666, 449: 0.4909009, 334: 0.99668485, 614: 0.994062, 451: 0.99576664, 691: 0.98843855, 681: 0.9962972, 1626: 0.9963064, 766: 0.9963593, 665: 0.9927483, 616: 0.9964431, 612: 0.9709216, 154: 0.99228704, 190: 0.9964348, 15: 0.99261075, 1268: 0.9963574, 8: 0.34951282, 1296: 0.996461, 329: 0.9907459, 1611: 0.99652064, 1678: 0.9960944, 780: 0.99679166, 4: 0.45562944, 1661: 0.042689674, 1293: 0.99018997, 294: 0.99655485, 1637: 0.99192226, 1365: 0.99653614, 686: 0.99220043, 1333: 0.99672025, 1474: 0.9946031, 759: 0.9962287, 1584: 0.99645567, 504: 0.99649435, 395: 0.22645992, 1573: 0.9862293, 240: 0.9926965, 92: 0.9961104, 85: 0.5100024, 1146: 0.9931211, 735: 0.99592704, 1140: 0.99119043, 528: 0.99678624, 1510: 0.991529, 495: 0.99454993, 574: 0.9962573, 627: 0.9942959, 261: 0.99213845, 1298: 0.9963851, 1232: 0.99299157, 1648: 0.9964282, 821: 0.9969739, 94: 0.9911567, 1495: 0.9966634, 437: 0.99649066, 280: 0.21572147, 120: 0.99629503, 1597: 0.99144626, 520: 0.99127406, 42: 0.99605536, 498: 0.99638736, 1633: 0.996534, 1092: 0.9929811, 835: 0.98937523, 1043: 0.996756, 1181: 0.9896762, 300: 0.9964624, 920: 0.99104553, 86: 0.99702483, 1569: 0.9948999, 1476: 0.9913386, 1166: 0.9903341, 1016: 0.97835106, 79: 0.99658126, 752: 0.9964114, 986: 0.9903798, 1399: 0.99632275, 1496: 0.9882762, 516: 0.99104077, 1580: 0.9905405, 75: 0.99622065, 969: 0.99418205, 41: 0.041256856, 158: 0.9965534, 1596: 0.9914725, 138: 0.99284124, 832: 0.9965417, 645: 0.9923608, 252: 0.99180835, 724: 0.9968285, 561: 0.996621, 337: 0.99473226, 1176: 0.9910849, 960: 0.9969415, 1719: 0.9752237, 1591: 0.99662554, 61: 0.99646807, 1142: 0.9962847, 1169: 0.9892134, 1331: 0.99638534, 1465: 0.9966, 539: 0.9891655, 1631: 0.9882101, 312: 0.996617, 415: 0.9964708, 747: 0.99614197, 953: 0.9963468, 50: 0.9963496, 1638: 0.99083287, 1699: 0.99450314, 1407: 0.24831614, 1560: 0.9947227, 340: 0.9943593, 608: 0.99616677, 524: 0.9969289, 638: 0.9940785, 213: 0.9966767, 1519: 0.99577796, 1356: 0.9835354, 889: 0.9963329, 304: 0.996615, 1276: 0.99082255, 659: 0.24487104, 801: 0.9890338, 796: 0.9940095, 1093: 0.9965808, 425: 0.9900495, 876: 0.9882791, 381: 0.9968364, 106: 0.9822244, 128: 0.9964328, 1705: 0.989971, 1098: 0.9963392, 829: 0.9870524, 788: 0.9957728, 248: 0.9937251, 34: 0.9961373, 632: 0.9964754, 1698: 0.99441165, 9: 0.9965617, 418: 0.8770678, 40: 0.9966294, 604: 0.9933882, 1235: 0.99167836, 577: 0.9966319, 1666: 0.9920426, 1245: 0.99585426, 1673: 0.9898263, 1684: 0.994167, 68: 0.9966042, 629: 0.99649614, 11: 0.98626846, 1394: 0.04180851, 1582: 0.9770657, 1471: 0.99688905, 384: 0.99668723, 987: 0.99149525, 54: 0.9930106, 944: 0.98873806, 1697: 0.99657875, 809: 0.98902494, 675: 0.9905675, 1219: 0.99253696, 309: 0.9926495, 1048: 0.9944494, 1051: 0.996816, 1204: 0.99679273, 436: 0.9963379, 643: 0.99665904, 981: 0.89908636, 827: 0.99316734, 1377: 0.99667007, 1173: 0.9961062, 551: 0.99623615, 1073: 0.7447648, 412: 0.99249744, 1097: 0.99716127, 363: 0.9959858, 322: 0.9906787, 968: 0.9966485, 907: 0.9967558, 331: 0.9964521, 1086: 0.98913467, 507: 0.99192154, 940: 0.26881132, 1536: 0.9919659, 828: 0.9966401, 786: 0.43480113, 1444: 0.99050623, 534: 0.99677086, 297: 0.9970099, 635: 0.9967244, 581: 0.9970692, 1258: 0.9945004, 1604: 0.996655, 136: 0.9925484, 939: 0.99435014, 1500: 0.99642473, 269: 0.9273663, 288: 0.985393, 1224: 0.9945905, 1493: 0.9913079, 1340: 0.99620616, 260: 0.99627423, 362: 0.9963715, 722: 0.9902068, 1248: 0.9966017, 767: 0.98702776, 866: 0.9926219, 875: 0.99180365, 756: 0.9960155, 706: 0.9916339, 1376: 0.99687433, 49: 0.9854837, 1595: 0.9881948, 935: 0.99129033, 984: 0.9970175, 679: 0.99667966, 188: 0.9959714, 1186: 0.9924872, 848: 0.9904304, 1685: 0.9962625, 1724: 0.9957118, 1414: 0.9925961, 1354: 0.9951426, 281: 0.99674535, 522: 0.996734, 1677: 0.98888105, 103: 0.99612975, 456: 0.9919499, 644: 0.98460716, 1228: 0.983039, 895: 0.99687874, 541: 0.9967789, 1128: 0.9962787, 1323: 0.99634534, 830: 0.9930097, 1554: 0.9967956, 1020: 0.9963568, 1603: 0.9925608, 1538: 0.99656016, 377: 0.9953264, 473: 0.99015826, 398: 0.99106103, 419: 0.9965798, 129: 0.9935097, 1156: 0.99029654, 1275: 0.9924166, 360: 0.9965739, 751: 0.99377704, 1106: 0.9964709, 1437: 0.99585634, 673: 0.9879441, 1578: 0.9907177, 891: 0.9925546, 599: 0.9906944, 351: 0.99093103, 882: 0.33225325, 1036: 0.99663687, 1721: 0.9372445, 1134: 0.9918156, 1153: 0.9959753, 1074: 0.99590284, 901: 0.99238443, 17: 0.99639577, 286: 0.99606496, 344: 0.9908632, 359: 0.9891839, 749: 0.98894566, 348: 0.99268675, 1446: 0.987852, 249: 0.99669826, 914: 0.99336064, 1347: 0.99661475, 1231: 0.9940924, 929: 0.9894154, 864: 0.99127907, 1190: 0.99608153, 7: 0.99213684, 1198: 0.99674857, 851: 0.99096924, 1384: 0.99331653, 201: 0.9865443, 1450: 0.59020096, 480: 0.9915167, 1113: 0.9966719, 1077: 0.99704045, 867: 0.9966529, 18: 0.98985064, 1131: 0.9866215, 1619: 0.9915187, 1346: 0.9961015, 862: 0.9918676, 1050: 0.9969336, 74: 0.99284536, 770: 0.99389863, 1085: 0.996878, 982: 0.9966973, 170: 0.9965953, 464: 0.99523723, 696: 0.9967817, 1544: 0.9925948, 223: 0.9902022, 1038: 0.99694985, 1280: 0.32661372, 1366: 0.9917508, 1479: 0.9867959, 974: 0.98708177, 83: 0.9963701, 814: 0.99203193, 1433: 0.98974013, 1203: 0.99670345, 270: 0.9961361, 1054: 0.9972229, 1624: 0.99648225, 383: 0.9895643, 1385: 0.99377763, 1505: 0.995961, 1485: 0.9899934, 1080: 0.9941943, 1023: 0.9817763, 20: 0.9962858, 1067: 0.9962884, 385: 0.9963936, 332: 0.9924833, 903: 0.99634534, 324: 0.9966624, 227: 0.9966524, 1408: 0.98686755, 1389: 0.9905381, 1488: 0.9962889, 439: 0.9949308, 361: 0.99176097, 1654: 0.9917732, 753: 0.9966864, 1425: 0.996467, 990: 0.9966509, 554: 0.30488783, 909: 0.9942194, 1180: 0.99645007, 888: 0.99601585, 958: 0.99452883, 530: 0.99112004, 1441: 0.99643815, 469: 0.9968182, 1233: 0.9881015, 1215: 0.9873624, 368: 0.99344915, 1520: 0.99438536, 1570: 0.995856, 1124: 0.990546, 560: 0.9883879, 928: 0.9906968, 266: 0.9881811, 1236: 0.9924097, 460: 0.98800653, 1546: 0.9889586, 500: 0.9967146, 1133: 0.99648356, 1031: 0.99708456, 325: 0.9928974, 802: 0.99281526, 476: 0.9855971, 730: 0.9967205, 250: 0.99333125, 765: 0.9965688, 900: 0.99115914, 421: 0.9966234, 685: 0.99186534, 70: 0.9936121, 1247: 0.99663466, 799: 0.9843912, 16: 0.9909594, 1396: 0.9970693, 211: 0.99685514, 113: 0.9966002, 87: 0.9891424, 1037: 0.9933523, 1170: 0.9961046, 1014: 0.66819453, 80: 0.99629635, 1655: 0.9914757, 1533: 0.99648166, 1422: 0.99462295, 1162: 0.99361825, 978: 0.9968466, 1674: 0.9968201, 1154: 0.99690056, 748: 0.99195695, 1526: 0.99585646, 703: 0.99686736, 349: 0.9968681, 315: 0.9965127, 1321: 0.9963464, 289: 0.9964574, 1658: 0.9928392, 295: 0.99463356, 1348: 0.99666756, 1284: 0.99661297, 1379: 0.99622357, 1225: 0.9938308, 400: 0.98651195, 1660: 0.9913612, 1220: 0.99654406, 1395: 0.9944733, 1701: 0.99618214, 684: 0.9872808, 553: 0.9916888, 62: 0.99203944, 1283: 0.99498606, 313: 0.99362755, 262: 0.98994607, 1200: 0.9014963, 69: 0.9964103, 1577: 0.99310476, 1253: 0.9914745, 854: 0.99122417, 734: 0.31841955, 66: 0.9967945, 1614: 0.9878769, 708: 0.99006885, 559: 0.99178845, 1213: 0.98486114, 966: 0.99600035, 795: 0.98944914, 116: 0.9947448, 303: 0.9940923, 1632: 0.9914415, 563: 0.9934007, 374: 0.9960375, 402: 0.9888854, 10: 0.99244446, 1209: 0.99627066, 793: 0.995609, 474: 0.99618185, 896: 0.9898509, 1242: 0.9966871, 271: 0.9960698, 589: 0.9890303, 1217: 0.9969496, 417: 0.996842, 497: 0.9919892, 1639: 0.23057494, 656: 0.9965287, 196: 0.9961434, 653: 0.9929386, 1222: 0.9964618, 118: 0.9931599, 994: 0.987677, 949: 0.9922186, 912: 0.99426705, 0: 0.99671507, 1452: 0.9917883, 1492: 0.24987608, 130: 0.9954791, 713: 0.041927498, 1593: 0.9930403, 1063: 0.9969831, 1334: 0.99665546, 1199: 0.9964522, 1717: 0.99700683, 391: 0.9959345, 1620: 0.9963329, 1411: 0.9183608, 701: 0.99658257, 1478: 0.9896207, 704: 0.99700814, 125: 0.9913474, 1551: 0.986534, 1019: 0.2645201, 273: 0.9970547, 1529: 0.9967589, 1559: 0.8977457, 447: 0.9969554, 236: 0.9964849, 956: 0.98968726, 81: 0.99251467, 761: 0.9912174, 600: 0.9906418, 1185: 0.99692434, 235: 0.9961746, 1656: 0.9884437, 1406: 0.9968726, 1647: 0.9903978, 468: 0.996572, 28: 0.9846618, 1672: 0.9970982, 1589: 0.9963856, 1250: 0.9903048, 1707: 0.9969844, 350: 0.9923805, 976: 0.9924132, 740: 0.9901097, 1194: 0.9957426, 1454: 0.98963577, 1693: 0.9962018, 1022: 0.9962515, 871: 0.9967182, 1537: 0.9943756, 1372: 0.9916466, 401: 0.99657744, 255: 0.9959462, 977: 0.9867263, 175: 0.9922654, 705: 0.98966926, 964: 0.99262106, 797: 0.98858005, 380: 0.9924333, 1386: 0.9898004, 1007: 0.9899629, 1205: 0.9967063, 234: 0.99662066, 584: 0.99616265, 1680: 0.9965913, 1230: 0.9925479, 1041: 0.9965513, 426: 0.99653697, 1032: 0.9923119, 1065: 0.9963637, 277: 0.9881941, 1164: 0.9920603, 736: 0.99688005, 173: 0.9965406, 1576: 0.99102354, 906: 0.99665856, 1256: 0.04166773, 963: 0.9963586, 587: 0.9918928, 26: 0.9965252, 774: 0.986782, 150: 0.99597675, 651: 0.9964043, 1405: 0.9896628, 1174: 0.9963844, 926: 0.99681014, 1114: 0.9963481, 1613: 0.99094677, 700: 0.9967566, 1687: 0.9732857, 366: 0.9929945, 1434: 0.9916899, 1689: 0.9967163, 959: 0.9962309, 683: 0.99349326, 114: 0.9965217, 1403: 0.9962681, 1477: 0.99679667, 6: 0.99699044, 1088: 0.54278237, 545: 0.9919652, 510: 0.9907267, 1473: 0.996505, 641: 0.9913088, 1116: 0.99675566, 1141: 0.9127208, 671: 0.99696016, 1100: 0.99092454, 1712: 0.9922218, 1709: 0.9916653, 1669: 0.9942624, 1362: 0.99663997, 839: 0.9965681, 957: 0.99047196, 918: 0.9909957, 1184: 0.9963903, 1545: 0.98899394, 1118: 0.9931745, 208: 0.98257244, 161: 0.98858356, 1435: 0.9967648, 606: 0.99688333, 378: 0.9937735, 998: 0.9933776, 1060: 0.99637955, 636: 0.9967691, 310: 0.89553374, 540: 0.9887926, 1552: 0.9933286, 902: 0.9965694, 108: 0.99041945, 2: 0.98825175, 1486: 0.99161786, 1427: 0.99634093, 1645: 0.98834, 514: 0.9910629, 535: 0.99355596, 1049: 0.9944858, 1541: 0.9900069, 217: 0.98844355, 1274: 0.9904711, 1374: 0.99390924, 971: 0.9969214, 1535: 0.9962685, 1499: 0.311632, 1412: 0.99129593, 1586: 0.99638665, 743: 0.9966091, 1682: 0.9914757, 975: 0.9965, 1445: 0.9964696, 586: 0.99678373, 1252: 0.9906701, 567: 0.99659246, 819: 0.9940764, 1210: 0.9882896, 763: 0.99619114, 489: 0.99665713, 254: 0.996603, 1108: 0.041932583, 543: 0.9933756, 570: 0.9933309, 771: 0.99159044, 38: 0.98930246, 925: 0.99598444, 792: 0.9943658, 1600: 0.99630773, 399: 0.9937828, 22: 0.9958669, 1564: 0.9964083, 407: 0.99653107, 916: 0.9959033, 897: 0.98669434, 356: 0.9912388, 185: 0.9959046, 127: 0.99643636, 115: 0.9894169, 1512: 0.9960956, 1018: 0.9965773, 181: 0.9962752, 602: 0.9971341, 467: 0.9965037, 132: 0.9918218, 647: 0.9880696, 1424: 0.9967303, 1262: 0.9915848, 585: 0.9853467, 1690: 0.9947115, 755: 0.994402, 938: 0.99062365, 1587: 0.9827404, 610: 0.9914063, 471: 0.9887186, 215: 0.99582434, 335: 0.9925443, 1013: 0.99160963, 1404: 0.99671626, 373: 0.99646413, 1223: 0.9963445, 1216: 0.9968658, 1438: 0.99641645, 60: 0.9961636, 689: 0.9910416, 109: 0.99604756, 1720: 0.99653804, 1702: 0.9959609, 306: 0.99171233, 1322: 0.9964307, 1158: 0.9923609, 1463: 0.9947747, 433: 0.93413115, 375: 0.989028, 465: 0.99651587, 620: 0.99654144, 23: 0.99450254, 754: 0.9903706, 1521: 0.99628204, 257: 0.99186456, 1286: 0.9968997, 264: 0.9966229, 1105: 0.9966543, 195: 0.9969131, 1318: 0.9889059, 833: 0.99625117, 597: 0.9161034, 1294: 0.9937251, 481: 0.989005, 204: 0.99327576, 737: 0.9939803, 1567: 0.99008626, 531: 0.99292326, 206: 0.9922502, 1281: 0.99689853, 1430: 0.99218374, 318: 0.9965687, 1267: 0.99387854, 1460: 0.9935087, 804: 0.99644643, 699: 0.9896248, 1361: 0.98836935, 490: 0.99626476, 53: 0.9845478, 887: 0.9893484, 568: 0.99116206, 1371: 0.99295956, 811: 0.22553669, 890: 0.9925764, 1532: 0.99664754, 164: 0.9927562, 782: 0.9919777, 769: 0.99411327, 1103: 0.9961683, 598: 0.9968154, 237: 0.96359175, 1547: 0.9713528, 592: 0.9964104, 1191: 0.99322057, 1447: 0.9963297, 654: 0.99681205, 596: 0.9965869, 1608: 0.9899829, 1695: 0.9921967, 1306: 0.9964592, 962: 0.9960782, 428: 0.9967225, 712: 0.9943758, 457: 0.9901134, 46: 0.9971529, 562: 0.9967753, 317: 0.99285203, 142: 0.9965301, 894: 0.9937737, 847: 0.99647164, 1125: 0.9967423, 1612: 0.99248827, 96: 0.99629444, 1127: 0.99640733, 1542: 0.9877224, 1227: 0.9966182, 90: 0.9893973, 1155: 0.9907046, 1516: 0.9966551, 321: 0.99636936, 1342: 0.96849144, 229: 0.9888403, 274: 0.99695206, 1285: 0.27889356, 709: 0.9893293, 1550: 0.9909252, 1211: 0.041890316, 1642: 0.99056363, 1301: 0.99636084, 593: 0.99621683, 1183: 0.9965042, 492: 0.9820349, 291: 0.97194314, 210: 0.9891962, 65: 0.99644464, 547: 0.99359775, 544: 0.98719066, 186: 0.9968617, 1525: 0.99632096, 789: 0.9893183, 1480: 0.34435883, 124: 0.9887057, 1021: 0.99376726, 1472: 0.9964933, 1694: 0.9961753, 1005: 0.9878977, 91: 0.9966252, 1429: 0.9925443, 738: 0.9906172, 1030: 0.9946279, 972: 0.9921382, 89: 0.99223304, 826: 0.9935069, 171: 0.9947444, 1075: 0.99691546, 1282: 0.9958799, 853: 0.9962159, 760: 0.9943057, 1514: 0.9952108, 932: 0.993302, 162: 0.99238646, 880: 0.9916487, 777: 0.9963319, 1325: 0.99678695, 1616: 0.9897684, 1627: 0.9923447, 207: 0.9964812, 1206: 0.9964616, 430: 0.992531, 1566: 0.9892157, 669: 0.9890275, 762: 0.9927424, 1539: 0.9908598, 1459: 0.99663085, 151: 0.993618, 1467: 0.9927953, 1017: 0.99665785, 1711: 0.99636394, 942: 0.98551893, 347: 0.9909383, 180: 0.9915684, 1703: 0.99682534, 1115: 0.9935707, 989: 0.99651635, 135: 0.9917606, 1387: 0.9969555, 3: 0.99005157, 1592: 0.9867929, 1292: 0.9969982, 1270: 0.9965803, 1265: 0.9964747, 533: 0.99672854, 905: 0.98966545, 1649: 0.9910886, 372: 0.99289435, 1305: 0.9902154, 192: 0.9966725, 988: 0.99662775, 885: 0.99440384, 860: 0.9788897, 1302: 0.9888409, 1138: 0.99126726, 298: 0.996867, 275: 0.99613214, 649: 0.98826575, 778: 0.9857939, 1528: 0.9930066, 1708: 0.9924124, 434: 0.39121506, 1111: 0.99316543, 1295: 0.99663097, 1574: 0.9966505, 820: 0.99663925, 947: 0.996651, 1484: 0.9965738, 165: 0.99659675, 101: 0.9966635, 1364: 0.99251336, 715: 0.9970722, 1629: 0.991634, 794: 0.25526097, 285: 0.9965283, 571: 0.99671173, 64: 0.9944207, 1453: 0.98984116, 1581: 0.9968894, 911: 0.9907795, 850: 0.9970017, 403: 0.99667406, 930: 0.99597013, 1055: 0.9964825, 1381: 0.9899082, 420: 0.99217117, 1259: 0.996819, 556: 0.995886, 459: 0.99178946, 1159: 0.99666756, 870: 0.99390584, 36: 0.9964887, 1046: 0.99669266, 1218: 0.99193317, 1540: 0.9931132, 1053: 0.98700935, 1456: 0.9964933, 1636: 0.99357843, 355: 0.99627256, 1025: 0.99473214, 1119: 0.99696535, 904: 0.9966466, 1568: 0.99674726, 1335: 0.9896818, 1704: 0.99633837, 1417: 0.99634284, 1040: 0.9925972, 1440: 0.9961713, 631: 0.9503212, 371: 0.9965065, 282: 0.99004817, 1144: 0.9963014, 834: 0.9963846, 697: 0.9876414, 878: 0.26575485, 1122: 0.9968354, 452: 0.9942741, 466: 0.996436, 408: 0.991995, 242: 0.9969009, 1042: 0.98837763, 387: 0.9902289, 1329: 0.9965939, 247: 0.9924144, 157: 0.9935608, 1078: 0.99400604, 1316: 0.9911259, 442: 0.99234915, 624: 0.9945344, 1308: 0.99678636, 99: 0.99209327, 1683: 0.9968052, 1507: 0.9967133, 913: 0.9967277, 1498: 0.30124372, 652: 0.99239606, 595: 0.9931785, 296: 0.99398476, 27: 0.9923275, 299: 0.87035745, 1455: 0.9925189, 21: 0.996624, 245: 0.5991588, 367: 0.99495786, 1610: 0.99078965, 779: 0.9683861, 517: 0.9942367, 1297: 0.2531374, 174: 0.9964659, 1143: 0.99635965, 1398: 0.99216825, 1602: 0.99649054, 1715: 0.9964469, 406: 0.9844095, 1451: 0.996852, 169: 0.996247, 1599: 0.99676216, 440: 0.98795635, 910: 0.98436606, 405: 0.99142367, 1553: 0.99366957, 122: 0.99627954, 178: 0.9907832, 1506: 0.9969171, 346: 0.9968964, 246: 0.99038064, 1572: 0.9919419, 1150: 0.99036366, 427: 0.9961132, 153: 0.9966041, 1607: 0.9918663, 1337: 0.97827864, 1083: 0.993912, 1076: 0.9967192, 908: 0.9964227, 44: 0.9965269, 1527: 0.98718864, 77: 0.9873604, 1696: 0.9964238, 1001: 0.9958224, 147: 0.99041325, 1: 0.9963366, 1175: 0.9938864, 1107: 0.99687237, 82: 0.99017906, 389: 0.9908434, 1326: 0.9965939, 611: 0.9966684, 1691: 0.99098855, 955: 0.98908234, 1026: 0.9915685, 1353: 0.99671507, 1714: 0.99074405, 845: 0.99653, 1112: 0.9965487, 1358: 0.996554, 482: 0.9901384, 1400: 0.9927979, 1137: 0.9921977, 822: 0.25827602, 1168: 0.99627423, 859: 0.9941929, 840: 0.99695885, 1718: 0.97516984, 732: 0.9927302, 31: 0.9890982, 1045: 0.9921686, 409: 0.9966515, 973: 0.9927085, 1120: 0.9965062, 1686: 0.9930062, 1303: 0.99215204, 453: 0.9963799, 499: 0.9964515, 680: 0.99122834, 95: 0.9933756, 863: 0.99660814, 725: 0.99029845, 308: 0.98997635, 844: 0.99116033, 107: 0.99291795, 1071: 0.9965664, 1132: 0.99636406, 519: 0.99284875, 550: 0.99691296, 666: 0.9965856, 1336: 0.98893905, 650: 0.99642354, 1289: 0.9967114, 1271: 0.9966826, 1047: 0.99659353, 1123: 0.9911815, 1716: 0.99659604, 444: 0.9888398, 731: 0.9933351, 212: 0.9915058, 594: 0.9869845, 872: 0.9909915, 145: 0.9964187, 477: 0.9907895, 268: 0.9968395, 59: 0.9690364, 1713: 0.994235, 625: 0.99263, 179: 0.99622774, 1491: 0.9966401, 739: 0.9963315, 609: 0.9969656, 218: 0.99686015, 723: 0.996539, 431: 0.9965341, 472: 0.9909095, 1443: 0.9895667, 263: 0.9889681, 1029: 0.99681216, 980: 0.4039312, 222: 0.9921933, 1003: 0.996082, 1523: 0.9921524, 1307: 0.9916888, 892: 0.9915142, 812: 0.9970161, 413: 0.9926766, 572: 0.99654895, 1069: 0.99669576, 1419: 0.99642676, 915: 0.99371606, 163: 0.9964585, 1197: 0.99675626, 326: 0.99001896, 858: 0.99251735, 1239: 0.9963961, 131: 0.991305, 358: 0.99685943, 48: 0.9963321, 1722: 0.99675, 98: 0.9967308, 333: 0.99614346, 869: 0.9941321, 29: 0.9939283, 698: 0.9964461, 1367: 0.99668866, 526: 0.990704, 1109: 0.9927443, 1034: 0.9954965, 985: 0.9921759, 1130: 0.9919069, 1129: 0.99168605, 899: 0.9895168, 658: 0.98802084, 97: 0.9833703, 787: 0.9896771, 1618: 0.99443334, 485: 0.9920819, 1681: 0.99107295, 1350: 0.97238785, 441: 0.990168, 1196: 0.99686337, 110: 0.9934953, 1556: 0.99338067, 532: 0.99655426, 991: 0.9964728, 634: 0.99657804, 1483: 0.98832756, 461: 0.99122965, 677: 0.9917133, 886: 0.9970613, 446: 0.9964929, 646: 0.9960084, 1152: 0.9937557, 1464: 0.99701905, 682: 0.9958261, 202: 0.99187136, 155: 0.99454534, 172: 0.9968149, 513: 0.99186474, 200: 0.9939937, 1121: 0.99157953, 1628: 0.9872481, 1375: 0.992277, 744: 0.99697685, 1024: 0.99054354, 655: 0.9217641, 758: 0.9932405, 205: 0.99684286, 47: 0.9966354, 382: 0.9900473, 1634: 0.9967591, 1351: 0.99647886, 718: 0.9879838, 1095: 0.9964144, 1508: 0.9970662, 1091: 0.99593985, 601: 0.9962894, 1588: 0.99685353, 1432: 0.9965586, 868: 0.9939173, 566: 0.99661833, 1015: 0.99214935, 1110: 0.9968736, 922: 0.9930239, 1468: 0.99654925, 1662: 0.99659973, 58: 0.9965425, 1090: 0.99554634, 1249: 0.98986197, 719: 0.99107563, 1373: 0.9966893, 1157: 0.9944952, 1234: 0.99687636, 1237: 0.99655235, 936: 0.044179156, 548: 0.99649316, 1343: 0.9967578, 1061: 0.9967681, 1725: 0.99316734, 1277: 0.9877627, 78: 0.9914369, 302: 0.99629813, 1011: 0.99390537, 284: 0.99647456, 119: 0.99635834, 518: 0.9916957, 1149: 0.99127394, 823: 0.99035925, 1363: 0.839759, 775: 0.40648228, 133: 0.9851774, 287: 0.99095446, 424: 0.92113805, 1555: 0.9916197, 51: 0.9965773, 1388: 0.9940754, 1349: 0.991137, 927: 0.9969227, 1006: 0.996009, 139: 0.9963594, 1442: 0.99310064, 230: 0.993228, 104: 0.9963921, 508: 0.9946308, 1314: 0.9963773, 1675: 0.99683386, 343: 0.996309, 883: 0.9964508, 1139: 0.9928712, 1243: 0.9914663, 502: 0.99137175, 1101: 0.9867399, 1585: 0.98824114, 1058: 0.9964399, 1726: 0.98981583, 244: 0.99662364, 941: 0.996111, 1671: 0.97474694, 278: 0.99528825, 711: 0.9968606, 1089: 0.9923143, 484: 0.9918881, 943: 0.99348265, 1096: 0.9963606, 856: 0.9961234, 1663: 0.9931196, 111: 0.98851573, 1039: 0.99432796, 710: 0.9908269, 1012: 0.99662685, 565: 0.9910425, 305: 0.9887728, 1392: 0.9960711, 177: 0.98643875, 1515: 0.99012136, 626: 0.99304754, 1457: 0.99641114, 232: 0.06868912, 817: 0.9964142, 1309: 0.9919669, 672: 0.9963329, 251: 0.99640024, 1530: 0.9865124, 241: 0.98736507, 63: 0.99699533, 199: 0.996311, 622: 0.99603564, 209: 0.99427265, 1052: 0.996554, 1082: 0.99351865, 1667: 0.9932674, 1266: 0.99414754, 216: 0.99277097, 965: 0.9939995, 39: 0.99697363, 1357: 0.96711427, 1461: 0.9775803, 1263: 0.9965109, 790: 0.9961293, 992: 0.98876673, 357: 0.99122274, 470: 0.33583415, 52: 0.9838689, 884: 0.9918051, 515: 0.9965641, 695: 0.98935014, 454: 0.9906969, 1561: 0.9966628, 855: 0.9919647}, 'openaichat/gpt-4o': {182: 0.9941567, 825: 0.9944267, 1240: 0.9751321, 505: 0.98764837, 1482: 0.99340606, 1549: 0.99178606, 842: 0.9789196, 1605: 0.99120367, 386: 0.9783869, 1622: 0.9717668, 1182: 0.99387723, 1212: 0.9937973, 487: 0.9937219, 148: 0.967223, 661: 0.99413526, 950: 0.99368507, 393: 0.9937117, 1056: 0.9939579, 259: 0.9875164, 1415: 0.9855736, 523: 0.9939715, 353: 0.99353164, 1391: 0.9935666, 874: 0.99442357, 12: 0.99412066, 1700: 0.9821146, 527: 0.9812572, 496: 0.9840449, 483: 0.991227, 365: 0.9941684, 674: 0.980033, 93: 0.99217063, 729: 0.97791946, 370: 0.99418086, 714: 0.99210066, 898: 0.9845069, 1344: 0.99374986, 831: 0.9938646, 1723: 0.98423886, 203: 0.9818233, 345: 0.97860056, 67: 0.97821814, 1383: 0.97238696, 319: 0.987525, 852: 0.98359734, 1311: 0.98258305, 45: 0.9912451, 582: 0.9697132, 791: 0.9785534, 781: 0.9937536, 221: 0.99089175, 316: 0.9938345, 857: 0.9562807, 578: 0.9939183, 137: 0.9938625, 639: 0.96998894, 1257: 0.9941607, 390: 0.9932569, 5: 0.99417734, 628: 0.99386567, 1402: 0.9849038, 806: 0.9943235, 243: 0.99402857, 720: 0.99173534, 919: 0.99421096, 491: 0.99354136, 768: 0.97156906, 35: 0.9759393, 462: 0.9490668, 414: 0.9876693, 475: 0.9931359, 301: 0.9835608, 923: 0.98016167, 815: 0.99405426, 558: 0.9931896, 1458: 0.9917447, 25: 0.97433746, 810: 0.9941552, 557: 0.9915194, 1368: 0.9942334, 369: 0.977607, 1470: 0.9812992, 57: 0.9811856, 152: 0.993975, 307: 0.994282, 1598: 0.98002726, 1380: 0.97958994, 159: 0.99362046, 1382: 0.97926, 509: 0.9940388, 1665: 0.9726351, 615: 0.9808022, 404: 0.9857158, 396: 0.9936086, 1423: 0.9669855, 1179: 0.9941314, 224: 0.9940592, 1084: 0.9941906, 1359: 0.97801185, 660: 0.9703655, 1099: 0.9842263, 590: 0.9942572, 290: 0.9940957, 1548: 0.9930837, 1420: 0.9940696, 1410: 0.9860038, 967: 0.9937848, 979: 0.9795909, 1421: 0.98573697, 512: 0.9920551, 198: 0.9366415, 102: 0.99397236, 479: 0.9936744, 678: 0.9914541, 970: 0.9749274, 1135: 0.9941426, 1583: 0.9942192, 1028: 0.9816244, 397: 0.9804104, 1522: 0.94917774, 555: 0.98075795, 293: 0.9824837, 1504: 0.94491524, 1167: 0.9672211, 1360: 0.9940375, 1469: 0.9770081, 1081: 0.9756141, 1192: 0.99421656, 538: 0.97981846, 924: 0.9938578, 394: 0.988782, 1606: 0.9939977, 1397: 0.97736484, 105: 0.99181527, 997: 0.9774514, 144: 0.979958, 1288: 0.99378705, 1272: 0.99395776, 100: 0.99322367, 1579: 0.99411607, 1557: 0.99386144, 564: 0.9714336, 501: 0.98508817, 613: 0.9930559, 757: 0.9940826, 1475: 0.99395376, 865: 0.994261, 1571: 0.99387395, 1511: 0.9931183, 785: 0.9780694, 1251: 0.97857213, 1490: 0.99369323, 1481: 0.9929755, 24: 0.9941958, 648: 0.99452, 149: 0.9941963, 1339: 0.99346304, 843: 0.99144006, 253: 0.99407923, 379: 0.9934223, 1575: 0.9835271, 272: 0.98193467, 670: 0.9937186, 1502: 0.9916769, 1657: 0.984657, 996: 0.99399614, 702: 0.9934384, 276: 0.9937412, 1070: 0.98526615, 1462: 0.982061, 603: 0.9808395, 588: 0.994003, 733: 0.99406403, 220: 0.9924287, 542: 0.9942789, 1355: 0.99308807, 1352: 0.9779312, 197: 0.9860312, 449: 0.99393034, 334: 0.99411124, 614: 0.99189866, 451: 0.9789162, 691: 0.9825044, 681: 0.9943606, 1626: 0.99413115, 766: 0.9941466, 665: 0.97925466, 616: 0.9941922, 612: 0.9786512, 154: 0.9787593, 190: 0.99378806, 15: 0.9836843, 1268: 0.99412525, 8: 0.9636334, 1296: 0.9939107, 329: 0.9841106, 1611: 0.99415296, 1678: 0.9944306, 780: 0.9935408, 4: 0.9238966, 1661: 0.9133095, 1293: 0.9871192, 294: 0.9938496, 1637: 0.97755855, 1365: 0.9939621, 686: 0.9774096, 1333: 0.9937395, 1474: 0.9921623, 759: 0.99421304, 1584: 0.994273, 504: 0.99407417, 395: 0.9911652, 1573: 0.98085463, 240: 0.97620183, 92: 0.9942625, 85: 0.97452784, 1146: 0.9918744, 735: 0.9942226, 1140: 0.97692436, 528: 0.99404776, 1510: 0.9793897, 495: 0.9924206, 574: 0.9941818, 627: 0.9922273, 261: 0.97468424, 1298: 0.99411994, 1232: 0.99044317, 1648: 0.9943256, 821: 0.9939991, 94: 0.98454213, 1495: 0.9934395, 437: 0.9940528, 280: 0.992712, 120: 0.99432856, 1597: 0.992661, 520: 0.97939074, 42: 0.99422824, 498: 0.9942449, 1633: 0.9934743, 1092: 0.99354917, 835: 0.9856418, 1043: 0.9941549, 1181: 0.9835029, 300: 0.9941711, 920: 0.9728168, 86: 0.99370885, 1569: 0.9921228, 1476: 0.9939797, 1166: 0.98607165, 1016: 0.97698194, 79: 0.9943057, 752: 0.99365765, 986: 0.9755519, 1399: 0.9943705, 1496: 0.98187435, 516: 0.987058, 1580: 0.98241365, 75: 0.99422604, 969: 0.99182653, 41: 0.93463594, 158: 0.99415237, 1596: 0.97460383, 138: 0.9764097, 832: 0.9933954, 645: 0.97970504, 252: 0.9799524, 724: 0.9940195, 561: 0.9933909, 337: 0.9914909, 1176: 0.9608531, 960: 0.99367696, 1719: 0.9583051, 1591: 0.9934854, 61: 0.99427044, 1142: 0.9942674, 1169: 0.9840313, 1331: 0.9941678, 1465: 0.993814, 539: 0.97755677, 1631: 0.9842225, 312: 0.9939056, 415: 0.99415827, 747: 0.9940083, 953: 0.9941994, 50: 0.9941577, 1638: 0.98682076, 1699: 0.99183977, 1407: 0.9187229, 1560: 0.99102986, 340: 0.9921375, 608: 0.9941057, 524: 0.9938413, 638: 0.9919652, 213: 0.99385154, 1519: 0.9937959, 1356: 0.9775252, 889: 0.9941664, 304: 0.9943455, 1276: 0.976585, 659: 0.9569074, 801: 0.97976124, 796: 0.99207884, 1093: 0.9941485, 425: 0.9799963, 876: 0.97945935, 381: 0.9941328, 106: 0.960855, 128: 0.9941141, 1705: 0.9744752, 1098: 0.99413764, 829: 0.97555757, 788: 0.99152523, 248: 0.99215794, 34: 0.99424803, 632: 0.99419385, 1698: 0.99185455, 9: 0.9940077, 418: 0.9940533, 40: 0.9943242, 604: 0.98246014, 1235: 0.9718919, 577: 0.9938338, 1666: 0.9784224, 1245: 0.99403787, 1673: 0.9838095, 1684: 0.99185395, 68: 0.99415463, 629: 0.9941246, 11: 0.98084015, 1394: 0.7213777, 1582: 0.97427666, 1471: 0.99378246, 384: 0.9940289, 987: 0.9633738, 54: 0.99206054, 944: 0.9778375, 1697: 0.99332196, 809: 0.9789954, 675: 0.97918737, 1219: 0.9919918, 309: 0.9850935, 1048: 0.9921583, 1051: 0.9940149, 1204: 0.9940849, 436: 0.9937855, 643: 0.9939667, 981: 0.97901994, 827: 0.98030925, 1377: 0.99407405, 1173: 0.9941901, 551: 0.9939188, 1073: 0.9800475, 412: 0.9792428, 1097: 0.99360293, 363: 0.9942942, 322: 0.97684824, 968: 0.9939837, 907: 0.993638, 331: 0.99378395, 1086: 0.97067195, 507: 0.98752856, 940: 0.95425344, 1536: 0.981177, 828: 0.9932935, 786: 0.9635948, 1444: 0.9769234, 534: 0.99411666, 297: 0.9935137, 635: 0.9938338, 581: 0.9927367, 1258: 0.9906121, 1604: 0.99382246, 136: 0.97482, 939: 0.99229443, 1500: 0.9937634, 269: 0.9937325, 288: 0.9798732, 1224: 0.9912143, 1493: 0.98908114, 1340: 0.99409276, 260: 0.9941321, 362: 0.99410003, 722: 0.97870034, 1248: 0.99404705, 767: 0.9922949, 866: 0.9835434, 875: 0.98629147, 756: 0.9942188, 706: 0.9796919, 1376: 0.993883, 49: 0.98131424, 1595: 0.9850103, 935: 0.9691442, 984: 0.9936412, 679: 0.9939266, 188: 0.99419, 1186: 0.99390054, 848: 0.9810339, 1685: 0.95171636, 1724: 0.9773158, 1414: 0.99348664, 1354: 0.9916306, 281: 0.9939833, 522: 0.99389184, 1677: 0.9807802, 103: 0.994159, 456: 0.97749615, 644: 0.9649245, 1228: 0.9652897, 895: 0.99430084, 541: 0.99305904, 1128: 0.9941326, 1323: 0.9923908, 830: 0.9922822, 1554: 0.99380034, 1020: 0.99410456, 1603: 0.9753525, 1538: 0.9942076, 377: 0.992834, 473: 0.9772899, 398: 0.97942686, 419: 0.99327725, 129: 0.9919326, 1156: 0.98646045, 1275: 0.98417413, 360: 0.9937359, 751: 0.9916863, 1106: 0.994097, 1437: 0.97801685, 673: 0.9843406, 1578: 0.9742769, 891: 0.9842369, 599: 0.98438, 351: 0.9775025, 882: 0.9782413, 1036: 0.99213296, 1721: 0.9850643, 1134: 0.9867654, 1153: 0.99365026, 1074: 0.9942345, 901: 0.98609865, 17: 0.99349207, 286: 0.9942544, 344: 0.9783402, 359: 0.9819004, 749: 0.9743327, 348: 0.9915993, 1446: 0.9823309, 249: 0.99425805, 914: 0.980893, 1347: 0.9938788, 1231: 0.9920334, 929: 0.9780814, 864: 0.9701076, 1190: 0.99433124, 7: 0.976583, 1198: 0.993824, 851: 0.9845675, 1384: 0.9920608, 201: 0.9758542, 1450: 0.9689067, 480: 0.9808085, 1113: 0.99419516, 1077: 0.993863, 867: 0.993778, 18: 0.98164994, 1131: 0.98100764, 1619: 0.98614407, 1346: 0.9943422, 862: 0.95787, 1050: 0.9937762, 74: 0.9844512, 770: 0.991523, 1085: 0.99409926, 982: 0.9942636, 170: 0.9937797, 464: 0.9934808, 696: 0.99354386, 1544: 0.98984957, 223: 0.9821967, 1038: 0.9938552, 1280: 0.96787816, 1366: 0.984074, 1479: 0.984121, 974: 0.9839722, 83: 0.99412066, 814: 0.9921308, 1433: 0.98084736, 1203: 0.9933838, 270: 0.99441355, 1054: 0.99355775, 1624: 0.9941043, 383: 0.9796153, 1385: 0.99198735, 1505: 0.9939148, 1485: 0.98307043, 1080: 0.99207485, 1023: 0.9688919, 20: 0.9941156, 1067: 0.99278075, 385: 0.9941381, 332: 0.97833556, 903: 0.9943732, 324: 0.9937664, 227: 0.99419576, 1408: 0.978412, 1389: 0.9821583, 1488: 0.99403954, 439: 0.9913032, 361: 0.9786886, 1654: 0.9777439, 753: 0.99361306, 1425: 0.9942303, 990: 0.993356, 554: 0.96417576, 909: 0.99205875, 1180: 0.9942193, 888: 0.9942069, 958: 0.99180156, 530: 0.983084, 1441: 0.9939466, 469: 0.9934442, 1233: 0.9816203, 1215: 0.9699176, 368: 0.99151796, 1520: 0.9917304, 1570: 0.9942878, 1124: 0.9710324, 560: 0.97287285, 928: 0.9837082, 266: 0.97870344, 1236: 0.9838424, 460: 0.9834313, 1546: 0.9939482, 500: 0.99419457, 1133: 0.99372995, 1031: 0.9936812, 325: 0.98030806, 802: 0.9771255, 476: 0.9936085, 730: 0.99378514, 250: 0.9780216, 765: 0.9937742, 900: 0.9771402, 421: 0.99342865, 685: 0.98201925, 70: 0.9818522, 1247: 0.9939208, 799: 0.9805798, 16: 0.977423, 1396: 0.99371004, 211: 0.99411607, 113: 0.9943125, 87: 0.9714778, 1037: 0.99243176, 1170: 0.9942093, 1014: 0.9943486, 80: 0.994065, 1655: 0.98325956, 1533: 0.9938903, 1422: 0.9907967, 1162: 0.99170554, 978: 0.9940041, 1674: 0.9940708, 1154: 0.9938996, 748: 0.9797688, 1526: 0.99429744, 703: 0.9931851, 349: 0.99328977, 315: 0.99417406, 1321: 0.99421436, 289: 0.99415815, 1658: 0.99192154, 295: 0.99183184, 1348: 0.9934202, 1284: 0.9942439, 1379: 0.9942431, 1225: 0.9919389, 400: 0.9735605, 1660: 0.9825531, 1220: 0.9941129, 1395: 0.99137527, 1701: 0.9942842, 684: 0.9862683, 553: 0.9795567, 62: 0.9656853, 1283: 0.9918961, 313: 0.98389566, 262: 0.99218905, 1200: 0.992717, 69: 0.99427223, 1577: 0.9843687, 1253: 0.9805638, 854: 0.9837827, 734: 0.93645483, 66: 0.9938559, 1614: 0.97067475, 708: 0.9765682, 559: 0.9789027, 1213: 0.9788104, 966: 0.99429, 795: 0.98128134, 116: 0.99219066, 303: 0.9910501, 1632: 0.9909739, 563: 0.98445976, 374: 0.9943211, 402: 0.9803193, 10: 0.97047395, 1209: 0.9941338, 793: 0.9939663, 474: 0.9939585, 896: 0.97057354, 1242: 0.99322647, 271: 0.99413717, 589: 0.9785886, 1217: 0.9921022, 417: 0.9938916, 497: 0.9619893, 1639: 0.9601316, 656: 0.99334985, 196: 0.99421185, 653: 0.97941214, 1222: 0.99399215, 118: 0.9831769, 994: 0.9820358, 949: 0.98136383, 912: 0.9916843, 0: 0.99413574, 1452: 0.98934096, 1492: 0.8791482, 130: 0.9940579, 713: 0.70279634, 1593: 0.9828923, 1063: 0.9941148, 1334: 0.9940316, 1199: 0.9941347, 1717: 0.9939898, 391: 0.99423224, 1620: 0.99414957, 1411: 0.95091987, 701: 0.9938956, 1478: 0.978008, 704: 0.99336916, 125: 0.96180284, 1551: 0.9926634, 1019: 0.9655037, 273: 0.9941064, 1529: 0.9940783, 1559: 0.9462007, 447: 0.9937914, 236: 0.9942583, 956: 0.97829205, 81: 0.9821638, 761: 0.97722036, 600: 0.9786548, 1185: 0.9935489, 235: 0.97597116, 1656: 0.9830578, 1406: 0.99421614, 1647: 0.9795154, 468: 0.99404716, 28: 0.97845197, 1672: 0.99351513, 1589: 0.9940684, 1250: 0.96045125, 1707: 0.99401045, 350: 0.98286635, 976: 0.9839714, 740: 0.9762156, 1194: 0.9942319, 1454: 0.9630251, 1693: 0.99420255, 1022: 0.9942601, 871: 0.99402666, 1537: 0.9916577, 1372: 0.99400043, 401: 0.99416155, 255: 0.9938421, 977: 0.9826821, 175: 0.9808607, 705: 0.9800483, 964: 0.99167085, 797: 0.94875985, 380: 0.9795727, 1386: 0.97189313, 1007: 0.9848467, 1205: 0.99387276, 234: 0.9941083, 584: 0.9940732, 1680: 0.99409086, 1230: 0.9801744, 1041: 0.9935772, 426: 0.9939739, 1032: 0.9829746, 1065: 0.9941076, 277: 0.9792645, 1164: 0.98659986, 736: 0.9936026, 173: 0.9942286, 1576: 0.97610974, 906: 0.9939685, 1256: 0.6705495, 963: 0.9942222, 587: 0.984329, 26: 0.9943269, 774: 0.9864972, 150: 0.9942152, 651: 0.9942431, 1405: 0.98290116, 1174: 0.9931016, 926: 0.99362236, 1114: 0.99422187, 1613: 0.9849053, 700: 0.99405634, 1687: 0.98005635, 366: 0.96985346, 1434: 0.9924117, 1689: 0.9942275, 959: 0.9943071, 683: 0.9853689, 114: 0.99432737, 1403: 0.9940777, 1477: 0.9940685, 6: 0.9935314, 1088: 0.99013686, 545: 0.9810672, 510: 0.9781617, 1473: 0.9938538, 641: 0.9849613, 1116: 0.9937184, 1141: 0.98111826, 671: 0.99424666, 1100: 0.9620287, 1712: 0.97785974, 1709: 0.9825277, 1669: 0.9924017, 1362: 0.9939073, 839: 0.99420893, 957: 0.98170435, 918: 0.9786236, 1184: 0.9943006, 1545: 0.99345726, 1118: 0.9923719, 208: 0.9927977, 161: 0.97936445, 1435: 0.9936301, 606: 0.99260384, 378: 0.991441, 998: 0.99165374, 1060: 0.9941537, 636: 0.99407095, 310: 0.9808584, 540: 0.9866044, 1552: 0.9920426, 902: 0.9936021, 108: 0.9795958, 2: 0.94119453, 1486: 0.98607004, 1427: 0.99412316, 1645: 0.9793292, 514: 0.98470217, 535: 0.9917936, 1049: 0.99361694, 1541: 0.98113245, 217: 0.97758865, 1274: 0.986451, 1374: 0.989935, 971: 0.9922023, 1535: 0.9941029, 1499: 0.9928884, 1412: 0.9772654, 1586: 0.99419904, 743: 0.99383587, 1682: 0.97799224, 975: 0.99397296, 1445: 0.9940726, 586: 0.9938074, 1252: 0.9781245, 567: 0.99393106, 819: 0.99366474, 1210: 0.97800887, 763: 0.99427766, 489: 0.9941606, 254: 0.99409467, 1108: 0.6613674, 543: 0.97708434, 570: 0.9922449, 771: 0.9829686, 38: 0.9886734, 925: 0.9941115, 792: 0.9917224, 1600: 0.9938053, 399: 0.99228525, 22: 0.994115, 1564: 0.9938962, 407: 0.9938892, 916: 0.9943236, 897: 0.97773415, 356: 0.9716964, 185: 0.9942029, 127: 0.99432844, 115: 0.97800064, 1512: 0.99420714, 1018: 0.9937542, 181: 0.9943587, 602: 0.9939434, 467: 0.9938267, 132: 0.977482, 647: 0.9853791, 1424: 0.99336123, 1262: 0.9821389, 585: 0.9941749, 1690: 0.99235487, 755: 0.99126136, 938: 0.9869349, 1587: 0.9776069, 610: 0.9754925, 471: 0.9859444, 215: 0.99428105, 335: 0.9827655, 1013: 0.984065, 1404: 0.9940817, 373: 0.9941194, 1223: 0.9941274, 1216: 0.99427104, 1438: 0.99410856, 60: 0.99432653, 689: 0.98424107, 109: 0.9939879, 1720: 0.9940837, 1702: 0.9932734, 306: 0.9853065, 1322: 0.99371475, 1158: 0.9911596, 1463: 0.9918343, 433: 0.97008663, 375: 0.97111386, 465: 0.994125, 620: 0.9942321, 23: 0.9917938, 754: 0.97921914, 1521: 0.9941876, 257: 0.98484576, 1286: 0.9938783, 264: 0.99399525, 1105: 0.99385405, 195: 0.99350196, 1318: 0.9806908, 833: 0.99422765, 597: 0.9849451, 1294: 0.99139446, 481: 0.97701436, 204: 0.9802791, 737: 0.991715, 1567: 0.97622836, 531: 0.98675364, 206: 0.9816522, 1281: 0.9938775, 1430: 0.9763134, 318: 0.9939744, 1267: 0.9917101, 1460: 0.99131656, 804: 0.99410737, 699: 0.9801855, 1361: 0.98311585, 490: 0.99428564, 53: 0.9777755, 887: 0.97978115, 568: 0.9782477, 1371: 0.9744047, 811: 0.9475192, 890: 0.9838487, 1532: 0.99351066, 164: 0.98055595, 782: 0.9836627, 769: 0.99228173, 1103: 0.9941577, 598: 0.99395084, 237: 0.9643845, 1547: 0.9558161, 592: 0.99423283, 1191: 0.9919984, 1447: 0.9942597, 654: 0.9931647, 596: 0.99355996, 1608: 0.9736953, 1695: 0.9775473, 1306: 0.9940904, 962: 0.9775419, 428: 0.99311924, 712: 0.9938374, 457: 0.9800363, 46: 0.9940236, 562: 0.993846, 317: 0.9830883, 142: 0.9931163, 894: 0.9923401, 847: 0.9940975, 1125: 0.9940905, 1612: 0.987496, 96: 0.99415153, 1127: 0.99400914, 1542: 0.990931, 1227: 0.9940608, 90: 0.9787608, 1155: 0.9806358, 1516: 0.99352175, 321: 0.9941095, 1342: 0.9805464, 229: 0.98086506, 274: 0.9935737, 1285: 0.9809868, 709: 0.97444236, 1550: 0.9642271, 1211: 0.7008131, 1642: 0.98325306, 1301: 0.99425995, 593: 0.9932695, 1183: 0.9943241, 492: 0.98301977, 291: 0.9793419, 210: 0.9773552, 65: 0.9940606, 547: 0.9916578, 544: 0.97839135, 186: 0.99387854, 1525: 0.9940427, 789: 0.9759144, 1480: 0.9777348, 124: 0.9868319, 1021: 0.99197125, 1472: 0.9938319, 1694: 0.99424523, 1005: 0.9788069, 91: 0.99411327, 1429: 0.9863957, 738: 0.96102464, 1030: 0.9914283, 972: 0.98423886, 89: 0.96662736, 826: 0.97167027, 171: 0.9917983, 1075: 0.9937569, 1282: 0.9942298, 853: 0.99433917, 760: 0.9909258, 1514: 0.99161047, 932: 0.9940317, 162: 0.9911075, 880: 0.98153085, 777: 0.9944094, 1325: 0.9935086, 1616: 0.97947854, 1627: 0.9726063, 207: 0.9940409, 1206: 0.9940789, 430: 0.991441, 1566: 0.9813797, 669: 0.9930211, 762: 0.98684466, 1539: 0.9793336, 1459: 0.9941964, 151: 0.9918057, 1467: 0.98374707, 1017: 0.9938998, 1711: 0.9940858, 942: 0.9796243, 347: 0.97860783, 180: 0.9793545, 1703: 0.9940103, 1115: 0.9906543, 989: 0.9932666, 135: 0.9832917, 1387: 0.99358845, 3: 0.96556115, 1592: 0.9795228, 1292: 0.994044, 1270: 0.9931851, 1265: 0.9942926, 533: 0.99401605, 905: 0.97832173, 1649: 0.983403, 372: 0.9785089, 1305: 0.9801825, 192: 0.99376315, 988: 0.99370295, 885: 0.99218595, 860: 0.9655582, 1302: 0.987219, 1138: 0.99405473, 298: 0.99348974, 275: 0.99428105, 649: 0.98611414, 778: 0.9796964, 1528: 0.99285346, 1708: 0.985107, 434: 0.97969943, 1111: 0.992278, 1295: 0.9940042, 1574: 0.9937356, 820: 0.9939513, 947: 0.9941876, 1484: 0.99392784, 165: 0.99378127, 101: 0.99385977, 1364: 0.9701414, 715: 0.99352795, 1629: 0.9796005, 794: 0.8702132, 285: 0.99411845, 571: 0.9935575, 64: 0.9916807, 1453: 0.99176747, 1581: 0.9934546, 911: 0.98111683, 850: 0.99358517, 403: 0.99376994, 930: 0.993962, 1055: 0.9940147, 1381: 0.9863657, 420: 0.98131174, 1259: 0.99387133, 556: 0.99420965, 459: 0.98093694, 1159: 0.9944041, 870: 0.9924493, 36: 0.99420494, 1046: 0.9943311, 1218: 0.9801645, 1540: 0.9859401, 1053: 0.98556805, 1456: 0.993975, 1636: 0.9923361, 355: 0.9942762, 1025: 0.9940171, 1119: 0.9939812, 904: 0.9943692, 1568: 0.9939322, 1335: 0.98416847, 1704: 0.99438983, 1417: 0.9940189, 1040: 0.9860445, 1440: 0.99397534, 631: 0.99232703, 371: 0.99338293, 282: 0.9757991, 1144: 0.9944207, 834: 0.9934388, 697: 0.9846859, 878: 0.9320743, 1122: 0.9934569, 452: 0.9922478, 466: 0.9938257, 408: 0.97741276, 242: 0.9941103, 1042: 0.9826701, 387: 0.9758271, 1329: 0.9945702, 247: 0.9834599, 157: 0.99409866, 1078: 0.99189866, 1316: 0.9782111, 442: 0.9740084, 624: 0.9915684, 1308: 0.99380386, 99: 0.97670525, 1683: 0.99413705, 1507: 0.9941901, 913: 0.9938751, 1498: 0.9475, 652: 0.98375297, 595: 0.98589325, 296: 0.9916033, 27: 0.97684413, 299: 0.9753542, 1455: 0.97417873, 21: 0.9934896, 245: 0.99321175, 367: 0.99253476, 1610: 0.9789924, 779: 0.9802153, 517: 0.9903432, 1297: 0.93741035, 174: 0.9941444, 1143: 0.9929476, 1398: 0.9876249, 1602: 0.9939604, 1715: 0.99370295, 406: 0.96425426, 1451: 0.9940096, 169: 0.99437815, 1599: 0.9942299, 440: 0.9778896, 910: 0.9928011, 405: 0.9539968, 1553: 0.9920202, 122: 0.9943684, 178: 0.98622614, 1506: 0.99411994, 346: 0.99362516, 246: 0.98304904, 1572: 0.97980714, 1150: 0.98439515, 427: 0.99348915, 153: 0.99416935, 1607: 0.9720157, 1337: 0.9810831, 1083: 0.9920379, 1076: 0.9934621, 908: 0.99405473, 44: 0.9942029, 1527: 0.97761303, 77: 0.98023844, 1696: 0.99402905, 1001: 0.99374866, 147: 0.9616584, 1: 0.994251, 1175: 0.9923151, 1107: 0.99374723, 82: 0.9784025, 389: 0.97783047, 1326: 0.99379736, 611: 0.9941666, 1691: 0.9780546, 955: 0.97827154, 1026: 0.976173, 1353: 0.9941666, 1714: 0.9855127, 845: 0.993899, 1112: 0.9941459, 1358: 0.9941854, 482: 0.97831136, 1400: 0.98504674, 1137: 0.987107, 822: 0.99275666, 1168: 0.9943772, 859: 0.9916871, 840: 0.9933536, 1718: 0.9870275, 732: 0.99102473, 31: 0.97984034, 1045: 0.98176986, 409: 0.9940148, 973: 0.9924787, 1120: 0.9941744, 1686: 0.9881151, 1303: 0.9828829, 453: 0.99396133, 499: 0.9938514, 680: 0.98667914, 95: 0.9854961, 863: 0.99425066, 725: 0.9858906, 308: 0.98566854, 844: 0.9828099, 107: 0.97948986, 1071: 0.9932586, 1132: 0.9940101, 519: 0.9913367, 550: 0.9936792, 666: 0.993447, 1336: 0.9791308, 650: 0.9943164, 1289: 0.9937139, 1271: 0.9942198, 1047: 0.99430877, 1123: 0.9840644, 1716: 0.9941666, 444: 0.9852711, 731: 0.9923577, 212: 0.9771862, 594: 0.98432064, 872: 0.9810627, 145: 0.99318004, 477: 0.98688924, 268: 0.9931028, 59: 0.99418074, 1713: 0.99178255, 625: 0.98250556, 179: 0.9939036, 1491: 0.9936604, 739: 0.9942438, 609: 0.9936466, 218: 0.9937866, 723: 0.9937443, 431: 0.9936778, 472: 0.9813378, 1443: 0.98496705, 263: 0.9821507, 1029: 0.9939418, 980: 0.94959563, 222: 0.9697225, 1003: 0.99407, 1523: 0.9852905, 1307: 0.98243386, 892: 0.9793291, 812: 0.9936836, 413: 0.9924827, 572: 0.9942725, 1069: 0.99405503, 1419: 0.9940216, 915: 0.9919837, 163: 0.9941356, 1197: 0.9937018, 326: 0.97928953, 858: 0.985658, 1239: 0.9940738, 131: 0.9853758, 358: 0.993618, 48: 0.99406564, 1722: 0.99403447, 98: 0.9939966, 333: 0.9938314, 869: 0.99178195, 29: 0.9936026, 698: 0.9942509, 1367: 0.9942427, 526: 0.96976376, 1109: 0.9847409, 1034: 0.9940691, 985: 0.9747546, 1130: 0.9799197, 1129: 0.9921349, 899: 0.9770402, 658: 0.9779571, 97: 0.9798282, 787: 0.970769, 1618: 0.99151295, 485: 0.9834873, 1681: 0.9812243, 1350: 0.9737907, 441: 0.9773008, 1196: 0.9939213, 110: 0.99233717, 1556: 0.9926103, 532: 0.9941413, 991: 0.9941251, 634: 0.99364626, 1483: 0.9871387, 461: 0.9861566, 677: 0.98031384, 886: 0.993895, 446: 0.99421954, 646: 0.9942266, 1152: 0.9914853, 1464: 0.99138546, 682: 0.9942806, 202: 0.9542011, 155: 0.9905365, 172: 0.9938793, 513: 0.9924038, 200: 0.9913901, 1121: 0.9849572, 1628: 0.978799, 1375: 0.9865463, 744: 0.9939283, 1024: 0.9745198, 655: 0.9922746, 758: 0.9914219, 205: 0.99368745, 47: 0.9935493, 382: 0.9826628, 1634: 0.99334455, 1351: 0.9942022, 718: 0.97821313, 1095: 0.99321365, 1508: 0.9939002, 1091: 0.9941837, 601: 0.9934463, 1588: 0.99374604, 1432: 0.99416864, 868: 0.9919993, 566: 0.9940826, 1015: 0.9815105, 1110: 0.9943211, 922: 0.9925494, 1468: 0.9944253, 1662: 0.9942773, 58: 0.9941017, 1090: 0.99428815, 1249: 0.9923057, 719: 0.9836754, 1373: 0.99378794, 1157: 0.991819, 1234: 0.99429446, 1237: 0.9937716, 936: 0.74730897, 548: 0.99405587, 1343: 0.9940257, 1061: 0.9935138, 1725: 0.9920671, 1277: 0.98279977, 78: 0.98565835, 302: 0.994044, 1011: 0.9915679, 284: 0.9937237, 119: 0.9941347, 518: 0.9768034, 1149: 0.98105407, 823: 0.98530376, 1363: 0.9730566, 775: 0.98146373, 133: 0.97944665, 287: 0.98302877, 424: 0.963871, 1555: 0.98580104, 51: 0.9941702, 1388: 0.99392575, 1349: 0.98422074, 927: 0.9937391, 1006: 0.99421096, 139: 0.99423486, 1442: 0.98256874, 230: 0.9799992, 104: 0.9941234, 508: 0.9888362, 1314: 0.99418783, 1675: 0.9936805, 343: 0.9941836, 883: 0.9939686, 1139: 0.9801712, 1243: 0.9760701, 502: 0.98138064, 1101: 0.97843313, 1585: 0.9842138, 1058: 0.99409986, 1726: 0.9749519, 244: 0.97616005, 941: 0.9943404, 1671: 0.974147, 278: 0.9921313, 711: 0.99422425, 1089: 0.9676105, 484: 0.9816372, 943: 0.99137247, 1096: 0.9941916, 856: 0.9940739, 1663: 0.99159086, 111: 0.9860686, 1039: 0.9916482, 710: 0.9830768, 1012: 0.9941506, 565: 0.96458423, 305: 0.98291403, 1392: 0.99407923, 177: 0.98068994, 1515: 0.9826757, 626: 0.9741712, 1457: 0.9942232, 232: 0.9824554, 817: 0.99403304, 1309: 0.97956204, 672: 0.9943334, 251: 0.99335456, 1530: 0.96698326, 241: 0.9778356, 63: 0.9943487, 199: 0.99271387, 622: 0.9941241, 209: 0.9920328, 1052: 0.99399155, 1082: 0.9867675, 1667: 0.9921731, 1266: 0.99201596, 216: 0.9792038, 965: 0.9920054, 39: 0.9939115, 1357: 0.9927642, 1461: 0.97426003, 1263: 0.99414283, 790: 0.99345595, 992: 0.9801223, 357: 0.98312896, 470: 0.97860456, 52: 0.9731066, 884: 0.97878784, 515: 0.9941884, 695: 0.9815026, 454: 0.98078763, 1561: 0.9936033, 855: 0.9624199}, 'google/gemini-1.5-flash-002': {182: 0.9914929, 825: 0.99156123, 1240: 0.9773735, 505: 0.9812293, 1482: 0.9912986, 1549: 0.98745024, 842: 0.980551, 1605: 0.98814154, 386: 0.97547174, 1622: 0.9786007, 1182: 0.99157274, 1212: 0.99072486, 487: 0.9913272, 148: 0.97636956, 661: 0.9914658, 950: 0.99135244, 393: 0.9913031, 1056: 0.99119264, 259: 0.98079485, 1415: 0.97913307, 523: 0.99148554, 353: 0.99126536, 1391: 0.9913566, 874: 0.99156815, 12: 0.99148375, 1700: 0.97867304, 527: 0.9758589, 496: 0.9791461, 483: 0.99109846, 365: 0.9914494, 674: 0.98172873, 93: 0.98794854, 729: 0.97648346, 370: 0.99123865, 714: 0.98726916, 898: 0.9820343, 1344: 0.9914704, 831: 0.99140406, 1723: 0.97851324, 203: 0.97889197, 345: 0.9760079, 67: 0.9770796, 1383: 0.97717243, 319: 0.9822227, 852: 0.9788776, 1311: 0.9767759, 45: 0.9865385, 582: 0.9776383, 791: 0.977182, 781: 0.9914819, 221: 0.99093443, 316: 0.97643524, 857: 0.99119735, 578: 0.99057746, 137: 0.9914247, 639: 0.9763941, 1257: 0.9913653, 390: 0.9914982, 5: 0.9915468, 628: 0.9914669, 1402: 0.98229825, 806: 0.99136984, 243: 0.9915202, 720: 0.98708564, 919: 0.99110174, 491: 0.99136215, 768: 0.97727716, 35: 0.97667456, 462: 0.9778882, 414: 0.9838321, 475: 0.9912208, 301: 0.9784685, 923: 0.9780974, 815: 0.99146515, 558: 0.9913043, 1458: 0.98785233, 25: 0.97753394, 810: 0.9912909, 557: 0.9872224, 1368: 0.9915256, 369: 0.9774785, 1470: 0.97730494, 57: 0.97806466, 152: 0.99112797, 307: 0.991217, 1598: 0.9910738, 1380: 0.9774957, 159: 0.9914541, 1382: 0.97646844, 509: 0.9913673, 1665: 0.97705406, 615: 0.9772536, 404: 0.9802346, 396: 0.99111485, 1423: 0.97710776, 1179: 0.99134773, 224: 0.99150825, 1084: 0.9913441, 1359: 0.97672653, 660: 0.9768113, 1099: 0.98036444, 590: 0.99120444, 290: 0.99127144, 1548: 0.9913299, 1420: 0.9912178, 1410: 0.9800236, 967: 0.9912567, 979: 0.9789048, 1421: 0.9783667, 512: 0.9883277, 198: 0.977918, 102: 0.99118817, 479: 0.99137455, 678: 0.98872674, 970: 0.9779319, 1135: 0.99134904, 1583: 0.9913823, 1028: 0.98126423, 397: 0.9774974, 1522: 0.939319, 555: 0.9788771, 293: 0.98052096, 1504: 0.97710264, 1167: 0.975836, 1360: 0.9912909, 1469: 0.9783627, 1081: 0.99139297, 1192: 0.9914077, 538: 0.9776943, 924: 0.99139345, 394: 0.9819526, 1606: 0.99129033, 1397: 0.9778334, 105: 0.98361236, 997: 0.9770627, 144: 0.9779343, 1288: 0.9912192, 1272: 0.99131924, 100: 0.9909464, 1579: 0.9915427, 1557: 0.9910898, 564: 0.9769985, 501: 0.9780667, 613: 0.9914328, 757: 0.99123794, 1475: 0.9914653, 865: 0.99145436, 1571: 0.99149513, 1511: 0.9912606, 785: 0.9763957, 1251: 0.97722787, 1490: 0.99131036, 1481: 0.9914069, 24: 0.99143475, 648: 0.9916751, 149: 0.991223, 1339: 0.99074465, 843: 0.98724085, 253: 0.9912839, 379: 0.9916403, 1575: 0.9801326, 272: 0.9787015, 670: 0.99052835, 1502: 0.9873503, 1657: 0.9776833, 996: 0.9912913, 702: 0.9902535, 276: 0.99123514, 1070: 0.98138016, 1462: 0.9789316, 603: 0.97801787, 588: 0.9911045, 733: 0.99131715, 220: 0.98873746, 542: 0.99138486, 1355: 0.99138993, 1352: 0.97726053, 197: 0.97972345, 449: 0.96598935, 334: 0.991359, 614: 0.9869624, 451: 0.97695416, 691: 0.97770554, 681: 0.99139225, 1626: 0.9915569, 766: 0.991553, 665: 0.9788786, 616: 0.9915058, 612: 0.9769092, 154: 0.97859704, 190: 0.9912751, 15: 0.97792506, 1268: 0.9913532, 8: 0.9915165, 1296: 0.9909161, 329: 0.981726, 1611: 0.99163646, 1678: 0.9913818, 780: 0.9912698, 4: 0.9910172, 1661: 0.7585649, 1293: 0.9799168, 294: 0.9913031, 1637: 0.97711575, 1365: 0.9913986, 686: 0.97677535, 1333: 0.991495, 1474: 0.9882762, 759: 0.99151903, 1584: 0.99131644, 504: 0.9908297, 395: 0.97522503, 1573: 0.9760942, 240: 0.9770278, 92: 0.99138653, 85: 0.9914097, 1146: 0.98797476, 735: 0.9913374, 1140: 0.97727454, 528: 0.99140376, 1510: 0.9776619, 495: 0.987496, 574: 0.99135345, 627: 0.9876835, 261: 0.97650415, 1298: 0.9915975, 1232: 0.9875559, 1648: 0.9913599, 821: 0.9910322, 94: 0.9812856, 1495: 0.99146116, 437: 0.99097717, 280: 0.9787694, 120: 0.9915599, 1597: 0.9910846, 520: 0.97774553, 42: 0.99151516, 498: 0.9915332, 1633: 0.9914586, 1092: 0.9785694, 835: 0.9808457, 1043: 0.99153274, 1181: 0.97715396, 300: 0.99161255, 920: 0.9770107, 86: 0.99111664, 1569: 0.98864436, 1476: 0.9912088, 1166: 0.9797696, 1016: 0.977599, 79: 0.99146867, 752: 0.9913394, 986: 0.9781683, 1399: 0.99131536, 1496: 0.9781521, 516: 0.9801214, 1580: 0.9790285, 75: 0.99145234, 969: 0.9879538, 41: 0.82880926, 158: 0.99148303, 1596: 0.9777519, 138: 0.9760113, 832: 0.9915422, 645: 0.97663707, 252: 0.9766926, 724: 0.99135596, 561: 0.9912844, 337: 0.98749346, 1176: 0.9767619, 960: 0.9908406, 1719: 0.9767591, 1591: 0.99156415, 61: 0.9914689, 1142: 0.99134046, 1169: 0.9774473, 1331: 0.9915372, 1465: 0.9910199, 539: 0.97755444, 1631: 0.97860754, 312: 0.9915131, 415: 0.9914574, 747: 0.9913748, 953: 0.9913045, 50: 0.9915776, 1638: 0.982052, 1699: 0.9886868, 1407: 0.967924, 1560: 0.98757184, 340: 0.9877346, 608: 0.99134314, 524: 0.99117297, 638: 0.98725015, 213: 0.9916368, 1519: 0.9914165, 1356: 0.97572, 889: 0.99128854, 304: 0.991359, 1276: 0.978613, 659: 0.99140924, 801: 0.9770522, 796: 0.9885539, 1093: 0.9913598, 425: 0.97957313, 876: 0.9758419, 381: 0.991397, 106: 0.97794217, 128: 0.9914259, 1705: 0.9786547, 1098: 0.99118704, 829: 0.97687256, 788: 0.9872715, 248: 0.9879061, 34: 0.99137247, 632: 0.9914888, 1698: 0.9884043, 9: 0.991248, 418: 0.9910926, 40: 0.9912287, 604: 0.9782713, 1235: 0.9765315, 577: 0.9915036, 1666: 0.97546273, 1245: 0.9779287, 1673: 0.9802783, 1684: 0.9876699, 68: 0.99149597, 629: 0.9913902, 11: 0.9780766, 1394: 0.5148876, 1582: 0.97671264, 1471: 0.9911159, 384: 0.99142504, 987: 0.9764281, 54: 0.9859445, 944: 0.9764073, 1697: 0.991618, 809: 0.97644126, 675: 0.98068607, 1219: 0.98787946, 309: 0.97716254, 1048: 0.98804504, 1051: 0.99126315, 1204: 0.99129105, 436: 0.9913999, 643: 0.9912581, 981: 0.9780146, 827: 0.9795115, 1377: 0.99147546, 1173: 0.9915803, 551: 0.99148166, 1073: 0.9773046, 412: 0.9769627, 1097: 0.99085486, 363: 0.991211, 322: 0.97709763, 968: 0.99112636, 907: 0.99113727, 331: 0.991276, 1086: 0.98166454, 507: 0.9832992, 940: 0.97827756, 1536: 0.97637993, 828: 0.99131036, 786: 0.97474766, 1444: 0.97741127, 534: 0.9914213, 297: 0.99127614, 635: 0.9911464, 581: 0.99118716, 1258: 0.98621494, 1604: 0.99142224, 136: 0.97665375, 939: 0.9886099, 1500: 0.9914819, 269: 0.9913857, 288: 0.9768084, 1224: 0.9874384, 1493: 0.9862601, 1340: 0.99135864, 260: 0.99137115, 362: 0.9913795, 722: 0.97642356, 1248: 0.99149674, 767: 0.99135804, 866: 0.9811731, 875: 0.9830147, 756: 0.991437, 706: 0.97684324, 1376: 0.9913995, 49: 0.97769165, 1595: 0.97974133, 935: 0.9779258, 984: 0.99041814, 679: 0.99131083, 188: 0.9914795, 1186: 0.9914641, 848: 0.97698224, 1685: 0.9915109, 1724: 0.991004, 1414: 0.98946255, 1354: 0.9882685, 281: 0.9912384, 522: 0.99148905, 1677: 0.978006, 103: 0.99154925, 456: 0.97688955, 644: 0.97436655, 1228: 0.9766767, 895: 0.97366536, 541: 0.99155915, 1128: 0.9915138, 1323: 0.9915719, 830: 0.98761916, 1554: 0.99121475, 1020: 0.99151224, 1603: 0.9770394, 1538: 0.9915976, 377: 0.99127966, 473: 0.97684526, 398: 0.9773408, 419: 0.9912674, 129: 0.98704207, 1156: 0.979576, 1275: 0.9813292, 360: 0.9915417, 751: 0.98626816, 1106: 0.99141335, 1437: 0.99135584, 673: 0.98059535, 1578: 0.97734135, 891: 0.9814688, 599: 0.9772769, 351: 0.97724086, 882: 0.9773232, 1036: 0.99126184, 1721: 0.97713953, 1134: 0.9815502, 1153: 0.9913812, 1074: 0.9915371, 901: 0.98179746, 17: 0.9912315, 286: 0.99142754, 344: 0.97635084, 359: 0.97705907, 749: 0.9797559, 348: 0.9812408, 1446: 0.97849303, 249: 0.9914083, 914: 0.97692513, 1347: 0.99119043, 1231: 0.9878829, 929: 0.9776635, 864: 0.9774703, 1190: 0.991573, 7: 0.9782138, 1198: 0.9911204, 851: 0.97963023, 1384: 0.9883696, 201: 0.97687745, 1450: 0.9773676, 480: 0.97754955, 1113: 0.9917128, 1077: 0.9910137, 867: 0.99086, 18: 0.97690284, 1131: 0.97719187, 1619: 0.98228997, 1346: 0.9912335, 862: 0.9771549, 1050: 0.9913248, 74: 0.9798278, 770: 0.9877774, 1085: 0.99157625, 982: 0.9915399, 170: 0.99135256, 464: 0.99145925, 696: 0.9909326, 1544: 0.98821694, 223: 0.97943485, 1038: 0.99141055, 1280: 0.97547567, 1366: 0.98019904, 1479: 0.9767999, 974: 0.9777094, 83: 0.99142975, 814: 0.9839753, 1433: 0.97727066, 1203: 0.9912588, 270: 0.9911999, 1054: 0.99122506, 1624: 0.991458, 383: 0.97706956, 1385: 0.98820925, 1505: 0.99156195, 1485: 0.979992, 1080: 0.98675704, 1023: 0.9768287, 20: 0.99141407, 1067: 0.99139494, 385: 0.9913173, 332: 0.977095, 903: 0.9915978, 324: 0.990923, 227: 0.9915799, 1408: 0.97783196, 1389: 0.9773417, 1488: 0.9913148, 439: 0.98566806, 361: 0.97689706, 1654: 0.978403, 753: 0.99128926, 1425: 0.9915418, 990: 0.99116933, 554: 0.99132395, 909: 0.9866088, 1180: 0.9915182, 888: 0.9915153, 958: 0.9875059, 530: 0.9780608, 1441: 0.99143887, 469: 0.9907453, 1233: 0.97834784, 1215: 0.9773284, 368: 0.9877093, 1520: 0.9881728, 1570: 0.9913769, 1124: 0.9778657, 560: 0.97584355, 928: 0.97982717, 266: 0.97646683, 1236: 0.9777779, 460: 0.9806188, 1546: 0.991442, 500: 0.99151176, 1133: 0.99099475, 1031: 0.99101603, 325: 0.97933424, 802: 0.9758044, 476: 0.99144894, 730: 0.9911651, 250: 0.97678113, 765: 0.9912918, 900: 0.97675836, 421: 0.991299, 685: 0.978965, 70: 0.9812423, 1247: 0.991323, 799: 0.97553545, 16: 0.976004, 1396: 0.99112844, 211: 0.99137646, 113: 0.9914983, 87: 0.9770025, 1037: 0.9874006, 1170: 0.9912135, 1014: 0.9762574, 80: 0.9914465, 1655: 0.9799801, 1533: 0.9913174, 1422: 0.98768616, 1162: 0.9866268, 978: 0.99137783, 1674: 0.9914852, 1154: 0.99116266, 748: 0.97717494, 1526: 0.9914004, 703: 0.991359, 349: 0.9914724, 315: 0.99096245, 1321: 0.9915696, 289: 0.9913282, 1658: 0.98596746, 295: 0.9883018, 1348: 0.9912704, 1284: 0.99139506, 1379: 0.9913292, 1225: 0.9881067, 400: 0.9780669, 1660: 0.97726256, 1220: 0.99142295, 1395: 0.9878825, 1701: 0.9915187, 684: 0.9795655, 553: 0.97906756, 62: 0.9779628, 1283: 0.98710084, 313: 0.97648627, 262: 0.9875474, 1200: 0.9914982, 69: 0.99152935, 1577: 0.9821468, 1253: 0.9800867, 854: 0.97956264, 734: 0.9687658, 66: 0.9911246, 1614: 0.9763108, 708: 0.97667205, 559: 0.9786203, 1213: 0.9786726, 966: 0.9915182, 795: 0.97910726, 116: 0.98830366, 303: 0.9867431, 1632: 0.9868215, 563: 0.97861457, 374: 0.99162525, 402: 0.97790647, 10: 0.9773702, 1209: 0.9913703, 793: 0.9915188, 474: 0.99141085, 896: 0.9777454, 1242: 0.9912088, 271: 0.9913504, 589: 0.9771065, 1217: 0.9909677, 417: 0.9912786, 497: 0.9761578, 1639: 0.977243, 656: 0.99145, 196: 0.991514, 653: 0.97708136, 1222: 0.99127746, 118: 0.98137915, 994: 0.97721446, 949: 0.9778592, 912: 0.9883083, 0: 0.9915503, 1452: 0.98471653, 1492: 0.97398823, 130: 0.99131423, 713: 0.5178585, 1593: 0.98089373, 1063: 0.9914409, 1334: 0.9910931, 1199: 0.9915039, 1717: 0.9914984, 391: 0.9915092, 1620: 0.9915565, 1411: 0.97402745, 701: 0.99145573, 1478: 0.9763739, 704: 0.99167526, 125: 0.97671616, 1551: 0.99112904, 1019: 0.976025, 273: 0.99133474, 1529: 0.99134845, 1559: 0.97442967, 447: 0.99126947, 236: 0.9912169, 956: 0.9769728, 81: 0.9768603, 761: 0.97654223, 600: 0.97644174, 1185: 0.99095553, 235: 0.9744881, 1656: 0.9786704, 1406: 0.9913174, 1647: 0.97659326, 468: 0.9915978, 28: 0.9764925, 1672: 0.9909105, 1589: 0.99149126, 1250: 0.97888213, 1707: 0.9913549, 350: 0.9775544, 976: 0.97956103, 740: 0.9774774, 1194: 0.9914231, 1454: 0.99136317, 1693: 0.9916196, 1022: 0.9913584, 871: 0.99138135, 1537: 0.98780835, 1372: 0.9914124, 401: 0.9911481, 255: 0.9914619, 977: 0.97782, 175: 0.9775189, 705: 0.9766938, 964: 0.98643494, 797: 0.9775015, 380: 0.97578305, 1386: 0.97664446, 1007: 0.9810936, 1205: 0.9912314, 234: 0.991532, 584: 0.9914643, 1680: 0.9914874, 1230: 0.99089336, 1041: 0.99117893, 426: 0.9914607, 1032: 0.9777679, 1065: 0.9915764, 277: 0.9755594, 1164: 0.9833709, 736: 0.99083686, 173: 0.991351, 1576: 0.97746265, 906: 0.9910488, 1256: 0.50868684, 963: 0.99146396, 587: 0.9799446, 26: 0.99150896, 774: 0.9771572, 150: 0.9914792, 651: 0.9915147, 1405: 0.9782567, 1174: 0.991343, 926: 0.9914432, 1114: 0.9913476, 1613: 0.9791919, 700: 0.99110186, 1687: 0.9742702, 366: 0.97807443, 1434: 0.9844707, 1689: 0.9913128, 959: 0.99132955, 683: 0.9828761, 114: 0.9915217, 1403: 0.99138016, 1477: 0.9914097, 6: 0.99098295, 1088: 0.99156135, 545: 0.9798034, 510: 0.9777263, 1473: 0.991168, 641: 0.98112893, 1116: 0.99122286, 1141: 0.97952694, 671: 0.99137336, 1100: 0.9773809, 1712: 0.9766051, 1709: 0.97551095, 1669: 0.9880404, 1362: 0.99125856, 839: 0.991527, 957: 0.9772077, 918: 0.9783505, 1184: 0.9911617, 1545: 0.9914106, 1118: 0.98686975, 208: 0.9913839, 161: 0.9773071, 1435: 0.9912457, 606: 0.9915667, 378: 0.9870978, 998: 0.9881125, 1060: 0.99143535, 636: 0.9912565, 310: 0.9782491, 540: 0.97753805, 1552: 0.98807305, 902: 0.99137294, 108: 0.97686756, 2: 0.97638434, 1486: 0.9817331, 1427: 0.99119556, 1645: 0.9759424, 514: 0.97670287, 535: 0.987986, 1049: 0.9900407, 1541: 0.977724, 217: 0.9753551, 1274: 0.98301667, 1374: 0.9869578, 971: 0.99145526, 1535: 0.9915712, 1499: 0.97057265, 1412: 0.9769314, 1586: 0.9915283, 743: 0.99154186, 1682: 0.97581744, 975: 0.99130857, 1445: 0.99145645, 586: 0.99149925, 1252: 0.97625446, 567: 0.9910144, 819: 0.9892898, 1210: 0.9772205, 763: 0.9917744, 489: 0.9911942, 254: 0.9916963, 1108: 0.5129771, 543: 0.9770558, 570: 0.98745817, 771: 0.981461, 38: 0.9828584, 925: 0.99151963, 792: 0.98807275, 1600: 0.99092627, 399: 0.98760265, 22: 0.99140817, 1564: 0.9915263, 407: 0.9911355, 916: 0.9912815, 897: 0.9764439, 356: 0.9755486, 185: 0.991434, 127: 0.9916293, 115: 0.9769821, 1512: 0.991359, 1018: 0.99142975, 181: 0.9914153, 602: 0.99096054, 467: 0.9914643, 132: 0.97718346, 647: 0.9783171, 1424: 0.99127626, 1262: 0.9777231, 585: 0.9773892, 1690: 0.98890173, 755: 0.9867279, 938: 0.9783638, 1587: 0.97580075, 610: 0.9779114, 471: 0.98032135, 215: 0.99145645, 335: 0.9772296, 1013: 0.9816772, 1404: 0.99140453, 373: 0.9751584, 1223: 0.9914376, 1216: 0.99143606, 1438: 0.99145484, 60: 0.9913317, 689: 0.97965527, 109: 0.9912515, 1720: 0.99162465, 1702: 0.9913829, 306: 0.9783698, 1322: 0.99099755, 1158: 0.98658967, 1463: 0.9884809, 433: 0.9767621, 375: 0.97734785, 465: 0.9914261, 620: 0.9912616, 23: 0.9876815, 754: 0.97729367, 1521: 0.9916313, 257: 0.9816319, 1286: 0.99072295, 264: 0.99141276, 1105: 0.99119055, 195: 0.99128693, 1318: 0.9782954, 833: 0.99161935, 597: 0.97885555, 1294: 0.9871711, 481: 0.9772331, 204: 0.9778401, 737: 0.98768926, 1567: 0.9765347, 531: 0.98259175, 206: 0.97932684, 1281: 0.99133974, 1430: 0.9780808, 318: 0.99150485, 1267: 0.98748624, 1460: 0.9859446, 804: 0.9914034, 699: 0.9776693, 1361: 0.97847056, 490: 0.9916338, 53: 0.976586, 887: 0.9774122, 568: 0.9770757, 1371: 0.9775185, 811: 0.9773716, 890: 0.9804715, 1532: 0.9910847, 164: 0.9802069, 782: 0.9791063, 769: 0.9877844, 1103: 0.9915091, 598: 0.99142116, 237: 0.97694653, 1547: 0.9761212, 592: 0.99152386, 1191: 0.9863094, 1447: 0.9914328, 654: 0.9912298, 596: 0.9915786, 1608: 0.97722334, 1695: 0.9766053, 1306: 0.99124104, 962: 0.9913434, 428: 0.99128777, 712: 0.9901182, 457: 0.977866, 46: 0.9915509, 562: 0.9913965, 317: 0.9787759, 142: 0.99134237, 894: 0.9875875, 847: 0.99154764, 1125: 0.99104416, 1612: 0.98161006, 96: 0.991469, 1127: 0.9914335, 1542: 0.98491645, 1227: 0.9913653, 90: 0.9795552, 1155: 0.97756076, 1516: 0.9913765, 321: 0.99133885, 1342: 0.9782155, 229: 0.97650695, 274: 0.99078065, 1285: 0.980093, 709: 0.9815346, 1550: 0.9796831, 1211: 0.51333076, 1642: 0.9778707, 1301: 0.991514, 593: 0.99141777, 1183: 0.99178046, 492: 0.9764732, 291: 0.97660655, 210: 0.9769453, 65: 0.99141675, 547: 0.9881963, 544: 0.9770393, 186: 0.9911396, 1525: 0.99146324, 789: 0.9744824, 1480: 0.9821426, 124: 0.9778733, 1021: 0.9882464, 1472: 0.99145186, 1694: 0.991264, 1005: 0.97657436, 91: 0.99158293, 1429: 0.98034704, 738: 0.97725713, 1030: 0.9873542, 972: 0.98116577, 89: 0.9769934, 826: 0.9781854, 171: 0.98815316, 1075: 0.9909232, 1282: 0.99141556, 853: 0.991321, 760: 0.98476285, 1514: 0.9879175, 932: 0.9899658, 162: 0.98784816, 880: 0.9788862, 777: 0.991319, 1325: 0.9911294, 1616: 0.976895, 1627: 0.9802335, 207: 0.99144214, 1206: 0.9914255, 430: 0.98625135, 1566: 0.9783084, 669: 0.9913994, 762: 0.97947204, 1539: 0.97697145, 1459: 0.9913201, 151: 0.9869243, 1467: 0.979939, 1017: 0.9914248, 1711: 0.9914676, 942: 0.97724, 347: 0.9768935, 180: 0.9781659, 1703: 0.9915686, 1115: 0.9834463, 989: 0.991347, 135: 0.9753665, 1387: 0.99117345, 3: 0.9772231, 1592: 0.97642446, 1292: 0.99130464, 1270: 0.99138206, 1265: 0.9913282, 533: 0.9912612, 905: 0.97740173, 1649: 0.97804946, 372: 0.9771278, 1305: 0.9775048, 192: 0.99142015, 988: 0.9912032, 885: 0.98831314, 860: 0.975355, 1302: 0.98098975, 1138: 0.99124944, 298: 0.99110085, 275: 0.9915292, 649: 0.98150426, 778: 0.9766426, 1528: 0.9906345, 1708: 0.97932714, 434: 0.98202604, 1111: 0.98717785, 1295: 0.9915036, 1574: 0.99152476, 820: 0.9915051, 947: 0.9913965, 1484: 0.99143267, 165: 0.9910095, 101: 0.9912436, 1364: 0.97859734, 715: 0.9914472, 1629: 0.9771682, 794: 0.9633479, 285: 0.9913202, 571: 0.9909638, 64: 0.9882218, 1453: 0.9868891, 1581: 0.9911032, 911: 0.9775614, 850: 0.990868, 403: 0.9913264, 930: 0.9911975, 1055: 0.9915489, 1381: 0.9831754, 420: 0.9772329, 1259: 0.991269, 556: 0.9913942, 459: 0.9806948, 1159: 0.99136156, 870: 0.98809016, 36: 0.9914375, 1046: 0.9915279, 1218: 0.9783387, 1540: 0.9808353, 1053: 0.9792381, 1456: 0.9915398, 1636: 0.9880385, 355: 0.991537, 1025: 0.990373, 1119: 0.9913862, 904: 0.9913121, 1568: 0.9914848, 1335: 0.98246014, 1704: 0.99134856, 1417: 0.99152875, 1040: 0.98143965, 1440: 0.9916517, 631: 0.99134934, 371: 0.9912793, 282: 0.97733104, 1144: 0.99133766, 834: 0.99151504, 697: 0.97720534, 878: 0.97602385, 1122: 0.99128914, 452: 0.98791236, 466: 0.9913594, 408: 0.9770657, 242: 0.99150145, 1042: 0.97848266, 387: 0.97636783, 1329: 0.9914187, 247: 0.97754943, 157: 0.99089795, 1078: 0.9882477, 1316: 0.9776732, 442: 0.97763956, 624: 0.98697114, 1308: 0.99117744, 99: 0.979619, 1683: 0.99127907, 1507: 0.99143815, 913: 0.99120635, 1498: 0.9766872, 652: 0.98031676, 595: 0.98242927, 296: 0.987874, 27: 0.9765528, 299: 0.97349924, 1455: 0.977109, 21: 0.99139845, 245: 0.99154085, 367: 0.98869777, 1610: 0.97904086, 779: 0.9763282, 517: 0.98725814, 1297: 0.97689193, 174: 0.99165255, 1143: 0.9913134, 1398: 0.9844993, 1602: 0.9913121, 1715: 0.9910772, 406: 0.9768118, 1451: 0.9914274, 169: 0.9914825, 1599: 0.99156606, 440: 0.9763317, 910: 0.991582, 405: 0.9769468, 1553: 0.9867802, 122: 0.99138826, 178: 0.97976893, 1506: 0.99139977, 346: 0.9911032, 246: 0.97643197, 1572: 0.9766357, 1150: 0.97713155, 427: 0.9912998, 153: 0.9915555, 1607: 0.97748077, 1337: 0.9822626, 1083: 0.9876764, 1076: 0.991565, 908: 0.99155384, 44: 0.9914731, 1527: 0.9769513, 77: 0.97819555, 1696: 0.9914273, 1001: 0.9914552, 147: 0.9759753, 1: 0.99148035, 1175: 0.98852986, 1107: 0.99145156, 82: 0.9778211, 389: 0.9765079, 1326: 0.9912043, 611: 0.99153155, 1691: 0.9754626, 955: 0.97598934, 1026: 0.97895014, 1353: 0.99171716, 1714: 0.98076886, 845: 0.9914169, 1112: 0.9915058, 1358: 0.99148995, 482: 0.9768712, 1400: 0.98269695, 1137: 0.9817591, 822: 0.991293, 1168: 0.99144226, 859: 0.9880062, 840: 0.9908434, 1718: 0.9771259, 732: 0.984584, 31: 0.9781869, 1045: 0.98076814, 409: 0.99156284, 973: 0.98764646, 1120: 0.99141073, 1686: 0.98761624, 1303: 0.97824943, 453: 0.99155784, 499: 0.9911403, 680: 0.97976285, 95: 0.9820742, 863: 0.9911479, 725: 0.9798885, 308: 0.9790429, 844: 0.98139304, 107: 0.97956455, 1071: 0.99109226, 1132: 0.9915332, 519: 0.9872004, 550: 0.99147063, 666: 0.99144906, 1336: 0.97622764, 650: 0.9913965, 1289: 0.9914034, 1271: 0.99142104, 1047: 0.99129045, 1123: 0.98049104, 1716: 0.991569, 444: 0.9804613, 731: 0.98816687, 212: 0.97632194, 594: 0.9759917, 872: 0.9770642, 145: 0.99147624, 477: 0.9813524, 268: 0.99136424, 59: 0.99137866, 1713: 0.98781884, 625: 0.9824258, 179: 0.99138474, 1491: 0.9912554, 739: 0.9914273, 609: 0.9908154, 218: 0.9912254, 723: 0.9908304, 431: 0.991438, 472: 0.9782325, 1443: 0.9796886, 263: 0.97907776, 1029: 0.99127626, 980: 0.9695124, 222: 0.97561616, 1003: 0.9911375, 1523: 0.9829023, 1307: 0.98008186, 892: 0.9788848, 812: 0.99094766, 413: 0.9880134, 572: 0.9914205, 1069: 0.9913918, 1419: 0.9916256, 915: 0.98747987, 163: 0.9915126, 1197: 0.9915598, 326: 0.97646254, 858: 0.9829164, 1239: 0.9916881, 131: 0.9791846, 358: 0.9911357, 48: 0.9914483, 1722: 0.99117696, 98: 0.9914996, 333: 0.9909769, 869: 0.98717505, 29: 0.99016935, 698: 0.9916632, 1367: 0.99151176, 526: 0.977794, 1109: 0.9812121, 1034: 0.99149674, 985: 0.9772086, 1130: 0.9782073, 1129: 0.9849103, 899: 0.9769951, 658: 0.97675055, 97: 0.9760099, 787: 0.9777508, 1618: 0.9882252, 485: 0.97963697, 1681: 0.97686213, 1350: 0.9761944, 441: 0.97621095, 1196: 0.99133635, 110: 0.9877814, 1556: 0.9850584, 532: 0.99150497, 991: 0.99152136, 634: 0.9911839, 1483: 0.97961205, 461: 0.98246336, 677: 0.98045003, 886: 0.9911409, 446: 0.99149793, 646: 0.99137294, 1152: 0.9882284, 1464: 0.9914751, 682: 0.991356, 202: 0.97663385, 155: 0.9875937, 172: 0.9912689, 513: 0.9869206, 200: 0.98777497, 1121: 0.9808318, 1628: 0.99127203, 1375: 0.97931904, 744: 0.99116373, 1024: 0.9772045, 655: 0.9917286, 758: 0.98665744, 205: 0.99096316, 47: 0.9915223, 382: 0.97656333, 1634: 0.9914083, 1351: 0.9912983, 718: 0.977192, 1095: 0.99095386, 1508: 0.9911505, 1091: 0.99143946, 601: 0.9914693, 1588: 0.9914574, 1432: 0.9913474, 868: 0.98746234, 566: 0.9915597, 1015: 0.9764715, 1110: 0.9917176, 922: 0.9919166, 1468: 0.9914498, 1662: 0.991488, 58: 0.991165, 1090: 0.99149126, 1249: 0.9913434, 719: 0.98131734, 1373: 0.9911816, 1157: 0.98835236, 1234: 0.9913147, 1237: 0.9912538, 936: 0.517292, 548: 0.9914023, 1343: 0.99108374, 1061: 0.9914619, 1725: 0.9864966, 1277: 0.978434, 78: 0.9809869, 302: 0.9914882, 1011: 0.98751163, 284: 0.991503, 119: 0.9915005, 518: 0.9769174, 1149: 0.9787087, 823: 0.98071265, 1363: 0.9782472, 775: 0.6875318, 133: 0.97675836, 287: 0.97599435, 424: 0.9777945, 1555: 0.9768832, 51: 0.9914008, 1388: 0.99108195, 1349: 0.97746927, 927: 0.9915452, 1006: 0.991273, 139: 0.9911725, 1442: 0.9801618, 230: 0.9766703, 104: 0.99147683, 508: 0.984444, 1314: 0.99148226, 1675: 0.9910614, 343: 0.9915107, 883: 0.99121875, 1139: 0.9773827, 1243: 0.9773401, 502: 0.98154336, 1101: 0.97827893, 1585: 0.9789473, 1058: 0.9912402, 1726: 0.97710097, 244: 0.9912962, 941: 0.99131703, 1671: 0.9771417, 278: 0.9886863, 711: 0.99132675, 1089: 0.9782956, 484: 0.9796086, 943: 0.9883372, 1096: 0.99139446, 856: 0.99144685, 1663: 0.98593616, 111: 0.9813483, 1039: 0.98825836, 710: 0.9775994, 1012: 0.9915869, 565: 0.9753161, 305: 0.97888845, 1392: 0.9914904, 177: 0.977461, 1515: 0.9781794, 626: 0.9765439, 1457: 0.9915746, 232: 0.97931445, 817: 0.99156356, 1309: 0.97699976, 672: 0.9913844, 251: 0.9911226, 1530: 0.9770593, 241: 0.97630286, 63: 0.991458, 199: 0.9915018, 622: 0.99147207, 209: 0.9880788, 1052: 0.9913107, 1082: 0.97788936, 1667: 0.98679745, 1266: 0.9886285, 216: 0.97786456, 965: 0.9879045, 39: 0.99127954, 1357: 0.99133426, 1461: 0.97891736, 1263: 0.99130297, 790: 0.99164903, 992: 0.977258, 357: 0.9782014, 470: 0.97621423, 52: 0.97681296, 884: 0.9771574, 515: 0.9911623, 695: 0.97809577, 454: 0.9779016, 1561: 0.9912881, 855: 0.97713065}, 'google/gemini-1.5-pro-002': {182: 0.9420948, 825: 0.94321626, 1240: 0.94144475, 505: 0.9426166, 1482: 0.94749093, 1549: 0.94345146, 842: 0.94576305, 1605: 0.94459224, 386: 0.9421023, 1622: 0.9444849, 1182: 0.94246864, 1212: 0.94973487, 487: 0.9414956, 148: 0.94492376, 661: 0.94257885, 950: 0.9485304, 393: 0.9470497, 1056: 0.94765127, 259: 0.9445284, 1415: 0.942446, 523: 0.94507027, 353: 0.9485582, 1391: 0.9481159, 874: 0.9421501, 12: 0.94268626, 1700: 0.9456107, 527: 0.94160074, 496: 0.94130045, 483: 0.94219595, 365: 0.9420453, 674: 0.94452673, 93: 0.94351035, 729: 0.94156754, 370: 0.9428678, 714: 0.945549, 898: 0.94977677, 1344: 0.9465243, 831: 0.9429229, 1723: 0.94229525, 203: 0.9450313, 345: 0.94191307, 67: 0.94167536, 1383: 0.94117415, 319: 0.9479226, 852: 0.9452775, 1311: 0.94185805, 45: 0.95143735, 582: 0.94263184, 791: 0.9419568, 781: 0.94172555, 221: 0.9429365, 316: 0.9420077, 857: 0.9474739, 578: 0.9495887, 137: 0.94552106, 639: 0.9409773, 1257: 0.942845, 390: 0.946041, 5: 0.9433129, 628: 0.9421001, 1402: 0.9482428, 806: 0.94234484, 243: 0.9425859, 720: 0.950958, 919: 0.94503564, 491: 0.9423463, 768: 0.9420151, 35: 0.94236296, 462: 0.94509774, 414: 0.9459864, 475: 0.9458047, 301: 0.94299275, 923: 0.9469601, 815: 0.94091266, 558: 0.9420824, 1458: 0.9473981, 25: 0.9410488, 810: 0.9446455, 557: 0.9429248, 1368: 0.9413564, 369: 0.9422278, 1470: 0.941073, 57: 0.9420618, 152: 0.9475458, 307: 0.94177836, 1598: 0.94661623, 1380: 0.94207555, 159: 0.94134516, 1382: 0.94195634, 509: 0.941903, 1665: 0.9419008, 615: 0.94177145, 404: 0.94570035, 396: 0.946387, 1423: 0.9416225, 1179: 0.9421636, 224: 0.9461385, 1084: 0.9422467, 1359: 0.94150203, 660: 0.9415734, 1099: 0.9473975, 590: 0.94304717, 290: 0.9423808, 1548: 0.94203395, 1420: 0.94727755, 1410: 0.94484234, 967: 0.94665927, 979: 0.9423748, 1421: 0.9454181, 512: 0.9447473, 198: 0.94772875, 102: 0.94620353, 479: 0.9423298, 678: 0.944016, 970: 0.94125336, 1135: 0.9445616, 1583: 0.9429241, 1028: 0.9448595, 397: 0.94234055, 1522: 0.9433613, 555: 0.9426982, 293: 0.9450515, 1504: 0.94102156, 1167: 0.9413713, 1360: 0.9462859, 1469: 0.9426922, 1081: 0.94209206, 1192: 0.94239926, 538: 0.9418593, 924: 0.94591993, 394: 0.94471955, 1606: 0.94179, 1397: 0.9401412, 105: 0.94165134, 997: 0.94209015, 144: 0.9433129, 1288: 0.9467915, 1272: 0.94735086, 100: 0.9465177, 1579: 0.9426617, 1557: 0.94655555, 564: 0.94348085, 501: 0.9419301, 613: 0.946738, 757: 0.9474284, 1475: 0.9426986, 865: 0.9429613, 1571: 0.94292164, 1511: 0.947773, 785: 0.9402201, 1251: 0.94137913, 1490: 0.9475177, 1481: 0.9466667, 24: 0.94253504, 648: 0.9438371, 149: 0.9460079, 1339: 0.94997156, 843: 0.94720304, 253: 0.94237334, 379: 0.94624525, 1575: 0.94907767, 272: 0.94599664, 670: 0.9467946, 1502: 0.94466925, 1657: 0.9412773, 996: 0.94189, 702: 0.9509645, 276: 0.94639546, 1070: 0.94631165, 1462: 0.9413675, 603: 0.93996686, 588: 0.9424156, 733: 0.94235206, 220: 0.94436157, 542: 0.942682, 1355: 0.94631594, 1352: 0.9413148, 197: 0.9450416, 449: 0.94079655, 334: 0.9462761, 614: 0.94540215, 451: 0.94208676, 691: 0.94473326, 681: 0.9426989, 1626: 0.94244325, 766: 0.9423458, 665: 0.94239867, 616: 0.94255334, 612: 0.94202286, 154: 0.9425765, 190: 0.94660884, 15: 0.9414394, 1268: 0.9417203, 8: 0.9410206, 1296: 0.9417229, 329: 0.94827974, 1611: 0.9425537, 1678: 0.94362795, 780: 0.94595456, 4: 0.9424621, 1661: 0.11983473, 1293: 0.9413839, 294: 0.9476084, 1637: 0.94184995, 1365: 0.94225955, 686: 0.94126, 1333: 0.94512284, 1474: 0.9449588, 759: 0.9424986, 1584: 0.94318986, 504: 0.9428679, 395: 0.9405264, 1573: 0.9401146, 240: 0.94187105, 92: 0.9428684, 85: 0.94320226, 1146: 0.94468105, 735: 0.94257104, 1140: 0.9419359, 528: 0.9493624, 1510: 0.94115007, 495: 0.94784164, 574: 0.9427188, 627: 0.9438374, 261: 0.9419232, 1298: 0.9428001, 1232: 0.9436051, 1648: 0.94181776, 821: 0.94737333, 94: 0.9437132, 1495: 0.9447584, 437: 0.94286597, 280: 0.94755256, 120: 0.94384676, 1597: 0.9456659, 520: 0.941918, 42: 0.94281447, 498: 0.9455488, 1633: 0.94212556, 1092: 0.9457556, 835: 0.9470618, 1043: 0.9427575, 1181: 0.94081146, 300: 0.94236743, 920: 0.94236976, 86: 0.94703364, 1569: 0.946206, 1476: 0.9463466, 1166: 0.94519144, 1016: 0.9426925, 79: 0.94426507, 752: 0.9484748, 986: 0.94276035, 1399: 0.9425671, 1496: 0.9411491, 516: 0.94534814, 1580: 0.94359374, 75: 0.9417258, 969: 0.9441543, 41: 0.124660425, 158: 0.94317406, 1596: 0.9419196, 138: 0.9417609, 832: 0.9494301, 645: 0.94225705, 252: 0.9423302, 724: 0.94237465, 561: 0.94227415, 337: 0.9501674, 1176: 0.94251513, 960: 0.94772846, 1719: 0.9413573, 1591: 0.9443488, 61: 0.9431992, 1142: 0.94272864, 1169: 0.94057673, 1331: 0.94294286, 1465: 0.94370896, 539: 0.94227636, 1631: 0.9453153, 312: 0.9462682, 415: 0.9424853, 747: 0.9421805, 953: 0.9433541, 50: 0.9432497, 1638: 0.9460361, 1699: 0.94759226, 1407: 0.94359523, 1560: 0.94551754, 340: 0.94433117, 608: 0.94222254, 524: 0.9474357, 638: 0.94624823, 213: 0.94664025, 1519: 0.9469861, 1356: 0.9413813, 889: 0.94237083, 304: 0.94333965, 1276: 0.94290584, 659: 0.9453624, 801: 0.94209206, 796: 0.94734955, 1093: 0.9421995, 425: 0.94246536, 876: 0.9410214, 381: 0.9416091, 106: 0.9448578, 128: 0.9420564, 1705: 0.9399346, 1098: 0.9426103, 829: 0.9412501, 788: 0.9502832, 248: 0.9437099, 34: 0.9425885, 632: 0.9425889, 1698: 0.944062, 9: 0.94351244, 418: 0.9417572, 40: 0.94272727, 604: 0.94493365, 1235: 0.9432425, 577: 0.946247, 1666: 0.9415511, 1245: 0.9476572, 1673: 0.9445958, 1684: 0.9453226, 68: 0.9419745, 629: 0.9418456, 11: 0.94282967, 1394: 0.11096405, 1582: 0.94057983, 1471: 0.9438571, 384: 0.94636863, 987: 0.94222885, 54: 0.94281393, 944: 0.94126874, 1697: 0.9409781, 809: 0.94215256, 675: 0.94262207, 1219: 0.9432605, 309: 0.94177526, 1048: 0.9478211, 1051: 0.9418828, 1204: 0.9465042, 436: 0.94595385, 643: 0.9454016, 981: 0.94796115, 827: 0.9408749, 1377: 0.94281375, 1173: 0.9431343, 551: 0.94166225, 1073: 0.9424804, 412: 0.94119424, 1097: 0.94899005, 363: 0.9420926, 322: 0.9414903, 968: 0.9470815, 907: 0.9467119, 331: 0.94667923, 1086: 0.9475014, 507: 0.9466268, 940: 0.94248825, 1536: 0.9426725, 828: 0.943822, 786: 0.9459726, 1444: 0.9416811, 534: 0.94320333, 297: 0.94817656, 635: 0.94782096, 581: 0.94147253, 1258: 0.94848764, 1604: 0.9471642, 136: 0.94197315, 939: 0.94321924, 1500: 0.9463956, 269: 0.9475032, 288: 0.941791, 1224: 0.94313055, 1493: 0.9450352, 1340: 0.9421021, 260: 0.946452, 362: 0.94620407, 722: 0.9416017, 1248: 0.94306016, 767: 0.94222313, 866: 0.9459771, 875: 0.9453418, 756: 0.9423827, 706: 0.94334006, 1376: 0.9479861, 49: 0.9450991, 1595: 0.9456915, 935: 0.942622, 984: 0.9493368, 679: 0.941855, 188: 0.94293815, 1186: 0.9414882, 848: 0.9440114, 1685: 0.94083285, 1724: 0.942001, 1414: 0.94667387, 1354: 0.94511026, 281: 0.94593996, 522: 0.9420952, 1677: 0.94571316, 103: 0.94289607, 456: 0.94169587, 644: 0.9411473, 1228: 0.94222516, 895: 0.94325274, 541: 0.9424756, 1128: 0.9453525, 1323: 0.9420033, 830: 0.9441218, 1554: 0.9481234, 1020: 0.94457287, 1603: 0.94629925, 1538: 0.94391507, 377: 0.9419431, 473: 0.94151956, 398: 0.9421793, 419: 0.94821215, 129: 0.9454746, 1156: 0.94518024, 1275: 0.9475278, 360: 0.94247055, 751: 0.9477022, 1106: 0.94328487, 1437: 0.9419925, 673: 0.94237167, 1578: 0.9419751, 891: 0.9465537, 599: 0.9422785, 351: 0.94249964, 882: 0.94454235, 1036: 0.9465954, 1721: 0.94633543, 1134: 0.9452756, 1153: 0.9420122, 1074: 0.94238985, 901: 0.9449739, 17: 0.94219923, 286: 0.9425543, 344: 0.94047964, 359: 0.9419376, 749: 0.9413877, 348: 0.94350165, 1446: 0.9442704, 249: 0.9427872, 914: 0.94143474, 1347: 0.9435618, 1231: 0.9439224, 929: 0.94111246, 864: 0.94208086, 1190: 0.9422726, 7: 0.9428606, 1198: 0.9478805, 851: 0.94719946, 1384: 0.9442696, 201: 0.94170856, 1450: 0.941105, 480: 0.94246167, 1113: 0.9458063, 1077: 0.949423, 867: 0.9481719, 18: 0.94175637, 1131: 0.94122523, 1619: 0.9476396, 1346: 0.9427525, 862: 0.9422934, 1050: 0.94763273, 74: 0.9460302, 770: 0.9437678, 1085: 0.9464548, 982: 0.94329286, 170: 0.9450922, 464: 0.9415288, 696: 0.9476971, 1544: 0.94307977, 223: 0.94433767, 1038: 0.94206643, 1280: 0.94074255, 1366: 0.94459575, 1479: 0.94193834, 974: 0.94163954, 83: 0.9425109, 814: 0.94321257, 1433: 0.9425993, 1203: 0.9511346, 270: 0.942699, 1054: 0.9471057, 1624: 0.9424876, 383: 0.94222546, 1385: 0.9433028, 1505: 0.9427683, 1485: 0.94619167, 1080: 0.94486713, 1023: 0.9414234, 20: 0.9431062, 1067: 0.94187677, 385: 0.9428677, 332: 0.9418788, 903: 0.94344825, 324: 0.9417408, 227: 0.94500893, 1408: 0.94296724, 1389: 0.9425589, 1488: 0.9416035, 439: 0.9472786, 361: 0.9421905, 1654: 0.9416345, 753: 0.9419834, 1425: 0.9425038, 990: 0.94677037, 554: 0.9418109, 909: 0.9438416, 1180: 0.9429692, 888: 0.9431993, 958: 0.9479015, 530: 0.94227636, 1441: 0.9432169, 469: 0.9470793, 1233: 0.94027174, 1215: 0.9412507, 368: 0.94339204, 1520: 0.94849324, 1570: 0.9427864, 1124: 0.94302744, 560: 0.941421, 928: 0.94203436, 266: 0.94499, 1236: 0.9421495, 460: 0.94820344, 1546: 0.9418662, 500: 0.942599, 1133: 0.94296455, 1031: 0.9481791, 325: 0.94716483, 802: 0.9462226, 476: 0.94117624, 730: 0.94887197, 250: 0.9434316, 765: 0.9469759, 900: 0.94180506, 421: 0.9481295, 685: 0.9429041, 70: 0.9451357, 1247: 0.94310087, 799: 0.94058794, 16: 0.94137883, 1396: 0.9478547, 211: 0.94224274, 113: 0.9483503, 87: 0.94147205, 1037: 0.9441068, 1170: 0.9437617, 1014: 0.9426663, 80: 0.94468117, 1655: 0.94555837, 1533: 0.9422889, 1422: 0.9450202, 1162: 0.9440233, 978: 0.9411499, 1674: 0.9422419, 1154: 0.9460434, 748: 0.94096255, 1526: 0.94302636, 703: 0.9436184, 349: 0.9496871, 315: 0.9422942, 1321: 0.9420945, 289: 0.94190055, 1658: 0.94391483, 295: 0.9428432, 1348: 0.94435054, 1284: 0.9431026, 1379: 0.94225365, 1225: 0.9441304, 400: 0.9427366, 1660: 0.94179314, 1220: 0.9428898, 1395: 0.9437652, 1701: 0.94289935, 684: 0.94113064, 553: 0.9418205, 62: 0.9419225, 1283: 0.9453157, 313: 0.9423074, 262: 0.9438791, 1200: 0.94192225, 69: 0.94255835, 1577: 0.948289, 1253: 0.9416483, 854: 0.9470968, 734: 0.94592565, 66: 0.94875586, 1614: 0.9415575, 708: 0.9420945, 559: 0.94278926, 1213: 0.9484482, 966: 0.94195884, 795: 0.9422458, 116: 0.94549537, 303: 0.94368964, 1632: 0.94715834, 563: 0.94285285, 374: 0.94238627, 402: 0.9441777, 10: 0.9417735, 1209: 0.9419296, 793: 0.94272816, 474: 0.9425243, 896: 0.9418841, 1242: 0.9468336, 271: 0.9429353, 589: 0.941216, 1217: 0.9476991, 417: 0.9466238, 497: 0.94159704, 1639: 0.94209987, 656: 0.9413688, 196: 0.9428865, 653: 0.9418808, 1222: 0.9454289, 118: 0.9484318, 994: 0.9418053, 949: 0.9415963, 912: 0.94490534, 0: 0.94245213, 1452: 0.94227904, 1492: 0.94192946, 130: 0.9424569, 713: 0.111285195, 1593: 0.9446713, 1063: 0.94623727, 1334: 0.9464419, 1199: 0.94298047, 1717: 0.94449073, 391: 0.94254434, 1620: 0.9423419, 1411: 0.941375, 701: 0.94219977, 1478: 0.94241095, 704: 0.94248116, 125: 0.9415195, 1551: 0.9419155, 1019: 0.943845, 273: 0.9412638, 1529: 0.94319856, 1559: 0.94227076, 447: 0.94661033, 236: 0.942768, 956: 0.94137174, 81: 0.9470703, 761: 0.94242024, 600: 0.9417616, 1185: 0.94730806, 235: 0.94214875, 1656: 0.9409911, 1406: 0.9435717, 1647: 0.9421132, 468: 0.9417848, 28: 0.9414767, 1672: 0.94843906, 1589: 0.94239676, 1250: 0.94570994, 1707: 0.9424898, 350: 0.942504, 976: 0.94332594, 740: 0.9421774, 1194: 0.94276065, 1454: 0.9413431, 1693: 0.9417232, 1022: 0.9425292, 871: 0.94250643, 1537: 0.94290847, 1372: 0.94247395, 401: 0.94221693, 255: 0.9451433, 977: 0.94667464, 175: 0.94180983, 705: 0.94078666, 964: 0.9427332, 797: 0.94254035, 380: 0.9425922, 1386: 0.9411053, 1007: 0.9461601, 1205: 0.9486959, 234: 0.94192445, 584: 0.9423501, 1680: 0.94306844, 1230: 0.9416468, 1041: 0.946719, 426: 0.9425832, 1032: 0.94303125, 1065: 0.94503576, 277: 0.94144595, 1164: 0.9469993, 736: 0.9471418, 173: 0.9447213, 1576: 0.9424812, 906: 0.946481, 1256: 0.11189872, 963: 0.9422665, 587: 0.9461765, 26: 0.94169533, 774: 0.9409479, 150: 0.9425109, 651: 0.94650215, 1405: 0.9446934, 1174: 0.94480455, 926: 0.9465521, 1114: 0.94304526, 1613: 0.94612527, 700: 0.94669235, 1687: 0.9431712, 366: 0.9416018, 1434: 0.9456853, 1689: 0.94344306, 959: 0.94281405, 683: 0.9474919, 114: 0.94232476, 1403: 0.9426737, 1477: 0.94708925, 6: 0.9494952, 1088: 0.9416574, 545: 0.9467818, 510: 0.9468489, 1473: 0.94697374, 641: 0.9463615, 1116: 0.94751906, 1141: 0.94627047, 671: 0.941395, 1100: 0.9415075, 1712: 0.94189495, 1709: 0.94037294, 1669: 0.94425994, 1362: 0.94645965, 839: 0.94694513, 957: 0.9424864, 918: 0.94136965, 1184: 0.94262093, 1545: 0.9488749, 1118: 0.9488871, 208: 0.94694555, 161: 0.940875, 1435: 0.9494934, 606: 0.9449679, 378: 0.94459677, 998: 0.94243073, 1060: 0.94165456, 636: 0.9446052, 310: 0.94217193, 540: 0.9416521, 1552: 0.94439495, 902: 0.94609576, 108: 0.94230485, 2: 0.9454729, 1486: 0.9471441, 1427: 0.94607687, 1645: 0.94052625, 514: 0.94208103, 535: 0.94272345, 1049: 0.94633484, 1541: 0.94541365, 217: 0.942167, 1274: 0.945354, 1374: 0.9477369, 971: 0.941648, 1535: 0.9425044, 1499: 0.94127625, 1412: 0.9425092, 1586: 0.94289917, 743: 0.9461706, 1682: 0.9437484, 975: 0.9429867, 1445: 0.94691724, 586: 0.94776946, 1252: 0.94181484, 567: 0.94646126, 819: 0.94287425, 1210: 0.9418772, 763: 0.942979, 489: 0.9421011, 254: 0.9431689, 1108: 0.11308045, 543: 0.94232655, 570: 0.94250953, 771: 0.9422674, 38: 0.94285667, 925: 0.945018, 792: 0.9439567, 1600: 0.9482092, 399: 0.9436258, 22: 0.9427525, 1564: 0.9424177, 407: 0.94812405, 916: 0.94304734, 897: 0.94147205, 356: 0.9413446, 185: 0.94279975, 127: 0.94348073, 115: 0.94200855, 1512: 0.9431798, 1018: 0.94625986, 181: 0.94238216, 602: 0.94506866, 467: 0.94291514, 132: 0.94188565, 647: 0.9400111, 1424: 0.94636726, 1262: 0.94088185, 585: 0.9421896, 1690: 0.9507821, 755: 0.944413, 938: 0.9406106, 1587: 0.94305265, 610: 0.94235957, 471: 0.9415277, 215: 0.9422548, 335: 0.9425146, 1013: 0.94275165, 1404: 0.94223213, 373: 0.9433185, 1223: 0.9449737, 1216: 0.94279116, 1438: 0.94226557, 60: 0.94319314, 689: 0.94164765, 109: 0.94586796, 1720: 0.94217914, 1702: 0.9438627, 306: 0.9467784, 1322: 0.9506494, 1158: 0.94798034, 1463: 0.94762385, 433: 0.94052136, 375: 0.945946, 465: 0.94237685, 620: 0.94239324, 23: 0.94405615, 754: 0.94263595, 1521: 0.9427349, 257: 0.94728005, 1286: 0.9479642, 264: 0.94691604, 1105: 0.9425147, 195: 0.947594, 1318: 0.94271296, 833: 0.9416038, 597: 0.94179577, 1294: 0.9439892, 481: 0.9419195, 204: 0.94232637, 737: 0.9445188, 1567: 0.94346505, 531: 0.9461968, 206: 0.9430841, 1281: 0.94177747, 1430: 0.941892, 318: 0.9422081, 1267: 0.9428639, 1460: 0.9419987, 804: 0.94274807, 699: 0.9428533, 1361: 0.94086623, 490: 0.94297147, 53: 0.94121236, 887: 0.94281405, 568: 0.94273365, 1371: 0.9421712, 811: 0.94185257, 890: 0.9461875, 1532: 0.94665104, 164: 0.9459274, 782: 0.9433571, 769: 0.9475469, 1103: 0.9425753, 598: 0.94402415, 237: 0.9455677, 1547: 0.9416, 592: 0.9424445, 1191: 0.9425213, 1447: 0.9427515, 654: 0.94614345, 596: 0.9421493, 1608: 0.9407795, 1695: 0.94282126, 1306: 0.94295764, 962: 0.9416721, 428: 0.94201165, 712: 0.94178796, 457: 0.9421094, 46: 0.9464577, 562: 0.94461817, 317: 0.9448315, 142: 0.9428039, 894: 0.9463659, 847: 0.9457944, 1125: 0.94438964, 1612: 0.94595855, 96: 0.94205374, 1127: 0.9420347, 1542: 0.9469431, 1227: 0.94573385, 90: 0.9473637, 1155: 0.9438372, 1516: 0.946841, 321: 0.94163126, 1342: 0.94120246, 229: 0.9405083, 274: 0.9496144, 1285: 0.9463809, 709: 0.94713223, 1550: 0.94237655, 1211: 0.11134549, 1642: 0.9451488, 1301: 0.9427083, 593: 0.94149685, 1183: 0.94536525, 492: 0.9419949, 291: 0.94171214, 210: 0.9412096, 65: 0.9469034, 547: 0.9432627, 544: 0.94187295, 186: 0.9421599, 1525: 0.94232136, 789: 0.94116294, 1480: 0.94669706, 124: 0.9410048, 1021: 0.94370323, 1472: 0.94618654, 1694: 0.9417354, 1005: 0.9402592, 91: 0.9420555, 1429: 0.94591683, 738: 0.9424186, 1030: 0.9472733, 972: 0.9477755, 89: 0.94170135, 826: 0.9420199, 171: 0.94843864, 1075: 0.948055, 1282: 0.9425562, 853: 0.9432172, 760: 0.94570214, 1514: 0.9512268, 932: 0.9420018, 162: 0.9450661, 880: 0.94222176, 777: 0.94226485, 1325: 0.9462872, 1616: 0.94179493, 1627: 0.9469035, 207: 0.9421205, 1206: 0.9419304, 430: 0.94207245, 1566: 0.9414674, 669: 0.9466033, 762: 0.9459609, 1539: 0.94287926, 1459: 0.9436149, 151: 0.9492176, 1467: 0.94648194, 1017: 0.9424917, 1711: 0.9425258, 942: 0.9424768, 347: 0.94140935, 180: 0.94351715, 1703: 0.9474464, 1115: 0.9501701, 989: 0.9424523, 135: 0.9421259, 1387: 0.9501308, 3: 0.9422818, 1592: 0.9424265, 1292: 0.9470074, 1270: 0.9416351, 1265: 0.9429132, 533: 0.94533885, 905: 0.942428, 1649: 0.9404263, 372: 0.94174683, 1305: 0.942504, 192: 0.94533074, 988: 0.9461806, 885: 0.94719994, 860: 0.9427274, 1302: 0.9420822, 1138: 0.9485382, 298: 0.947814, 275: 0.9424471, 649: 0.9430959, 778: 0.9425252, 1528: 0.94131124, 1708: 0.9455058, 434: 0.9497682, 1111: 0.9429582, 1295: 0.9464382, 1574: 0.9461998, 820: 0.94964194, 947: 0.94186443, 1484: 0.94221944, 165: 0.94307685, 101: 0.942699, 1364: 0.94254214, 715: 0.9464578, 1629: 0.9413031, 794: 0.94138116, 285: 0.9425826, 571: 0.9476135, 64: 0.9440791, 1453: 0.94397455, 1581: 0.9454023, 911: 0.94168913, 850: 0.94787997, 403: 0.9423283, 930: 0.9432398, 1055: 0.945416, 1381: 0.9474997, 420: 0.9423565, 1259: 0.9476572, 556: 0.94236773, 459: 0.9455607, 1159: 0.94334877, 870: 0.9457943, 36: 0.9428182, 1046: 0.942565, 1218: 0.9418266, 1540: 0.947319, 1053: 0.94607705, 1456: 0.9438799, 1636: 0.9452682, 355: 0.94273186, 1025: 0.94296, 1119: 0.94735974, 904: 0.943348, 1568: 0.94720995, 1335: 0.94279003, 1704: 0.9427007, 1417: 0.9422095, 1040: 0.94545245, 1440: 0.9448332, 631: 0.9413063, 371: 0.94147277, 282: 0.94198614, 1144: 0.94262516, 834: 0.94242036, 697: 0.9428484, 878: 0.94094825, 1122: 0.9457401, 452: 0.9424831, 466: 0.94296426, 408: 0.94104165, 242: 0.94729125, 1042: 0.940795, 387: 0.9415585, 1329: 0.9428843, 247: 0.94165623, 157: 0.94264114, 1078: 0.94504, 1316: 0.9416572, 442: 0.9431468, 624: 0.94482523, 1308: 0.947386, 99: 0.9464664, 1683: 0.94263065, 1507: 0.9437697, 913: 0.9486595, 1498: 0.81760585, 652: 0.94609106, 595: 0.9485135, 296: 0.94853646, 27: 0.94103414, 299: 0.94035196, 1455: 0.9418781, 21: 0.9467113, 245: 0.9425076, 367: 0.9475792, 1610: 0.94132847, 779: 0.9440581, 517: 0.9450181, 1297: 0.9408769, 174: 0.942841, 1143: 0.93974316, 1398: 0.94372827, 1602: 0.9465364, 1715: 0.9481614, 406: 0.94307256, 1451: 0.9468531, 169: 0.9421512, 1599: 0.94421625, 440: 0.9409004, 910: 0.94230944, 405: 0.947398, 1553: 0.9442358, 122: 0.9430744, 178: 0.940688, 1506: 0.9483682, 346: 0.94895744, 246: 0.9420038, 1572: 0.942013, 1150: 0.94060457, 427: 0.94567436, 153: 0.9416795, 1607: 0.941683, 1337: 0.9431149, 1083: 0.94291943, 1076: 0.9412449, 908: 0.94243044, 44: 0.94377923, 1527: 0.94098896, 77: 0.94349146, 1696: 0.9424738, 1001: 0.9468341, 147: 0.94143283, 1: 0.94272953, 1175: 0.94305223, 1107: 0.94589335, 82: 0.942023, 389: 0.94155496, 1326: 0.9479642, 611: 0.9421995, 1691: 0.9415482, 955: 0.9411209, 1026: 0.94505495, 1353: 0.94595814, 1714: 0.945864, 845: 0.94679934, 1112: 0.94229186, 1358: 0.9431185, 482: 0.9412221, 1400: 0.94632596, 1137: 0.9460631, 822: 0.9456563, 1168: 0.9425446, 859: 0.94923264, 840: 0.95141596, 1718: 0.94028026, 732: 0.94686973, 31: 0.94625175, 1045: 0.9451664, 409: 0.9420713, 973: 0.94355917, 1120: 0.9420018, 1686: 0.94398046, 1303: 0.9477923, 453: 0.9468128, 499: 0.9479903, 680: 0.9461517, 95: 0.9465799, 863: 0.94411135, 725: 0.9456064, 308: 0.9415723, 844: 0.94906723, 107: 0.946623, 1071: 0.948468, 1132: 0.94217837, 519: 0.94221985, 550: 0.9461981, 666: 0.94207996, 1336: 0.94037175, 650: 0.9429138, 1289: 0.94658375, 1271: 0.94260186, 1047: 0.94262207, 1123: 0.9456483, 1716: 0.9427827, 444: 0.94542485, 731: 0.9483147, 212: 0.9405782, 594: 0.94022566, 872: 0.94207615, 145: 0.9414997, 477: 0.94470775, 268: 0.94600004, 59: 0.9423541, 1713: 0.95041984, 625: 0.9454748, 179: 0.9451797, 1491: 0.94707704, 739: 0.94263744, 609: 0.94953823, 218: 0.94785696, 723: 0.94872975, 431: 0.9478454, 472: 0.9432444, 1443: 0.9449042, 263: 0.944815, 1029: 0.9477564, 980: 0.94254446, 222: 0.94201934, 1003: 0.9421209, 1523: 0.94493836, 1307: 0.9451286, 892: 0.94206154, 812: 0.9477972, 413: 0.94524074, 572: 0.94238776, 1069: 0.94305634, 1419: 0.942106, 915: 0.9432839, 163: 0.942688, 1197: 0.9453038, 326: 0.9418217, 858: 0.9456287, 1239: 0.9430962, 131: 0.9411803, 358: 0.94686824, 48: 0.94249827, 1722: 0.9464024, 98: 0.94207567, 333: 0.9419584, 869: 0.9440555, 29: 0.9410801, 698: 0.94302934, 1367: 0.94252276, 526: 0.94196343, 1109: 0.94726866, 1034: 0.9435422, 985: 0.94245297, 1130: 0.94103205, 1129: 0.9426411, 899: 0.94087833, 658: 0.9425972, 97: 0.9439791, 787: 0.94087005, 1618: 0.94334257, 485: 0.9469864, 1681: 0.9417187, 1350: 0.9414028, 441: 0.94208884, 1196: 0.94634867, 110: 0.942688, 1556: 0.9437493, 532: 0.9428459, 991: 0.94221216, 634: 0.94546556, 1483: 0.94537425, 461: 0.9461382, 677: 0.9400845, 886: 0.94832385, 446: 0.9424607, 646: 0.9429264, 1152: 0.94333816, 1464: 0.94271815, 682: 0.9428018, 202: 0.9415782, 155: 0.95298344, 172: 0.9427005, 513: 0.94347763, 200: 0.94638115, 1121: 0.947327, 1628: 0.9415297, 1375: 0.94577265, 744: 0.9484884, 1024: 0.9426832, 655: 0.9420069, 758: 0.94439536, 205: 0.94951165, 47: 0.9446865, 382: 0.94184464, 1634: 0.9420639, 1351: 0.9419631, 718: 0.9413218, 1095: 0.9470835, 1508: 0.9491114, 1091: 0.9411951, 601: 0.94208485, 1588: 0.9462057, 1432: 0.9428489, 868: 0.9430558, 566: 0.942567, 1015: 0.94146526, 1110: 0.9442089, 922: 0.9438075, 1468: 0.9419154, 1662: 0.94283926, 58: 0.94654536, 1090: 0.94299847, 1249: 0.9410333, 719: 0.94824374, 1373: 0.94777405, 1157: 0.9500786, 1234: 0.9437442, 1237: 0.9432183, 936: 0.11968127, 548: 0.9423688, 1343: 0.9467179, 1061: 0.9466254, 1725: 0.94368535, 1277: 0.94511527, 78: 0.94079363, 302: 0.9420734, 1011: 0.9422384, 284: 0.94263536, 119: 0.9429281, 518: 0.94147795, 1149: 0.9414688, 823: 0.94734776, 1363: 0.94200665, 775: 0.12539618, 133: 0.9423684, 287: 0.9415052, 424: 0.9405164, 1555: 0.94214654, 51: 0.94393873, 1388: 0.94307595, 1349: 0.9424877, 927: 0.94531447, 1006: 0.94200784, 139: 0.94301915, 1442: 0.94656587, 230: 0.9420532, 104: 0.94421095, 508: 0.95185363, 1314: 0.9432503, 1675: 0.950976, 343: 0.94394535, 883: 0.9421991, 1139: 0.94355196, 1243: 0.9418351, 502: 0.9467027, 1101: 0.94175696, 1585: 0.9443035, 1058: 0.94222707, 1726: 0.94179887, 244: 0.9436999, 941: 0.942358, 1671: 0.94233304, 278: 0.95104545, 711: 0.9408787, 1089: 0.9422619, 484: 0.9413355, 943: 0.94311374, 1096: 0.9426899, 856: 0.9471958, 1663: 0.9423107, 111: 0.9416444, 1039: 0.9485292, 710: 0.94200474, 1012: 0.9419233, 565: 0.9419728, 305: 0.9455085, 1392: 0.94685894, 177: 0.941945, 1515: 0.94509333, 626: 0.9419106, 1457: 0.94279253, 232: 0.94458723, 817: 0.9422603, 1309: 0.9421168, 672: 0.94255114, 251: 0.94644725, 1530: 0.94341666, 241: 0.94158804, 63: 0.9420145, 199: 0.944977, 622: 0.9428821, 209: 0.94489205, 1052: 0.94533616, 1082: 0.9454776, 1667: 0.9430122, 1266: 0.94420916, 216: 0.94172704, 965: 0.946715, 39: 0.9425038, 1357: 0.9419934, 1461: 0.9463314, 1263: 0.94527227, 790: 0.9421756, 992: 0.9416281, 357: 0.9435029, 470: 0.94166857, 52: 0.9410893, 884: 0.9421896, 515: 0.9426866, 695: 0.9416166, 454: 0.94171995, 1561: 0.94716364, 855: 0.9415031}, 'google/gemini-1.0-pro': {182: 0.9548193, 825: 0.9540809, 1240: 0.95350045, 505: 0.956118, 1482: 0.95296943, 1549: 0.9554358, 842: 0.9541432, 1605: 0.9551947, 386: 0.9542506, 1622: 0.9531856, 1182: 0.95500886, 1212: 0.9529309, 487: 0.9528084, 148: 0.9520298, 661: 0.9555392, 950: 0.9552071, 393: 0.95431256, 1056: 0.95348257, 259: 0.9548287, 1415: 0.95491594, 523: 0.95362014, 353: 0.9537291, 1391: 0.95234704, 874: 0.9531468, 12: 0.9544317, 1700: 0.9540355, 527: 0.95376897, 496: 0.95412445, 483: 0.9528241, 365: 0.9543877, 674: 0.9530837, 93: 0.9559193, 729: 0.9534953, 370: 0.9538421, 714: 0.9542048, 898: 0.9551923, 1344: 0.9555212, 831: 0.95406, 1723: 0.9544369, 203: 0.95358443, 345: 0.95436764, 67: 0.95376694, 1383: 0.9536985, 319: 0.95475507, 852: 0.95313, 1311: 0.95576274, 45: 0.9576091, 582: 0.95421773, 791: 0.95227027, 781: 0.95377743, 221: 0.9513902, 316: 0.9548109, 857: 0.9524848, 578: 0.95680237, 137: 0.9547628, 639: 0.95374894, 1257: 0.9552055, 390: 0.95318484, 5: 0.95507324, 628: 0.95420426, 1402: 0.95411533, 806: 0.9548564, 243: 0.95424646, 720: 0.9560262, 919: 0.95399153, 491: 0.9539, 768: 0.9528623, 35: 0.9535745, 462: 0.95329314, 414: 0.95588374, 475: 0.9530694, 301: 0.9547507, 923: 0.95421857, 815: 0.9533898, 558: 0.9542583, 1458: 0.9578139, 25: 0.95391834, 810: 0.95364094, 557: 0.95553726, 1368: 0.95474017, 369: 0.9542178, 1470: 0.95436275, 57: 0.9555502, 152: 0.954908, 307: 0.95181984, 1598: 0.9533408, 1380: 0.95360863, 159: 0.9530621, 1382: 0.9537936, 509: 0.9534399, 1665: 0.95275486, 615: 0.9552369, 404: 0.954276, 396: 0.9524526, 1423: 0.9546647, 1179: 0.9553848, 224: 0.9540687, 1084: 0.9552911, 1359: 0.95428216, 660: 0.9538108, 1099: 0.95351833, 590: 0.95574695, 290: 0.9541051, 1548: 0.95271415, 1420: 0.95544255, 1410: 0.9547829, 967: 0.9528482, 979: 0.95439327, 1421: 0.9537074, 512: 0.95532125, 198: 0.95335156, 102: 0.9533611, 479: 0.95237416, 678: 0.95497245, 970: 0.95407, 1135: 0.95426404, 1583: 0.954797, 1028: 0.9533885, 397: 0.95432746, 1522: 0.9543231, 555: 0.9544349, 293: 0.9540023, 1504: 0.9533979, 1167: 0.9528165, 1360: 0.953849, 1469: 0.95306516, 1081: 0.9542511, 1192: 0.9546456, 538: 0.95347315, 924: 0.954485, 394: 0.9544226, 1606: 0.9533873, 1397: 0.95373666, 105: 0.95472825, 997: 0.95372677, 144: 0.953222, 1288: 0.95303136, 1272: 0.9550852, 100: 0.95188713, 1579: 0.95478725, 1557: 0.95447296, 564: 0.9538374, 501: 0.95411634, 613: 0.9540469, 757: 0.9564092, 1475: 0.9542154, 865: 0.95485574, 1571: 0.9536703, 1511: 0.9534072, 785: 0.9543297, 1251: 0.95348877, 1490: 0.9536367, 1481: 0.95454496, 24: 0.9544732, 648: 0.95387894, 149: 0.95400697, 1339: 0.954135, 843: 0.9548324, 253: 0.9549767, 379: 0.9542073, 1575: 0.95579004, 272: 0.95386356, 670: 0.9537859, 1502: 0.9553305, 1657: 0.9537442, 996: 0.95282054, 702: 0.95658785, 276: 0.95366913, 1070: 0.95283055, 1462: 0.9547503, 603: 0.9542811, 588: 0.95569295, 733: 0.95372313, 220: 0.958905, 542: 0.9545871, 1355: 0.9528494, 1352: 0.9539105, 197: 0.953399, 449: 0.9533624, 334: 0.9538972, 614: 0.9549884, 451: 0.9558819, 691: 0.95381755, 681: 0.9553515, 1626: 0.95347226, 766: 0.9538695, 665: 0.9541686, 616: 0.95449036, 612: 0.9552488, 154: 0.95365906, 190: 0.9547944, 15: 0.95381075, 1268: 0.954735, 8: 0.95343703, 1296: 0.95440704, 329: 0.95452356, 1611: 0.95438063, 1678: 0.95477074, 780: 0.9527927, 4: 0.9522535, 1661: 0.95590746, 1293: 0.95440257, 294: 0.95341605, 1637: 0.95417655, 1365: 0.9549867, 686: 0.95320284, 1333: 0.95284057, 1474: 0.9555541, 759: 0.9539821, 1584: 0.95390606, 504: 0.954434, 395: 0.9525513, 1573: 0.95558983, 240: 0.95378023, 92: 0.9543711, 85: 0.9531916, 1146: 0.95558125, 735: 0.95509773, 1140: 0.95390695, 528: 0.95484734, 1510: 0.9527863, 495: 0.9565123, 574: 0.95457166, 627: 0.9567559, 261: 0.95385844, 1298: 0.95480746, 1232: 0.9553281, 1648: 0.9542912, 821: 0.95246047, 94: 0.9540127, 1495: 0.95264196, 437: 0.954062, 280: 0.9531833, 120: 0.95481646, 1597: 0.9531708, 520: 0.954206, 42: 0.9542282, 498: 0.9544555, 1633: 0.9543429, 1092: 0.9545038, 835: 0.9543054, 1043: 0.95444626, 1181: 0.95575345, 300: 0.9541977, 920: 0.9533655, 86: 0.95242727, 1569: 0.9574615, 1476: 0.9544646, 1166: 0.953926, 1016: 0.95239604, 79: 0.95493114, 752: 0.9552576, 986: 0.9527436, 1399: 0.95486146, 1496: 0.95513827, 516: 0.9544858, 1580: 0.95559067, 75: 0.95499843, 969: 0.95572734, 41: 0.95580006, 158: 0.95454985, 1596: 0.9539412, 138: 0.95316046, 832: 0.9574922, 645: 0.9536546, 252: 0.9541238, 724: 0.95437944, 561: 0.9547969, 337: 0.9558701, 1176: 0.95246553, 960: 0.9547829, 1719: 0.9535933, 1591: 0.9541453, 61: 0.9546237, 1142: 0.9546249, 1169: 0.95503855, 1331: 0.95524293, 1465: 0.9544282, 539: 0.9532976, 1631: 0.95389444, 312: 0.95475334, 415: 0.9543773, 747: 0.9545352, 953: 0.9542876, 50: 0.9549504, 1638: 0.95424324, 1699: 0.9584493, 1407: 0.955263, 1560: 0.95542645, 340: 0.9558177, 608: 0.9545125, 524: 0.95388764, 638: 0.9548081, 213: 0.9538128, 1519: 0.9523817, 1356: 0.95365286, 889: 0.9548901, 304: 0.95362175, 1276: 0.95300174, 659: 0.95251423, 801: 0.95420444, 796: 0.9558264, 1093: 0.9543263, 425: 0.9538334, 876: 0.9540996, 381: 0.9535423, 106: 0.95189726, 128: 0.9557342, 1705: 0.9529553, 1098: 0.9544202, 829: 0.95537186, 788: 0.9553824, 248: 0.95528936, 34: 0.9545691, 632: 0.95405644, 1698: 0.9561392, 9: 0.95350814, 418: 0.95278543, 40: 0.9546646, 604: 0.9545077, 1235: 0.9528134, 577: 0.95419043, 1666: 0.9529464, 1245: 0.95362186, 1673: 0.9547413, 1684: 0.9564837, 68: 0.9545492, 629: 0.9541613, 11: 0.95536566, 1394: 0.95700824, 1582: 0.9539985, 1471: 0.95328647, 384: 0.95442873, 987: 0.953382, 54: 0.953869, 944: 0.95478755, 1697: 0.95290655, 809: 0.9542899, 675: 0.9538925, 1219: 0.9549342, 309: 0.9536595, 1048: 0.9564443, 1051: 0.9545328, 1204: 0.95363736, 436: 0.95387983, 643: 0.9536018, 981: 0.9529914, 827: 0.95399815, 1377: 0.9537176, 1173: 0.9546526, 551: 0.95317584, 1073: 0.95335066, 412: 0.95444536, 1097: 0.95443237, 363: 0.9552548, 322: 0.95315117, 968: 0.9529849, 907: 0.95329845, 331: 0.9528188, 1086: 0.95483243, 507: 0.9550365, 940: 0.9534236, 1536: 0.95441204, 828: 0.9538425, 786: 0.9544872, 1444: 0.953836, 534: 0.95446503, 297: 0.9538925, 635: 0.95289433, 581: 0.9531768, 1258: 0.9541439, 1604: 0.95386755, 136: 0.9528593, 939: 0.95515317, 1500: 0.9547676, 269: 0.9543095, 288: 0.9550331, 1224: 0.95371246, 1493: 0.95647246, 1340: 0.9542468, 260: 0.9539369, 362: 0.9539816, 722: 0.9537245, 1248: 0.9540833, 767: 0.9533783, 866: 0.95362043, 875: 0.95334405, 756: 0.9544444, 706: 0.9545735, 1376: 0.9532787, 49: 0.9537568, 1595: 0.9546262, 935: 0.95303875, 984: 0.9543234, 679: 0.9536429, 188: 0.9550971, 1186: 0.95339346, 848: 0.9543839, 1685: 0.9543654, 1724: 0.9553803, 1414: 0.9537814, 1354: 0.9556817, 281: 0.9536743, 522: 0.9550463, 1677: 0.954202, 103: 0.9543827, 456: 0.9549331, 644: 0.95428544, 1228: 0.95285404, 895: 0.9533819, 541: 0.9535851, 1128: 0.9545718, 1323: 0.953104, 830: 0.9550947, 1554: 0.9561389, 1020: 0.9532062, 1603: 0.953822, 1538: 0.9551835, 377: 0.9534389, 473: 0.95341235, 398: 0.9556058, 419: 0.9530967, 129: 0.95400065, 1156: 0.9537616, 1275: 0.95440346, 360: 0.95401174, 751: 0.954259, 1106: 0.9543453, 1437: 0.95534265, 673: 0.95335305, 1578: 0.95369935, 891: 0.9537307, 599: 0.9536832, 351: 0.95471376, 882: 0.9526015, 1036: 0.9530523, 1721: 0.9542643, 1134: 0.95356935, 1153: 0.9542087, 1074: 0.9543415, 901: 0.9534287, 17: 0.9541347, 286: 0.9548815, 344: 0.95337105, 359: 0.9535048, 749: 0.95395106, 348: 0.9549844, 1446: 0.9550131, 249: 0.9540061, 914: 0.95459485, 1347: 0.9535746, 1231: 0.9548988, 929: 0.95379174, 864: 0.95323706, 1190: 0.95432335, 7: 0.95429426, 1198: 0.9529162, 851: 0.95540684, 1384: 0.95549774, 201: 0.9552349, 1450: 0.952794, 480: 0.95282525, 1113: 0.9538896, 1077: 0.9559184, 867: 0.95482934, 18: 0.9539653, 1131: 0.9551334, 1619: 0.9543745, 1346: 0.95525783, 862: 0.95222336, 1050: 0.9540275, 74: 0.95479494, 770: 0.95587695, 1085: 0.95447534, 982: 0.95441127, 170: 0.9540549, 464: 0.95398504, 696: 0.9531034, 1544: 0.9544995, 223: 0.953295, 1038: 0.95336574, 1280: 0.95483834, 1366: 0.9545833, 1479: 0.9553242, 974: 0.95541394, 83: 0.9548333, 814: 0.95627075, 1433: 0.9539565, 1203: 0.9541043, 270: 0.95412946, 1054: 0.9522247, 1624: 0.95447695, 383: 0.9549206, 1385: 0.9555295, 1505: 0.95333314, 1485: 0.9537128, 1080: 0.95602655, 1023: 0.95424277, 20: 0.95465064, 1067: 0.95379937, 385: 0.9549839, 332: 0.9539628, 903: 0.95516056, 324: 0.95439833, 227: 0.95522857, 1408: 0.95420694, 1389: 0.9544435, 1488: 0.9543079, 439: 0.95602816, 361: 0.953799, 1654: 0.9541091, 753: 0.953637, 1425: 0.95442224, 990: 0.9542658, 554: 0.9528228, 909: 0.95443356, 1180: 0.95502824, 888: 0.9553289, 958: 0.95616746, 530: 0.95341843, 1441: 0.95412505, 469: 0.95296764, 1233: 0.9560383, 1215: 0.95469904, 368: 0.95462435, 1520: 0.9564535, 1570: 0.9554299, 1124: 0.9531105, 560: 0.95454735, 928: 0.9538323, 266: 0.9544464, 1236: 0.95348084, 460: 0.95492864, 1546: 0.95401675, 500: 0.9554701, 1133: 0.9547531, 1031: 0.95394504, 325: 0.95371336, 802: 0.95271546, 476: 0.95407665, 730: 0.95428383, 250: 0.9526542, 765: 0.9533627, 900: 0.9528982, 421: 0.953781, 685: 0.95382625, 70: 0.95316327, 1247: 0.9539161, 799: 0.9534222, 16: 0.9527521, 1396: 0.95517147, 211: 0.95366704, 113: 0.95368004, 87: 0.9534742, 1037: 0.9562005, 1170: 0.9551269, 1014: 0.95475423, 80: 0.9538012, 1655: 0.953563, 1533: 0.9537423, 1422: 0.95579463, 1162: 0.9554025, 978: 0.95436144, 1674: 0.95424026, 1154: 0.95311767, 748: 0.95361596, 1526: 0.95509565, 703: 0.9528824, 349: 0.9545172, 315: 0.9542076, 1321: 0.95501757, 289: 0.9527241, 1658: 0.95529425, 295: 0.9548571, 1348: 0.9535541, 1284: 0.9551828, 1379: 0.9548732, 1225: 0.9553972, 400: 0.95391226, 1660: 0.9529122, 1220: 0.95485485, 1395: 0.95474756, 1701: 0.9545513, 684: 0.9552055, 553: 0.95215, 62: 0.952837, 1283: 0.95523834, 313: 0.9539141, 262: 0.95702463, 1200: 0.95453864, 69: 0.95467794, 1577: 0.9556511, 1253: 0.954296, 854: 0.9536738, 734: 0.95427537, 66: 0.9533535, 1614: 0.95378006, 708: 0.95374, 559: 0.95360905, 1213: 0.95426023, 966: 0.9549091, 795: 0.95486015, 116: 0.9546971, 303: 0.95497334, 1632: 0.95538056, 563: 0.95420176, 374: 0.9552705, 402: 0.95520645, 10: 0.9537743, 1209: 0.95443475, 793: 0.95545477, 474: 0.95351386, 896: 0.9538882, 1242: 0.9533692, 271: 0.95361024, 589: 0.9549695, 1217: 0.953566, 417: 0.9544039, 497: 0.95351833, 1639: 0.95351726, 656: 0.9528086, 196: 0.9548568, 653: 0.9531386, 1222: 0.9539167, 118: 0.9557661, 994: 0.9549038, 949: 0.95332265, 912: 0.95588326, 0: 0.95515645, 1452: 0.9541617, 1492: 0.95328635, 130: 0.9537308, 713: 0.95732915, 1593: 0.95340854, 1063: 0.954834, 1334: 0.95289695, 1199: 0.9557138, 1717: 0.95430726, 391: 0.9545213, 1620: 0.9554254, 1411: 0.9542736, 701: 0.9552473, 1478: 0.953486, 704: 0.95399934, 125: 0.95279336, 1551: 0.9533237, 1019: 0.9531969, 273: 0.95296293, 1529: 0.95363766, 1559: 0.9526171, 447: 0.9527479, 236: 0.9546637, 956: 0.95375615, 81: 0.9529482, 761: 0.9537851, 600: 0.954107, 1185: 0.9518563, 235: 0.95386744, 1656: 0.95489895, 1406: 0.9537115, 1647: 0.9538756, 468: 0.9548963, 28: 0.9544114, 1672: 0.9530172, 1589: 0.9542778, 1250: 0.9537408, 1707: 0.9546523, 350: 0.9538247, 976: 0.95465076, 740: 0.9540445, 1194: 0.9550331, 1454: 0.95384055, 1693: 0.95493907, 1022: 0.9539639, 871: 0.95480704, 1537: 0.9551729, 1372: 0.9540419, 401: 0.9540755, 255: 0.9547954, 977: 0.9522891, 175: 0.95442766, 705: 0.9544596, 964: 0.9559946, 797: 0.9527021, 380: 0.9532275, 1386: 0.9532715, 1007: 0.9539524, 1205: 0.9555203, 234: 0.954252, 584: 0.954669, 1680: 0.9525828, 1230: 0.9540509, 1041: 0.95290506, 426: 0.95491004, 1032: 0.9537808, 1065: 0.9544681, 277: 0.9545311, 1164: 0.9542989, 736: 0.9530214, 173: 0.9550214, 1576: 0.9544318, 906: 0.9540904, 1256: 0.95668244, 963: 0.95445156, 587: 0.9532144, 26: 0.9542717, 774: 0.9533288, 150: 0.95332026, 651: 0.95405537, 1405: 0.95337874, 1174: 0.95299244, 926: 0.9538679, 1114: 0.9551381, 1613: 0.9537655, 700: 0.9535218, 1687: 0.95486015, 366: 0.9531207, 1434: 0.95698696, 1689: 0.95338404, 959: 0.95468414, 683: 0.95645756, 114: 0.95404613, 1403: 0.954576, 1477: 0.9529215, 6: 0.9553397, 1088: 0.9535902, 545: 0.9533183, 510: 0.95275116, 1473: 0.9544397, 641: 0.954042, 1116: 0.9537693, 1141: 0.95327884, 671: 0.9532962, 1100: 0.9528719, 1712: 0.9537021, 1709: 0.9559737, 1669: 0.9559518, 1362: 0.95353526, 839: 0.95469403, 957: 0.953426, 918: 0.9531793, 1184: 0.95412403, 1545: 0.95553434, 1118: 0.9554603, 208: 0.9533677, 161: 0.95464534, 1435: 0.95362586, 606: 0.95416474, 378: 0.95546466, 998: 0.9554254, 1060: 0.9543102, 636: 0.95388806, 310: 0.9527508, 540: 0.9539357, 1552: 0.9559988, 902: 0.9544076, 108: 0.95406824, 2: 0.95421827, 1486: 0.9551728, 1427: 0.95424503, 1645: 0.9541934, 514: 0.9540996, 535: 0.9547203, 1049: 0.9535333, 1541: 0.9541481, 217: 0.9544892, 1274: 0.954177, 1374: 0.9555249, 971: 0.9530812, 1535: 0.9549666, 1499: 0.953564, 1412: 0.9544494, 1586: 0.9552823, 743: 0.95476115, 1682: 0.9533869, 975: 0.9541583, 1445: 0.95460653, 586: 0.9542936, 1252: 0.95348895, 567: 0.9544257, 819: 0.9539808, 1210: 0.95403755, 763: 0.95499694, 489: 0.95426506, 254: 0.9551413, 1108: 0.9571265, 543: 0.9531928, 570: 0.95466727, 771: 0.9537176, 38: 0.955311, 925: 0.955176, 792: 0.95568967, 1600: 0.9556841, 399: 0.9562166, 22: 0.9550651, 1564: 0.9547561, 407: 0.95419264, 916: 0.95486015, 897: 0.9550777, 356: 0.95259154, 185: 0.9552961, 127: 0.9540434, 115: 0.9540574, 1512: 0.9542341, 1018: 0.9534631, 181: 0.95443714, 602: 0.9536958, 467: 0.9538143, 132: 0.9524869, 647: 0.9545917, 1424: 0.95293343, 1262: 0.9539704, 585: 0.9547511, 1690: 0.958179, 755: 0.9551968, 938: 0.953937, 1587: 0.9538272, 610: 0.95373774, 471: 0.9550508, 215: 0.9547702, 335: 0.9547652, 1013: 0.9541347, 1404: 0.95448065, 373: 0.9524859, 1223: 0.95458776, 1216: 0.95509684, 1438: 0.9549508, 60: 0.95493865, 689: 0.9549257, 109: 0.9534921, 1720: 0.95486516, 1702: 0.95423245, 306: 0.95438486, 1322: 0.9561767, 1158: 0.95755655, 1463: 0.95665365, 433: 0.95290935, 375: 0.95420164, 465: 0.9546032, 620: 0.95387256, 23: 0.9557795, 754: 0.95399505, 1521: 0.955198, 257: 0.95348746, 1286: 0.95517755, 264: 0.9548927, 1105: 0.9538812, 195: 0.95261025, 1318: 0.9545274, 833: 0.95448196, 597: 0.9525955, 1294: 0.954485, 481: 0.9540369, 204: 0.9538654, 737: 0.9557244, 1567: 0.9538043, 531: 0.95509577, 206: 0.953727, 1281: 0.9540777, 1430: 0.95437413, 318: 0.95409364, 1267: 0.954016, 1460: 0.95411134, 804: 0.9549665, 699: 0.9541531, 1361: 0.95493466, 490: 0.9553182, 53: 0.9541444, 887: 0.95408356, 568: 0.9531712, 1371: 0.95454836, 811: 0.95304394, 890: 0.9539976, 1532: 0.95245236, 164: 0.9529346, 782: 0.9560884, 769: 0.9553453, 1103: 0.9552242, 598: 0.9537307, 237: 0.95432985, 1547: 0.95316255, 592: 0.95430714, 1191: 0.9563031, 1447: 0.95385695, 654: 0.95335543, 596: 0.9541784, 1608: 0.95408106, 1695: 0.953894, 1306: 0.95470065, 962: 0.9542951, 428: 0.952906, 712: 0.9553935, 457: 0.9538079, 46: 0.9533443, 562: 0.9546852, 317: 0.9540125, 142: 0.9545453, 894: 0.9563161, 847: 0.9543353, 1125: 0.95365417, 1612: 0.95495987, 96: 0.95467025, 1127: 0.95335644, 1542: 0.9570968, 1227: 0.9538962, 90: 0.95441705, 1155: 0.9543025, 1516: 0.9545168, 321: 0.95409584, 1342: 0.9543344, 229: 0.95396054, 274: 0.9564255, 1285: 0.9537114, 709: 0.9540251, 1550: 0.95302284, 1211: 0.9573348, 1642: 0.95336133, 1301: 0.9550115, 593: 0.95394444, 1183: 0.9557234, 492: 0.95562565, 291: 0.9546634, 210: 0.95405674, 65: 0.9541535, 547: 0.9550714, 544: 0.9534054, 186: 0.9544999, 1525: 0.95470196, 789: 0.95411956, 1480: 0.9543065, 124: 0.95568365, 1021: 0.9559826, 1472: 0.9542364, 1694: 0.9542951, 1005: 0.95562446, 91: 0.9551038, 1429: 0.9536752, 738: 0.95365536, 1030: 0.9561071, 972: 0.9554284, 89: 0.95418864, 826: 0.953642, 171: 0.95669687, 1075: 0.9532674, 1282: 0.9550563, 853: 0.95491767, 760: 0.95719355, 1514: 0.9581685, 932: 0.95422316, 162: 0.954135, 880: 0.9533118, 777: 0.9533987, 1325: 0.9536804, 1616: 0.9539041, 1627: 0.9530446, 207: 0.9544596, 1206: 0.9539866, 430: 0.95556325, 1566: 0.9539222, 669: 0.95297235, 762: 0.9545069, 1539: 0.95227385, 1459: 0.9555512, 151: 0.9551484, 1467: 0.9546032, 1017: 0.9543585, 1711: 0.9544142, 942: 0.9531348, 347: 0.95409006, 180: 0.9538104, 1703: 0.9539243, 1115: 0.9541593, 989: 0.9545114, 135: 0.95296824, 1387: 0.95375085, 3: 0.9539219, 1592: 0.9538012, 1292: 0.9544332, 1270: 0.9540026, 1265: 0.95477074, 533: 0.9537383, 905: 0.95448786, 1649: 0.95370173, 372: 0.9538698, 1305: 0.95493084, 192: 0.95416635, 988: 0.9527427, 885: 0.955561, 860: 0.9541819, 1302: 0.95435613, 1138: 0.9534394, 298: 0.95375174, 275: 0.9540657, 649: 0.95462775, 778: 0.9540464, 1528: 0.95335114, 1708: 0.95379925, 434: 0.9569161, 1111: 0.9556943, 1295: 0.95423955, 1574: 0.95421106, 820: 0.95443517, 947: 0.9536321, 1484: 0.9549801, 165: 0.95295995, 101: 0.9540408, 1364: 0.95330983, 715: 0.95363575, 1629: 0.9547838, 794: 0.9530195, 285: 0.95489746, 571: 0.9553911, 64: 0.9540416, 1453: 0.9549041, 1581: 0.9535729, 911: 0.9541411, 850: 0.9550079, 403: 0.95403355, 930: 0.9539434, 1055: 0.955019, 1381: 0.9542305, 420: 0.95428824, 1259: 0.953937, 556: 0.9547825, 459: 0.95328766, 1159: 0.95485336, 870: 0.95708925, 36: 0.9546484, 1046: 0.95459265, 1218: 0.95375705, 1540: 0.9540703, 1053: 0.9538297, 1456: 0.95402354, 1636: 0.95515114, 355: 0.9538091, 1025: 0.95490867, 1119: 0.9543941, 904: 0.9552116, 1568: 0.95350045, 1335: 0.9561408, 1704: 0.95406336, 1417: 0.9542289, 1040: 0.9537511, 1440: 0.9544094, 631: 0.95369047, 371: 0.95438313, 282: 0.95383036, 1144: 0.95417213, 834: 0.9540149, 697: 0.9545682, 878: 0.9542015, 1122: 0.9531204, 452: 0.95473444, 466: 0.9549354, 408: 0.9539317, 242: 0.9527976, 1042: 0.9552688, 387: 0.9531142, 1329: 0.9542344, 247: 0.95387495, 157: 0.9546996, 1078: 0.955121, 1316: 0.95400673, 442: 0.9537434, 624: 0.9541456, 1308: 0.953537, 99: 0.9521395, 1683: 0.95457333, 1507: 0.95338655, 913: 0.9550253, 1498: 0.95496476, 652: 0.9533982, 595: 0.957731, 296: 0.9565964, 27: 0.9525744, 299: 0.9536608, 1455: 0.9537228, 21: 0.9543355, 245: 0.95453954, 367: 0.9566711, 1610: 0.9539885, 779: 0.9521654, 517: 0.95426136, 1297: 0.95450467, 174: 0.95506346, 1143: 0.95274293, 1398: 0.95614594, 1602: 0.9542213, 1715: 0.9536268, 406: 0.9541432, 1451: 0.95319575, 169: 0.95482564, 1599: 0.95315886, 440: 0.9543823, 910: 0.953531, 405: 0.95357513, 1553: 0.95505196, 122: 0.9551758, 178: 0.9542748, 1506: 0.9559272, 346: 0.9532676, 246: 0.95426255, 1572: 0.9543374, 1150: 0.95498097, 427: 0.9530969, 153: 0.9546786, 1607: 0.9529293, 1337: 0.9557977, 1083: 0.9554789, 1076: 0.9542401, 908: 0.9539214, 44: 0.95534104, 1527: 0.9540673, 77: 0.95399123, 1696: 0.954908, 1001: 0.954448, 147: 0.95335037, 1: 0.9547515, 1175: 0.95571285, 1107: 0.95315623, 82: 0.9539882, 389: 0.9541005, 1326: 0.9542754, 611: 0.954667, 1691: 0.95350564, 955: 0.95418125, 1026: 0.9542266, 1353: 0.954972, 1714: 0.95456797, 845: 0.9541478, 1112: 0.9544973, 1358: 0.9548395, 482: 0.9531684, 1400: 0.95318073, 1137: 0.9536854, 822: 0.9535292, 1168: 0.9535358, 859: 0.9569386, 840: 0.95384055, 1718: 0.9536407, 732: 0.9547046, 31: 0.95378035, 1045: 0.9536032, 409: 0.9534353, 973: 0.9554955, 1120: 0.9547367, 1686: 0.95366997, 1303: 0.9523708, 453: 0.95475674, 499: 0.95341635, 680: 0.9549815, 95: 0.9539997, 863: 0.95376694, 725: 0.95389414, 308: 0.95431095, 844: 0.95604473, 107: 0.953662, 1071: 0.95481443, 1132: 0.9550714, 519: 0.954135, 550: 0.9532263, 666: 0.9540615, 1336: 0.9549342, 650: 0.95291513, 1289: 0.95399135, 1271: 0.95406634, 1047: 0.95455194, 1123: 0.9533411, 1716: 0.95521855, 444: 0.9541277, 731: 0.9568811, 212: 0.95311165, 594: 0.95609444, 872: 0.95357555, 145: 0.9535774, 477: 0.9554155, 268: 0.9537783, 59: 0.95423603, 1713: 0.9575677, 625: 0.9535643, 179: 0.9536126, 1491: 0.95325494, 739: 0.9546312, 609: 0.9556532, 218: 0.9534882, 723: 0.9550974, 431: 0.9554158, 472: 0.9537692, 1443: 0.95415354, 263: 0.9544267, 1029: 0.95529026, 980: 0.9523994, 222: 0.95360136, 1003: 0.9534554, 1523: 0.9537458, 1307: 0.9531774, 892: 0.9541107, 812: 0.9524425, 413: 0.9570959, 572: 0.9546439, 1069: 0.9537851, 1419: 0.95435023, 915: 0.9547579, 163: 0.9547939, 1197: 0.9533395, 326: 0.9539862, 858: 0.9569733, 1239: 0.9548114, 131: 0.95544887, 358: 0.9536108, 48: 0.954686, 1722: 0.9529507, 98: 0.95534015, 333: 0.95378363, 869: 0.95560014, 29: 0.95323485, 698: 0.95419794, 1367: 0.9539668, 526: 0.9532271, 1109: 0.95420575, 1034: 0.9528003, 985: 0.9536956, 1130: 0.9537798, 1129: 0.9561396, 899: 0.95448, 658: 0.95349264, 97: 0.9541124, 787: 0.9542244, 1618: 0.955464, 485: 0.95484453, 1681: 0.9542656, 1350: 0.95444745, 441: 0.9539485, 1196: 0.953328, 110: 0.955765, 1556: 0.95460284, 532: 0.95490634, 991: 0.9538883, 634: 0.9528679, 1483: 0.9557918, 461: 0.9547759, 677: 0.9534858, 886: 0.9550541, 446: 0.95448, 646: 0.9551732, 1152: 0.95609266, 1464: 0.9527848, 682: 0.9551642, 202: 0.9533222, 155: 0.9572696, 172: 0.9536178, 513: 0.9561338, 200: 0.95465916, 1121: 0.9542611, 1628: 0.95149845, 1375: 0.9543987, 744: 0.9555713, 1024: 0.9535529, 655: 0.95496184, 758: 0.95577645, 205: 0.9549377, 47: 0.95493585, 382: 0.95457584, 1634: 0.9542146, 1351: 0.95461625, 718: 0.95343107, 1095: 0.9536047, 1508: 0.95469326, 1091: 0.9542725, 601: 0.9540482, 1588: 0.9545113, 1432: 0.95344883, 868: 0.95473087, 566: 0.95464754, 1015: 0.9546585, 1110: 0.95409095, 922: 0.95544493, 1468: 0.95249075, 1662: 0.95479614, 58: 0.95336956, 1090: 0.9553071, 1249: 0.9535695, 719: 0.95502216, 1373: 0.95363194, 1157: 0.9572778, 1234: 0.954128, 1237: 0.9540895, 936: 0.95692265, 548: 0.9543922, 1343: 0.95251596, 1061: 0.95422554, 1725: 0.95402485, 1277: 0.9544619, 78: 0.95256525, 302: 0.95492965, 1011: 0.9550355, 284: 0.95301527, 119: 0.9549665, 518: 0.95441836, 1149: 0.9535568, 823: 0.95449585, 1363: 0.9538235, 775: 0.9561254, 133: 0.95482975, 287: 0.95295995, 424: 0.9529886, 1555: 0.9543453, 51: 0.95312345, 1388: 0.95298594, 1349: 0.95453554, 927: 0.9535103, 1006: 0.9546011, 139: 0.95471174, 1442: 0.9532348, 230: 0.9536909, 104: 0.9544879, 508: 0.9575656, 1314: 0.95485204, 1675: 0.9556715, 343: 0.95335275, 883: 0.9548811, 1139: 0.95421857, 1243: 0.9535684, 502: 0.95380586, 1101: 0.95549667, 1585: 0.9547617, 1058: 0.9544255, 1726: 0.9534494, 244: 0.95414555, 941: 0.9547605, 1671: 0.95460784, 278: 0.95744383, 711: 0.9539636, 1089: 0.95367247, 484: 0.95261157, 943: 0.9549355, 1096: 0.9552797, 856: 0.9549051, 1663: 0.9552812, 111: 0.9542671, 1039: 0.95549035, 710: 0.9546065, 1012: 0.9535937, 565: 0.95380044, 305: 0.95355874, 1392: 0.9535684, 177: 0.9542379, 1515: 0.9545426, 626: 0.95463026, 1457: 0.95338535, 232: 0.9540078, 817: 0.9547453, 1309: 0.95362955, 672: 0.95505023, 251: 0.95311403, 1530: 0.9532025, 241: 0.954823, 63: 0.95372355, 199: 0.95485497, 622: 0.95487213, 209: 0.9565473, 1052: 0.9536366, 1082: 0.9537958, 1667: 0.9552302, 1266: 0.9558567, 216: 0.9533256, 965: 0.95596486, 39: 0.9538539, 1357: 0.95464814, 1461: 0.9528271, 1263: 0.9533639, 790: 0.95447177, 992: 0.9543111, 357: 0.95413077, 470: 0.95430076, 52: 0.95391065, 884: 0.95481884, 515: 0.9548947, 695: 0.95446473, 454: 0.9528284, 1561: 0.95334584, 855: 0.9524473}, 'azure/Phi-3-mini-4k-instruct': {182: 0.94824076, 825: 0.9494805, 1240: 0.8984161, 505: 0.90003985, 1482: 0.95135695, 1549: 0.89728224, 842: 0.90573627, 1605: 0.90789515, 386: 0.8961344, 1622: 0.9036835, 1182: 0.94975483, 1212: 0.950425, 487: 0.94835246, 148: 0.90022683, 661: 0.94824386, 950: 0.9476852, 393: 0.94974256, 1056: 0.9467957, 259: 0.900766, 1415: 0.8997325, 523: 0.9514861, 353: 0.9497687, 1391: 0.9499692, 874: 0.94810003, 12: 0.94908357, 1700: 0.90027666, 527: 0.89681804, 496: 0.89910996, 483: 0.9076664, 365: 0.9491069, 674: 0.90887743, 93: 0.9009009, 729: 0.89714307, 370: 0.9508728, 714: 0.90381676, 898: 0.9018615, 1344: 0.9496528, 831: 0.94842625, 1723: 0.89968663, 203: 0.90061605, 345: 0.8998346, 67: 0.90174496, 1383: 0.8995853, 319: 0.9041805, 852: 0.90019244, 1311: 0.89677423, 45: 0.9096312, 582: 0.9005245, 791: 0.90831214, 781: 0.9518261, 221: 0.952906, 316: 0.8956832, 857: 0.89866143, 578: 0.9462399, 137: 0.9483429, 639: 0.8982058, 1257: 0.9462929, 390: 0.95338285, 5: 0.94927055, 628: 0.9501199, 1402: 0.9043199, 806: 0.9480173, 243: 0.94988227, 720: 0.90401447, 919: 0.9455331, 491: 0.9536534, 768: 0.9000245, 35: 0.89976984, 462: 0.948889, 414: 0.902299, 475: 0.9514451, 301: 0.9032738, 923: 0.90290636, 815: 0.9508025, 558: 0.94998467, 1458: 0.9133387, 25: 0.89923394, 810: 0.9497557, 557: 0.89682764, 1368: 0.9512961, 369: 0.90040576, 1470: 0.897852, 57: 0.8987998, 152: 0.9479567, 307: 0.8981579, 1598: 0.94998074, 1380: 0.896809, 159: 0.950108, 1382: 0.89884806, 509: 0.9521867, 1665: 0.90250045, 615: 0.8959347, 404: 0.90503967, 396: 0.94988036, 1423: 0.8971634, 1179: 0.94847995, 224: 0.9478228, 1084: 0.94845283, 1359: 0.89701086, 660: 0.90898305, 1099: 0.909578, 590: 0.9487576, 290: 0.9477809, 1548: 0.9491673, 1420: 0.94851106, 1410: 0.8998062, 967: 0.9505551, 979: 0.9016805, 1421: 0.90613085, 512: 0.9049603, 198: 0.8964632, 102: 0.95141435, 479: 0.94951147, 678: 0.9007826, 970: 0.8982792, 1135: 0.9480652, 1583: 0.94684815, 1028: 0.9024951, 397: 0.8981977, 1522: 0.9501193, 555: 0.9002243, 293: 0.90278435, 1504: 0.89828014, 1167: 0.90361845, 1360: 0.94813424, 1469: 0.903052, 1081: 0.9482696, 1192: 0.9462296, 538: 0.9011425, 924: 0.949707, 394: 0.9027656, 1606: 0.94999707, 1397: 0.8966729, 105: 0.9044893, 997: 0.8999897, 144: 0.9011767, 1288: 0.9503448, 1272: 0.94762206, 100: 0.94990605, 1579: 0.94934577, 1557: 0.9479523, 564: 0.90330434, 501: 0.9017757, 613: 0.9500486, 757: 0.9475223, 1475: 0.95043105, 865: 0.94784087, 1571: 0.9504053, 1511: 0.9490959, 785: 0.90676576, 1251: 0.9027616, 1490: 0.95028764, 1481: 0.9503253, 24: 0.94830644, 648: 0.9495969, 149: 0.9503711, 1339: 0.9426024, 843: 0.9013608, 253: 0.94895625, 379: 0.9479709, 1575: 0.90372145, 272: 0.89900964, 670: 0.95061284, 1502: 0.9081385, 1657: 0.90046775, 996: 0.94909304, 702: 0.901716, 276: 0.95156103, 1070: 0.90402746, 1462: 0.8978973, 603: 0.901694, 588: 0.94925475, 733: 0.9518814, 220: 0.9105741, 542: 0.95003945, 1355: 0.9505935, 1352: 0.8996023, 197: 0.9033063, 449: 0.89628816, 334: 0.95009893, 614: 0.8988801, 451: 0.94297534, 691: 0.9008418, 681: 0.94937134, 1626: 0.9516819, 766: 0.9516446, 665: 0.89778554, 616: 0.9493001, 612: 0.8961646, 154: 0.9014648, 190: 0.95249695, 15: 0.90017426, 1268: 0.94839793, 8: 0.8926439, 1296: 0.9517157, 329: 0.90762794, 1611: 0.9515504, 1678: 0.94897306, 780: 0.9514106, 4: 0.95122296, 1661: 0.89889205, 1293: 0.90059817, 294: 0.9507504, 1637: 0.89743775, 1365: 0.95105934, 686: 0.89523023, 1333: 0.95301884, 1474: 0.90394074, 759: 0.94949865, 1584: 0.9487179, 504: 0.94875103, 395: 0.90064174, 1573: 0.90282226, 240: 0.89814174, 92: 0.9488509, 85: 0.8989044, 1146: 0.8987841, 735: 0.9471787, 1140: 0.8999578, 528: 0.9512192, 1510: 0.9018334, 495: 0.90279746, 574: 0.94984454, 627: 0.90484333, 261: 0.89839625, 1298: 0.94944835, 1232: 0.9024016, 1648: 0.9481348, 821: 0.9510019, 94: 0.906022, 1495: 0.9521608, 437: 0.947732, 280: 0.90501136, 120: 0.94857854, 1597: 0.94962454, 520: 0.8952342, 42: 0.8970357, 498: 0.9482729, 1633: 0.95047575, 1092: 0.901286, 835: 0.90172774, 1043: 0.94943225, 1181: 0.8972148, 300: 0.9495037, 920: 0.90124565, 86: 0.9516462, 1569: 0.9091226, 1476: 0.90126055, 1166: 0.9044054, 1016: 0.90205836, 79: 0.9474895, 752: 0.9552932, 986: 0.9045357, 1399: 0.9473073, 1496: 0.8969727, 516: 0.9072772, 1580: 0.90717596, 75: 0.9464756, 969: 0.9014261, 41: 0.9011911, 158: 0.9506775, 1596: 0.8999769, 138: 0.90124553, 832: 0.9442557, 645: 0.8995641, 252: 0.89986587, 724: 0.94970924, 561: 0.9494345, 337: 0.9058714, 1176: 0.90063286, 960: 0.9505522, 1719: 0.89876366, 1591: 0.95101106, 61: 0.94968796, 1142: 0.9503011, 1169: 0.8976831, 1331: 0.94834095, 1465: 0.94480085, 539: 0.89850056, 1631: 0.90028733, 312: 0.95063287, 415: 0.95043254, 747: 0.9492997, 953: 0.94875383, 50: 0.9493971, 1638: 0.9046435, 1699: 0.907469, 1407: 0.89629656, 1560: 0.90249765, 340: 0.89861184, 608: 0.9488162, 524: 0.9486817, 638: 0.9220502, 213: 0.9491931, 1519: 0.9495728, 1356: 0.89715105, 889: 0.9500611, 304: 0.9485134, 1276: 0.8999322, 659: 0.95195115, 801: 0.8991996, 796: 0.9009242, 1093: 0.9491814, 425: 0.89938664, 876: 0.89706504, 381: 0.94928205, 106: 0.9032814, 128: 0.949821, 1705: 0.9044176, 1098: 0.9494403, 829: 0.8963005, 788: 0.9090045, 248: 0.8965395, 34: 0.94806373, 632: 0.94929785, 1698: 0.8959938, 9: 0.9456525, 418: 0.90197915, 40: 0.9499491, 604: 0.90154594, 1235: 0.8979392, 577: 0.94647694, 1666: 0.90091985, 1245: 0.9544192, 1673: 0.90164816, 1684: 0.90968853, 68: 0.9499201, 629: 0.95025146, 11: 0.89571047, 1394: 0.8994589, 1582: 0.8997375, 1471: 0.94186026, 384: 0.9502549, 987: 0.9022685, 54: 0.9490249, 944: 0.89623874, 1697: 0.9502448, 809: 0.89592934, 675: 0.90628123, 1219: 0.8976296, 309: 0.9005651, 1048: 0.9077545, 1051: 0.9507958, 1204: 0.95316803, 436: 0.95128465, 643: 0.9488697, 981: 0.8979179, 827: 0.9063968, 1377: 0.94987625, 1173: 0.94898695, 551: 0.9516829, 1073: 0.90108323, 412: 0.8972234, 1097: 0.94585276, 363: 0.9423478, 322: 0.90077794, 968: 0.9512551, 907: 0.94941175, 331: 0.9515025, 1086: 0.9026771, 507: 0.9052986, 940: 0.8969107, 1536: 0.9001498, 828: 0.95308954, 786: 0.89891547, 1444: 0.8960685, 534: 0.9463126, 297: 0.9464718, 635: 0.9541896, 581: 0.94894207, 1258: 0.90921277, 1604: 0.95080745, 136: 0.90279126, 939: 0.90041316, 1500: 0.949396, 269: 0.95101756, 288: 0.89555544, 1224: 0.89930373, 1493: 0.91092163, 1340: 0.9468995, 260: 0.9492447, 362: 0.94839525, 722: 0.8965544, 1248: 0.9481723, 767: 0.95017517, 866: 0.9072473, 875: 0.9074522, 756: 0.9479345, 706: 0.8983002, 1376: 0.9490538, 49: 0.89819616, 1595: 0.9002273, 935: 0.9014002, 984: 0.95237505, 679: 0.9511491, 188: 0.94951886, 1186: 0.95302457, 848: 0.89998394, 1685: 0.95092785, 1724: 0.94365734, 1414: 0.9509289, 1354: 0.9077306, 281: 0.9486884, 522: 0.94939107, 1677: 0.897239, 103: 0.9496137, 456: 0.8978576, 644: 0.89549077, 1228: 0.9013728, 895: 0.89907116, 541: 0.95026284, 1128: 0.94994694, 1323: 0.9505485, 830: 0.90109736, 1554: 0.9452771, 1020: 0.95065457, 1603: 0.9011864, 1538: 0.94631135, 377: 0.9503062, 473: 0.89960325, 398: 0.89568484, 419: 0.948928, 129: 0.90238404, 1156: 0.9030949, 1275: 0.9062748, 360: 0.90072715, 751: 0.9007081, 1106: 0.9496988, 1437: 0.9458877, 673: 0.8990043, 1578: 0.9011002, 891: 0.90287936, 599: 0.90271205, 351: 0.8998759, 882: 0.8998079, 1036: 0.9507957, 1721: 0.9034919, 1134: 0.9021585, 1153: 0.94880176, 1074: 0.9493508, 901: 0.9027372, 17: 0.94944084, 286: 0.9482803, 344: 0.904715, 359: 0.8987607, 749: 0.9040516, 348: 0.901309, 1446: 0.8979518, 249: 0.95031196, 914: 0.89661014, 1347: 0.94887036, 1231: 0.89969665, 929: 0.89990765, 864: 0.90096796, 1190: 0.9484354, 7: 0.8998104, 1198: 0.9504719, 851: 0.8978722, 1384: 0.9003801, 201: 0.8954915, 1450: 0.902167, 480: 0.89970315, 1113: 0.95130503, 1077: 0.94755566, 867: 0.94672036, 18: 0.896956, 1131: 0.89695287, 1619: 0.9048522, 1346: 0.94742084, 862: 0.9055074, 1050: 0.95159256, 74: 0.90400016, 770: 0.9009389, 1085: 0.948243, 982: 0.94999504, 170: 0.9498738, 464: 0.9534418, 696: 0.94855183, 1544: 0.90111464, 223: 0.9045304, 1038: 0.9512304, 1280: 0.8958723, 1366: 0.90174073, 1479: 0.89871716, 974: 0.89919645, 83: 0.94869244, 814: 0.9017926, 1433: 0.8994341, 1203: 0.942726, 270: 0.94741184, 1054: 0.9528946, 1624: 0.9505043, 383: 0.8962144, 1385: 0.90158963, 1505: 0.9503432, 1485: 0.9037444, 1080: 0.9056695, 1023: 0.8979725, 20: 0.9501489, 1067: 0.9506861, 385: 0.94921994, 332: 0.89860874, 903: 0.9498316, 324: 0.9514307, 227: 0.94726014, 1408: 0.8987808, 1389: 0.8987175, 1488: 0.9479649, 439: 0.9061995, 361: 0.8958539, 1654: 0.89893097, 753: 0.89722836, 1425: 0.94949514, 990: 0.9477941, 554: 0.9493894, 909: 0.9034441, 1180: 0.9494237, 888: 0.9465001, 958: 0.9091763, 530: 0.9018667, 1441: 0.94797117, 469: 0.9503317, 1233: 0.90236133, 1215: 0.89841944, 368: 0.89974654, 1520: 0.90807295, 1570: 0.9452026, 1124: 0.90015304, 560: 0.89721906, 928: 0.9015097, 266: 0.8954324, 1236: 0.89969057, 460: 0.90268517, 1546: 0.95140064, 500: 0.9489446, 1133: 0.94831556, 1031: 0.949877, 325: 0.90276057, 802: 0.90480965, 476: 0.9497156, 730: 0.952865, 250: 0.9029766, 765: 0.9514506, 900: 0.9019675, 421: 0.9483682, 685: 0.9001769, 70: 0.9062252, 1247: 0.94985324, 799: 0.89960396, 16: 0.89856225, 1396: 0.9459005, 211: 0.9495438, 113: 0.9483115, 87: 0.9015742, 1037: 0.8999953, 1170: 0.9470843, 1014: 0.94828933, 80: 0.9506494, 1655: 0.9047565, 1533: 0.9507641, 1422: 0.89533573, 1162: 0.8978894, 978: 0.9483533, 1674: 0.9497798, 1154: 0.950725, 748: 0.89920896, 1526: 0.94681174, 703: 0.94917595, 349: 0.9437375, 315: 0.9507145, 1321: 0.9496374, 289: 0.8998079, 1658: 0.8971956, 295: 0.90681285, 1348: 0.95225525, 1284: 0.9505745, 1379: 0.9458603, 1225: 0.94323015, 400: 0.8994765, 1660: 0.9029145, 1220: 0.9481767, 1395: 0.90016055, 1701: 0.9497365, 684: 0.8981348, 553: 0.9008376, 62: 0.90468913, 1283: 0.9069537, 313: 0.89637196, 262: 0.9034247, 1200: 0.94919944, 69: 0.8965641, 1577: 0.9056045, 1253: 0.9056881, 854: 0.90800315, 734: 0.9013518, 66: 0.9467593, 1614: 0.89628744, 708: 0.90034884, 559: 0.90541935, 1213: 0.90296745, 966: 0.94738394, 795: 0.9021065, 116: 0.90009624, 303: 0.8996784, 1632: 0.90839106, 563: 0.90570694, 374: 0.946418, 402: 0.90235984, 10: 0.8993228, 1209: 0.9474346, 793: 0.94364536, 474: 0.9509968, 896: 0.89806455, 1242: 0.9508581, 271: 0.9502516, 589: 0.8983997, 1217: 0.9477078, 417: 0.94990486, 497: 0.89750445, 1639: 0.9490214, 656: 0.9501538, 196: 0.94701993, 653: 0.89971906, 1222: 0.9490298, 118: 0.901612, 994: 0.8972225, 949: 0.8997784, 912: 0.9029607, 0: 0.9489473, 1452: 0.90723825, 1492: 0.8962414, 130: 0.9494969, 713: 0.8998395, 1593: 0.90487546, 1063: 0.9481794, 1334: 0.9489364, 1199: 0.94954973, 1717: 0.95017636, 391: 0.94772553, 1620: 0.9479672, 1411: 0.8992111, 701: 0.9494662, 1478: 0.8982245, 704: 0.9465018, 125: 0.9014329, 1551: 0.95093346, 1019: 0.9057684, 273: 0.95236534, 1529: 0.946524, 1559: 0.899367, 447: 0.9533905, 236: 0.9492665, 956: 0.8981958, 81: 0.904136, 761: 0.8980202, 600: 0.8973837, 1185: 0.9445163, 235: 0.89729947, 1656: 0.89736676, 1406: 0.95257956, 1647: 0.9026997, 468: 0.9488138, 28: 0.8978958, 1672: 0.9503911, 1589: 0.9520168, 1250: 0.90490675, 1707: 0.9496554, 350: 0.90231305, 976: 0.90544635, 740: 0.8965848, 1194: 0.9439653, 1454: 0.95195687, 1693: 0.9490743, 1022: 0.94870555, 871: 0.949988, 1537: 0.89989436, 1372: 0.95028883, 401: 0.9471967, 255: 0.9481053, 977: 0.9064766, 175: 0.8986721, 705: 0.8969074, 964: 0.8967145, 797: 0.90418714, 380: 0.90073836, 1386: 0.8968906, 1007: 0.9024063, 1205: 0.9486605, 234: 0.9498385, 584: 0.94698095, 1680: 0.9495465, 1230: 0.90884495, 1041: 0.9503679, 426: 0.95049393, 1032: 0.8991867, 1065: 0.9504607, 277: 0.8956155, 1164: 0.90738153, 736: 0.9450448, 173: 0.95147544, 1576: 0.91290826, 906: 0.9476908, 1256: 0.8981673, 963: 0.9497627, 587: 0.9046061, 26: 0.8959175, 774: 0.9029022, 150: 0.9500146, 651: 0.9493533, 1405: 0.9008112, 1174: 0.94902056, 926: 0.94931394, 1114: 0.9468259, 1613: 0.8980539, 700: 0.9495467, 1687: 0.8990851, 366: 0.8994419, 1434: 0.9023039, 1689: 0.9489643, 959: 0.94756544, 683: 0.9064337, 114: 0.95167017, 1403: 0.94643456, 1477: 0.95092696, 6: 0.94648975, 1088: 0.9497848, 545: 0.90421706, 510: 0.9052083, 1473: 0.9468972, 641: 0.9073384, 1116: 0.95019656, 1141: 0.9053052, 671: 0.9501804, 1100: 0.9005408, 1712: 0.8971021, 1709: 0.90290457, 1669: 0.8978624, 1362: 0.94946104, 839: 0.94909453, 957: 0.8986618, 918: 0.90126026, 1184: 0.94847536, 1545: 0.9463184, 1118: 0.90422827, 208: 0.9501418, 161: 0.8961767, 1435: 0.9509823, 606: 0.9500131, 378: 0.8974557, 998: 0.9003759, 1060: 0.9491784, 636: 0.9501498, 310: 0.9096002, 540: 0.8983753, 1552: 0.90090764, 902: 0.95095706, 108: 0.8978385, 2: 0.9011171, 1486: 0.9023916, 1427: 0.9501871, 1645: 0.8974698, 514: 0.8993983, 535: 0.8977429, 1049: 0.9507657, 1541: 0.9001504, 217: 0.89481646, 1274: 0.90708584, 1374: 0.904849, 971: 0.95326155, 1535: 0.95058, 1499: 0.90019196, 1412: 0.89668417, 1586: 0.94994104, 743: 0.94910944, 1682: 0.9088932, 975: 0.9521133, 1445: 0.95106155, 586: 0.95075893, 1252: 0.90031195, 567: 0.94960237, 819: 0.9527607, 1210: 0.8972538, 763: 0.950023, 489: 0.95149726, 254: 0.94938767, 1108: 0.8978322, 543: 0.89803773, 570: 0.89792967, 771: 0.90348667, 38: 0.9016405, 925: 0.948201, 792: 0.89941067, 1600: 0.9011656, 399: 0.89781964, 22: 0.9443318, 1564: 0.9501252, 407: 0.9490304, 916: 0.94862485, 897: 0.8951859, 356: 0.8999184, 185: 0.9462062, 127: 0.94804037, 115: 0.8980442, 1512: 0.94920534, 1018: 0.9483138, 181: 0.94999063, 602: 0.95231265, 467: 0.94971687, 132: 0.8993071, 647: 0.9029866, 1424: 0.95349383, 1262: 0.89847064, 585: 0.8978716, 1690: 0.90692997, 755: 0.90221876, 938: 0.9016869, 1587: 0.8970916, 610: 0.90067434, 471: 0.8987681, 215: 0.89513534, 335: 0.8969213, 1013: 0.9028683, 1404: 0.95043784, 373: 0.90628105, 1223: 0.8966422, 1216: 0.94948965, 1438: 0.9490376, 60: 0.94658726, 689: 0.9016827, 109: 0.94962496, 1720: 0.9502484, 1702: 0.9492696, 306: 0.9028602, 1322: 0.9472383, 1158: 0.9059393, 1463: 0.9103934, 433: 0.89933324, 375: 0.8984705, 465: 0.94915843, 620: 0.95065886, 23: 0.9023719, 754: 0.8991975, 1521: 0.94948447, 257: 0.9040863, 1286: 0.9452111, 264: 0.94881886, 1105: 0.94725233, 195: 0.95220995, 1318: 0.8981403, 833: 0.9481043, 597: 0.9002247, 1294: 0.8969589, 481: 0.9007201, 204: 0.89907527, 737: 0.9020987, 1567: 0.9064147, 531: 0.90627664, 206: 0.8994494, 1281: 0.94834363, 1430: 0.8971961, 318: 0.94925207, 1267: 0.8986152, 1460: 0.89983064, 804: 0.9489744, 699: 0.90687764, 1361: 0.89769566, 490: 0.89671236, 53: 0.8966682, 887: 0.89949256, 568: 0.90041333, 1371: 0.89693594, 811: 0.9004839, 890: 0.9032424, 1532: 0.94926155, 164: 0.90564036, 782: 0.90120894, 769: 0.9072848, 1103: 0.9477156, 598: 0.9509699, 237: 0.8984655, 1547: 0.9006639, 592: 0.9490269, 1191: 0.9023003, 1447: 0.9492148, 654: 0.94529015, 596: 0.9512067, 1608: 0.8986, 1695: 0.8991246, 1306: 0.94961077, 962: 0.9489138, 428: 0.94858354, 712: 0.9500404, 457: 0.8994172, 46: 0.95103985, 562: 0.9510993, 317: 0.8999263, 142: 0.9482597, 894: 0.9002741, 847: 0.9495591, 1125: 0.95103145, 1612: 0.9048839, 96: 0.95102036, 1127: 0.9496698, 1542: 0.90568906, 1227: 0.9506781, 90: 0.90614533, 1155: 0.90114605, 1516: 0.95152044, 321: 0.9482279, 1342: 0.89533794, 229: 0.899936, 274: 0.9443039, 1285: 0.9106306, 709: 0.9031781, 1550: 0.90247655, 1211: 0.8996877, 1642: 0.9002018, 1301: 0.8981074, 593: 0.95023847, 1183: 0.93889374, 492: 0.8974788, 291: 0.8966997, 210: 0.896903, 65: 0.95058924, 547: 0.9006218, 544: 0.8984973, 186: 0.9489812, 1525: 0.9510049, 789: 0.8972455, 1480: 0.91100216, 124: 0.89817274, 1021: 0.8986462, 1472: 0.9498285, 1694: 0.9476116, 1005: 0.89669466, 91: 0.94826454, 1429: 0.9020883, 738: 0.90029144, 1030: 0.90207314, 972: 0.9078676, 89: 0.9012963, 826: 0.9017793, 171: 0.9085226, 1075: 0.9524224, 1282: 0.94612306, 853: 0.9482596, 760: 0.9144008, 1514: 0.90682113, 932: 0.94930565, 162: 0.9018947, 880: 0.899128, 777: 0.9498399, 1325: 0.9489343, 1616: 0.8977666, 1627: 0.9098921, 207: 0.9506355, 1206: 0.94920254, 430: 0.8948594, 1566: 0.8980591, 669: 0.9026219, 762: 0.9009601, 1539: 0.8998388, 1459: 0.94813615, 151: 0.90172654, 1467: 0.90305734, 1017: 0.9505199, 1711: 0.9512773, 942: 0.90018654, 347: 0.89789736, 180: 0.90252256, 1703: 0.9498031, 1115: 0.90641147, 989: 0.9485831, 135: 0.90206206, 1387: 0.95172995, 3: 0.8993258, 1592: 0.8969642, 1292: 0.9481872, 1270: 0.95019925, 1265: 0.9482307, 533: 0.9503428, 905: 0.8976397, 1649: 0.899557, 372: 0.8992892, 1305: 0.8971541, 192: 0.9498879, 988: 0.9506192, 885: 0.9025417, 860: 0.8975022, 1302: 0.8997524, 1138: 0.9451488, 298: 0.9516907, 275: 0.95056295, 649: 0.90039766, 778: 0.89916855, 1528: 0.9514395, 1708: 0.90254295, 434: 0.90639305, 1111: 0.8989855, 1295: 0.9479479, 1574: 0.94962174, 820: 0.9473448, 947: 0.95075387, 1484: 0.9487431, 165: 0.9523914, 101: 0.9524853, 1364: 0.90207535, 715: 0.9530935, 1629: 0.89753354, 794: 0.9014844, 285: 0.94948125, 571: 0.9508819, 64: 0.9009843, 1453: 0.9104341, 1581: 0.94893456, 911: 0.90138084, 850: 0.94947994, 403: 0.95097136, 930: 0.94854385, 1055: 0.9493826, 1381: 0.909622, 420: 0.89646304, 1259: 0.9492611, 556: 0.94599736, 459: 0.9032842, 1159: 0.9505361, 870: 0.9022903, 36: 0.9504268, 1046: 0.95079666, 1218: 0.9043861, 1540: 0.90794754, 1053: 0.9026494, 1456: 0.9490913, 1636: 0.90833575, 355: 0.9498948, 1025: 0.95150715, 1119: 0.9493241, 904: 0.948501, 1568: 0.9494649, 1335: 0.90078914, 1704: 0.8945165, 1417: 0.9498404, 1040: 0.905534, 1440: 0.9505098, 631: 0.94930667, 371: 0.94574255, 282: 0.8972711, 1144: 0.9486871, 834: 0.9502926, 697: 0.90516424, 878: 0.9002407, 1122: 0.9491768, 452: 0.9004524, 466: 0.9509615, 408: 0.89897585, 242: 0.9486148, 1042: 0.89706594, 387: 0.90084845, 1329: 0.94754195, 247: 0.897627, 157: 0.95058376, 1078: 0.9495967, 1316: 0.9022058, 442: 0.90328664, 624: 0.89822, 1308: 0.9495543, 99: 0.9109584, 1683: 0.94689864, 1507: 0.9509868, 913: 0.9460311, 1498: 0.89901114, 652: 0.9061476, 595: 0.90706754, 296: 0.9103144, 27: 0.8984821, 299: 0.9012383, 1455: 0.898631, 21: 0.9519305, 245: 0.9522263, 367: 0.90246004, 1610: 0.9034208, 779: 0.9052303, 517: 0.9083537, 1297: 0.8958617, 174: 0.8952583, 1143: 0.9514326, 1398: 0.9058354, 1602: 0.9488917, 1715: 0.94918793, 406: 0.9087099, 1451: 0.9512737, 169: 0.94888043, 1599: 0.9507761, 440: 0.8968468, 910: 0.90047604, 405: 0.9014035, 1553: 0.9044264, 122: 0.9472965, 178: 0.89909613, 1506: 0.9470924, 346: 0.9495969, 246: 0.89796525, 1572: 0.8960365, 1150: 0.9073125, 427: 0.9492803, 153: 0.9488518, 1607: 0.8993795, 1337: 0.8933143, 1083: 0.902003, 1076: 0.9501395, 908: 0.9494244, 44: 0.94819015, 1527: 0.89549506, 77: 0.9005067, 1696: 0.9496129, 1001: 0.9475717, 147: 0.89850175, 1: 0.9504476, 1175: 0.9013054, 1107: 0.9511602, 82: 0.89861345, 389: 0.8969184, 1326: 0.9013831, 611: 0.9492226, 1691: 0.8974116, 955: 0.8971275, 1026: 0.9041288, 1353: 0.94838357, 1714: 0.902182, 845: 0.9506459, 1112: 0.94950396, 1358: 0.94990456, 482: 0.8989072, 1400: 0.91317093, 1137: 0.90435463, 822: 0.90218323, 1168: 0.9496084, 859: 0.9026468, 840: 0.9450547, 1718: 0.89788246, 732: 0.90663385, 31: 0.9035943, 1045: 0.90617824, 409: 0.9501084, 973: 0.9019315, 1120: 0.9461621, 1686: 0.90545464, 1303: 0.9010647, 453: 0.9482849, 499: 0.9532693, 680: 0.9023836, 95: 0.9057362, 863: 0.9486561, 725: 0.90634614, 308: 0.89711523, 844: 0.9010519, 107: 0.90213084, 1071: 0.94545925, 1132: 0.9489252, 519: 0.89719164, 550: 0.94890374, 666: 0.94929826, 1336: 0.89634836, 650: 0.9523416, 1289: 0.94820064, 1271: 0.90027446, 1047: 0.9490395, 1123: 0.9033346, 1716: 0.9490897, 444: 0.8993896, 731: 0.90360695, 212: 0.8989017, 594: 0.9015338, 872: 0.9006597, 145: 0.9519396, 477: 0.90002847, 268: 0.9510404, 59: 0.8957081, 1713: 0.902067, 625: 0.90883464, 179: 0.9501578, 1491: 0.9499797, 739: 0.94724023, 609: 0.94509697, 218: 0.9496872, 723: 0.95009863, 431: 0.94912386, 472: 0.8976608, 1443: 0.8991604, 263: 0.898316, 1029: 0.947538, 980: 0.9490927, 222: 0.8994207, 1003: 0.9484707, 1523: 0.90337205, 1307: 0.90310603, 892: 0.9015954, 812: 0.9475499, 413: 0.9044457, 572: 0.9496356, 1069: 0.95119774, 1419: 0.89917034, 915: 0.89502734, 163: 0.94891363, 1197: 0.9504057, 326: 0.9510477, 858: 0.90681106, 1239: 0.9514058, 131: 0.9028616, 358: 0.9538424, 48: 0.89862376, 1722: 0.94750977, 98: 0.9493291, 333: 0.9478545, 869: 0.89915276, 29: 0.95186174, 698: 0.95023996, 1367: 0.9487272, 526: 0.8962414, 1109: 0.90342534, 1034: 0.95095015, 985: 0.8981193, 1130: 0.9016301, 1129: 0.9022364, 899: 0.8962239, 658: 0.9001923, 97: 0.89908963, 787: 0.8983989, 1618: 0.8985817, 485: 0.900014, 1681: 0.90015614, 1350: 0.8973773, 441: 0.9004827, 1196: 0.9511495, 110: 0.9006047, 1556: 0.9011869, 532: 0.9490624, 991: 0.8975891, 634: 0.95065284, 1483: 0.8996244, 461: 0.90605533, 677: 0.90483785, 886: 0.9461698, 446: 0.94977665, 646: 0.9426865, 1152: 0.8979896, 1464: 0.9493084, 682: 0.94705856, 202: 0.9068372, 155: 0.9080927, 172: 0.89978933, 513: 0.9022335, 200: 0.90398806, 1121: 0.90419525, 1628: 0.94889647, 1375: 0.8999539, 744: 0.94981056, 1024: 0.8992989, 655: 0.9490049, 758: 0.89246386, 205: 0.94373196, 47: 0.94805586, 382: 0.90095884, 1634: 0.95141715, 1351: 0.89720863, 718: 0.8983803, 1095: 0.95351434, 1508: 0.9480337, 1091: 0.95053613, 601: 0.94946104, 1588: 0.9496056, 1432: 0.94857854, 868: 0.8961043, 566: 0.9489414, 1015: 0.8976149, 1110: 0.9466629, 922: 0.9029239, 1468: 0.94913554, 1662: 0.94931763, 58: 0.9518333, 1090: 0.94714487, 1249: 0.9523509, 719: 0.9047426, 1373: 0.9494862, 1157: 0.9050845, 1234: 0.9484571, 1237: 0.9482449, 936: 0.90369785, 548: 0.94934416, 1343: 0.9473086, 1061: 0.95051557, 1725: 0.9011926, 1277: 0.89856285, 78: 0.90967655, 302: 0.94939053, 1011: 0.8957375, 284: 0.9484848, 119: 0.95011264, 518: 0.8984943, 1149: 0.90019006, 823: 0.9038983, 1363: 0.8996355, 775: 0.9524196, 133: 0.8968372, 287: 0.9040288, 424: 0.897627, 1555: 0.90027493, 51: 0.9475331, 1388: 0.89400136, 1349: 0.89929, 927: 0.9510869, 1006: 0.8970951, 139: 0.9494269, 1442: 0.9062603, 230: 0.89898145, 104: 0.94861925, 508: 0.91405797, 1314: 0.9481327, 1675: 0.94308984, 343: 0.949727, 883: 0.94943506, 1139: 0.90538347, 1243: 0.8966075, 502: 0.89995843, 1101: 0.8994014, 1585: 0.89742947, 1058: 0.9498415, 1726: 0.89940727, 244: 0.90348256, 941: 0.94793063, 1671: 0.8985722, 278: 0.91289395, 711: 0.9508815, 1089: 0.9006619, 484: 0.9003883, 943: 0.89684296, 1096: 0.9487551, 856: 0.9482997, 1663: 0.9027845, 111: 0.8998952, 1039: 0.9071108, 710: 0.8983342, 1012: 0.94916886, 565: 0.8962716, 305: 0.89902335, 1392: 0.9511629, 177: 0.8978029, 1515: 0.9024602, 626: 0.8955209, 1457: 0.9509235, 232: 0.904414, 817: 0.9491768, 1309: 0.8955877, 672: 0.9497443, 251: 0.948743, 1530: 0.9013162, 241: 0.89529204, 63: 0.95108074, 199: 0.902374, 622: 0.9467256, 209: 0.899487, 1052: 0.9503381, 1082: 0.89873624, 1667: 0.90443087, 1266: 0.8970307, 216: 0.89853716, 965: 0.9107368, 39: 0.95032704, 1357: 0.94880027, 1461: 0.90740657, 1263: 0.9518073, 790: 0.9501207, 992: 0.89780194, 357: 0.9035464, 470: 0.90318054, 52: 0.8981797, 884: 0.8966119, 515: 0.9490025, 695: 0.9000897, 454: 0.9057842, 1561: 0.9493893, 855: 0.9015156}, 'azure/Phi-3.5-mini-instruct': {182: 0.9383506, 825: 0.9354931, 1240: 0.9248749, 505: 0.93592405, 1482: 0.93443793, 1549: 0.9221342, 842: 0.9417353, 1605: 0.9287774, 386: 0.93559736, 1622: 0.92032635, 1182: 0.93218875, 1212: 0.94421804, 487: 0.93093324, 148: 0.92026466, 661: 0.93537617, 950: 0.941269, 393: 0.9369674, 1056: 0.91937053, 259: 0.94188696, 1415: 0.940882, 523: 0.9313733, 353: 0.93128467, 1391: 0.9437507, 874: 0.9214326, 12: 0.9350792, 1700: 0.94051033, 527: 0.9303515, 496: 0.92451286, 483: 0.92797303, 365: 0.93519163, 674: 0.9274985, 93: 0.9366709, 729: 0.92756754, 370: 0.9253027, 714: 0.93126637, 898: 0.9440999, 1344: 0.93792164, 831: 0.92639464, 1723: 0.93908733, 203: 0.9309152, 345: 0.927534, 67: 0.92841476, 1383: 0.9276027, 319: 0.9435371, 852: 0.9427417, 1311: 0.9379189, 45: 0.93066823, 582: 0.92937875, 791: 0.92809767, 781: 0.9379784, 221: 0.9261924, 316: 0.9358938, 857: 0.92698675, 578: 0.94373953, 137: 0.9351643, 639: 0.92814285, 1257: 0.9335137, 390: 0.932621, 5: 0.93783987, 628: 0.92853373, 1402: 0.94283664, 806: 0.9390665, 243: 0.9335818, 720: 0.9347126, 919: 0.94118005, 491: 0.9231159, 768: 0.92888016, 35: 0.9236183, 462: 0.9244761, 414: 0.93236333, 475: 0.9310611, 301: 0.9281056, 923: 0.9348407, 815: 0.92741114, 558: 0.9344417, 1458: 0.93744487, 25: 0.92847496, 810: 0.9396342, 557: 0.9376329, 1368: 0.93915325, 369: 0.9250382, 1470: 0.92597616, 57: 0.9323798, 152: 0.94171715, 307: 0.933582, 1598: 0.92842996, 1380: 0.9348348, 159: 0.9254071, 1382: 0.9385738, 509: 0.9260177, 1665: 0.92769605, 615: 0.93783504, 404: 0.94099647, 396: 0.94029427, 1423: 0.92563194, 1179: 0.93633085, 224: 0.9396979, 1084: 0.9385581, 1359: 0.9375691, 660: 0.9278951, 1099: 0.94367415, 590: 0.93960214, 290: 0.93635964, 1548: 0.925324, 1420: 0.9436542, 1410: 0.9416448, 967: 0.9305402, 979: 0.92810917, 1421: 0.9416925, 512: 0.9269094, 198: 0.93015456, 102: 0.9429538, 479: 0.92999357, 678: 0.92350215, 970: 0.92673606, 1135: 0.9372832, 1583: 0.93495667, 1028: 0.93958014, 397: 0.93562335, 1522: 0.93947333, 555: 0.93679136, 293: 0.94155306, 1504: 0.92464775, 1167: 0.92743176, 1360: 0.93998104, 1469: 0.92541444, 1081: 0.9347324, 1192: 0.9340002, 538: 0.9306359, 924: 0.9377757, 394: 0.9387712, 1606: 0.9358608, 1397: 0.9365236, 105: 0.92584586, 997: 0.9267862, 144: 0.9202928, 1288: 0.9362126, 1272: 0.9457821, 100: 0.94152445, 1579: 0.9381435, 1557: 0.9409649, 564: 0.9257305, 501: 0.9257015, 613: 0.9357761, 757: 0.9428198, 1475: 0.94003373, 865: 0.93764657, 1571: 0.93489635, 1511: 0.9384041, 785: 0.9319721, 1251: 0.92511, 1490: 0.94097185, 1481: 0.9364405, 24: 0.9311479, 648: 0.93101376, 149: 0.94392663, 1339: 0.93703824, 843: 0.9394103, 253: 0.9388535, 379: 0.93160826, 1575: 0.9359464, 272: 0.94179475, 670: 0.92157084, 1502: 0.9303158, 1657: 0.92810035, 996: 0.9339696, 702: 0.93791324, 276: 0.91954255, 1070: 0.9380401, 1462: 0.9400557, 603: 0.9274776, 588: 0.9408913, 733: 0.9330644, 220: 0.92183197, 542: 0.93982327, 1355: 0.9247613, 1352: 0.9282485, 197: 0.93826145, 449: 0.9303291, 334: 0.9423436, 614: 0.92541915, 451: 0.9365894, 691: 0.93394333, 681: 0.93747187, 1626: 0.9264778, 766: 0.9359835, 665: 0.9340884, 616: 0.9362032, 612: 0.9387435, 154: 0.93108153, 190: 0.9368321, 15: 0.9275064, 1268: 0.93567127, 8: 0.9269643, 1296: 0.9298592, 329: 0.94945985, 1611: 0.9250142, 1678: 0.93533915, 780: 0.93813205, 4: 0.9300471, 1661: 0.9288305, 1293: 0.9415347, 294: 0.93650234, 1637: 0.9281442, 1365: 0.93477124, 686: 0.92749447, 1333: 0.9432896, 1474: 0.93201786, 759: 0.93541676, 1584: 0.932419, 504: 0.93553424, 395: 0.9289537, 1573: 0.9335284, 240: 0.9257776, 92: 0.93181336, 85: 0.9299655, 1146: 0.93038607, 735: 0.9377819, 1140: 0.9308303, 528: 0.9260511, 1510: 0.92397434, 495: 0.9300343, 574: 0.93499327, 627: 0.9311823, 261: 0.93517566, 1298: 0.93072844, 1232: 0.92168486, 1648: 0.93626326, 821: 0.94357, 94: 0.9375644, 1495: 0.9279332, 437: 0.9276024, 280: 0.92588174, 120: 0.9398717, 1597: 0.93887365, 520: 0.9256551, 42: 0.92267627, 498: 0.9296678, 1633: 0.9272608, 1092: 0.9228386, 835: 0.9378613, 1043: 0.9350587, 1181: 0.9381236, 300: 0.93336517, 920: 0.9342403, 86: 0.94193804, 1569: 0.9256683, 1476: 0.94210535, 1166: 0.9442997, 1016: 0.93545693, 79: 0.9351423, 752: 0.93737924, 986: 0.93055713, 1399: 0.9291065, 1496: 0.93756104, 516: 0.94080806, 1580: 0.9373341, 75: 0.9379672, 969: 0.926957, 41: 0.9348097, 158: 0.93861187, 1596: 0.9275266, 138: 0.924676, 832: 0.94383574, 645: 0.92807376, 252: 0.9364917, 724: 0.9332026, 561: 0.9273283, 337: 0.9421079, 1176: 0.92696565, 960: 0.9320513, 1719: 0.9256073, 1591: 0.92563766, 61: 0.94157255, 1142: 0.9376438, 1169: 0.9336242, 1331: 0.9379511, 1465: 0.9311432, 539: 0.9287691, 1631: 0.94141614, 312: 0.9370313, 415: 0.9406395, 747: 0.936148, 953: 0.93294203, 50: 0.9389485, 1638: 0.9285158, 1699: 0.92854273, 1407: 0.9223666, 1560: 0.9233429, 340: 0.93242437, 608: 0.9351445, 524: 0.9453089, 638: 0.9349871, 213: 0.9266605, 1519: 0.9387705, 1356: 0.92722464, 889: 0.9380158, 304: 0.93501365, 1276: 0.9291094, 659: 0.9323135, 801: 0.93604106, 796: 0.91155475, 1093: 0.93270594, 425: 0.9323636, 876: 0.93814653, 381: 0.9235411, 106: 0.9289679, 128: 0.9413275, 1705: 0.92921376, 1098: 0.9389019, 829: 0.9385857, 788: 0.9401009, 248: 0.92443806, 34: 0.93125033, 632: 0.9319321, 1698: 0.9336095, 9: 0.9289017, 418: 0.9377479, 40: 0.9253579, 604: 0.9348543, 1235: 0.93173337, 577: 0.938107, 1666: 0.9298702, 1245: 0.929485, 1673: 0.93941534, 1684: 0.93492436, 68: 0.9328719, 629: 0.93587065, 11: 0.9396427, 1394: 0.92593336, 1582: 0.9238599, 1471: 0.9276712, 384: 0.9336921, 987: 0.9084092, 54: 0.92217034, 944: 0.93038076, 1697: 0.92739, 809: 0.9386418, 675: 0.9279333, 1219: 0.93315125, 309: 0.9258745, 1048: 0.9104698, 1051: 0.9308616, 1204: 0.9396244, 436: 0.94175965, 643: 0.9397794, 981: 0.9403143, 827: 0.93352634, 1377: 0.9326224, 1173: 0.9390832, 551: 0.9290396, 1073: 0.9306354, 412: 0.9318569, 1097: 0.93977433, 363: 0.9388123, 322: 0.9179995, 968: 0.9360955, 907: 0.9382889, 331: 0.9309969, 1086: 0.9264594, 507: 0.94255793, 940: 0.93120545, 1536: 0.92578393, 828: 0.9286973, 786: 0.9385494, 1444: 0.9250305, 534: 0.926499, 297: 0.92761266, 635: 0.9434799, 581: 0.9359058, 1258: 0.93012094, 1604: 0.94132274, 136: 0.92481863, 939: 0.9317613, 1500: 0.9334321, 269: 0.93723315, 288: 0.93823016, 1224: 0.92590237, 1493: 0.93188864, 1340: 0.9353425, 260: 0.93816775, 362: 0.9408602, 722: 0.9264341, 1248: 0.9173597, 767: 0.93028903, 866: 0.94349515, 875: 0.928841, 756: 0.93699104, 706: 0.93737215, 1376: 0.9388641, 49: 0.9344194, 1595: 0.94318956, 935: 0.9255376, 984: 0.94469804, 679: 0.93611395, 188: 0.93541324, 1186: 0.9295917, 848: 0.9287185, 1685: 0.92909557, 1724: 0.9386025, 1414: 0.9395895, 1354: 0.92836624, 281: 0.9416222, 522: 0.9397721, 1677: 0.9385418, 103: 0.92514074, 456: 0.9379559, 644: 0.9242048, 1228: 0.9150136, 895: 0.9315224, 541: 0.9256432, 1128: 0.93691075, 1323: 0.9257882, 830: 0.9316688, 1554: 0.9421261, 1020: 0.9374201, 1603: 0.93360907, 1538: 0.9241676, 377: 0.9290858, 473: 0.9182292, 398: 0.939449, 419: 0.9444629, 129: 0.94070566, 1156: 0.9383173, 1275: 0.93408406, 360: 0.9294915, 751: 0.9345616, 1106: 0.9346656, 1437: 0.93736535, 673: 0.94133437, 1578: 0.92585075, 891: 0.9439678, 599: 0.93741614, 351: 0.92870253, 882: 0.93024737, 1036: 0.92838, 1721: 0.93582314, 1134: 0.9428177, 1153: 0.92144567, 1074: 0.93702954, 901: 0.939427, 17: 0.93568295, 286: 0.9379334, 344: 0.9346171, 359: 0.93314356, 749: 0.92524916, 348: 0.9386558, 1446: 0.9397496, 249: 0.93300647, 914: 0.9284192, 1347: 0.9239595, 1231: 0.9318638, 929: 0.93144256, 864: 0.9350093, 1190: 0.93436027, 7: 0.9309587, 1198: 0.9442648, 851: 0.92648065, 1384: 0.93405557, 201: 0.9350309, 1450: 0.92530227, 480: 0.92231053, 1113: 0.9435268, 1077: 0.94588417, 867: 0.93916124, 18: 0.9378005, 1131: 0.93770045, 1619: 0.9412446, 1346: 0.9426187, 862: 0.9267546, 1050: 0.93423194, 74: 0.9400714, 770: 0.935734, 1085: 0.93190736, 982: 0.93043673, 170: 0.94220304, 464: 0.93024987, 696: 0.93903023, 1544: 0.9223601, 223: 0.9319679, 1038: 0.9275785, 1280: 0.92665064, 1366: 0.93887573, 1479: 0.9334508, 974: 0.9368481, 83: 0.9375197, 814: 0.9319845, 1433: 0.93008196, 1203: 0.93462676, 270: 0.9246427, 1054: 0.9361596, 1624: 0.93408227, 383: 0.9324429, 1385: 0.93058515, 1505: 0.9317855, 1485: 0.9356222, 1080: 0.93549645, 1023: 0.92281765, 20: 0.9397417, 1067: 0.9291566, 385: 0.93903214, 332: 0.9345777, 903: 0.9361239, 324: 0.92706716, 227: 0.9244448, 1408: 0.9342146, 1389: 0.9326985, 1488: 0.938152, 439: 0.9389728, 361: 0.9372384, 1654: 0.92484623, 753: 0.93185735, 1425: 0.9356948, 990: 0.93431044, 554: 0.92786384, 909: 0.9286116, 1180: 0.9319784, 888: 0.93697137, 958: 0.93515253, 530: 0.9364035, 1441: 0.9296614, 469: 0.9334075, 1233: 0.93330073, 1215: 0.92939276, 368: 0.9263898, 1520: 0.92374104, 1570: 0.93897957, 1124: 0.92796326, 560: 0.93665636, 928: 0.9404428, 266: 0.9300765, 1236: 0.9241303, 460: 0.9370197, 1546: 0.92961997, 500: 0.93869895, 1133: 0.9383249, 1031: 0.93959284, 325: 0.9414516, 802: 0.9270431, 476: 0.93313825, 730: 0.9444531, 250: 0.93662024, 765: 0.9323906, 900: 0.92122847, 421: 0.9342368, 685: 0.9259671, 70: 0.934037, 1247: 0.9219368, 799: 0.9352205, 16: 0.9182638, 1396: 0.9395132, 211: 0.93265575, 113: 0.93741393, 87: 0.92937165, 1037: 0.9318542, 1170: 0.9377282, 1014: 0.9266921, 80: 0.93630415, 1655: 0.9250325, 1533: 0.9189076, 1422: 0.93258804, 1162: 0.9257434, 978: 0.93508166, 1674: 0.9255195, 1154: 0.94293964, 748: 0.92794067, 1526: 0.93827415, 703: 0.9368797, 349: 0.9235207, 315: 0.94256043, 1321: 0.9392464, 289: 0.9356821, 1658: 0.9345612, 295: 0.9303158, 1348: 0.9339003, 1284: 0.94153184, 1379: 0.92949504, 1225: 0.92297685, 400: 0.92797947, 1660: 0.9320374, 1220: 0.9300939, 1395: 0.92528135, 1701: 0.9289208, 684: 0.9392055, 553: 0.9377487, 62: 0.92315066, 1283: 0.9388545, 313: 0.93216026, 262: 0.94061005, 1200: 0.9256102, 69: 0.937359, 1577: 0.9454468, 1253: 0.91656756, 854: 0.9380078, 734: 0.9112913, 66: 0.9316987, 1614: 0.92317235, 708: 0.9293306, 559: 0.9259159, 1213: 0.929244, 966: 0.9317362, 795: 0.92915475, 116: 0.9302307, 303: 0.92240894, 1632: 0.9348291, 563: 0.93317306, 374: 0.935675, 402: 0.9304977, 10: 0.93202364, 1209: 0.92357284, 793: 0.9334269, 474: 0.92574567, 896: 0.9270576, 1242: 0.9353428, 271: 0.9238553, 589: 0.9383367, 1217: 0.9304526, 417: 0.9438788, 497: 0.9218903, 1639: 0.9281288, 656: 0.9273825, 196: 0.93928146, 653: 0.9260918, 1222: 0.93942326, 118: 0.9440934, 994: 0.93913823, 949: 0.93110627, 912: 0.9220406, 0: 0.93856096, 1452: 0.928835, 1492: 0.9176847, 130: 0.9294021, 713: 0.92727214, 1593: 0.94507676, 1063: 0.9387921, 1334: 0.94371784, 1199: 0.9382285, 1717: 0.9256975, 391: 0.9374298, 1620: 0.93835497, 1411: 0.9262862, 701: 0.9344219, 1478: 0.9310928, 704: 0.9291312, 125: 0.92651564, 1551: 0.92435634, 1019: 0.93158066, 273: 0.9404699, 1529: 0.92848814, 1559: 0.932068, 447: 0.9374042, 236: 0.9388783, 956: 0.92770374, 81: 0.92488784, 761: 0.9334403, 600: 0.93568796, 1185: 0.9410067, 235: 0.93550754, 1656: 0.93710315, 1406: 0.9370043, 1647: 0.9290097, 468: 0.937211, 28: 0.9365312, 1672: 0.94117635, 1589: 0.9236172, 1250: 0.91460323, 1707: 0.9381565, 350: 0.93374693, 976: 0.92804295, 740: 0.9381043, 1194: 0.9385367, 1454: 0.93136054, 1693: 0.9248938, 1022: 0.93304807, 871: 0.93671304, 1537: 0.93023014, 1372: 0.9298954, 401: 0.93161076, 255: 0.9197092, 977: 0.94197696, 175: 0.9306093, 705: 0.931835, 964: 0.93450516, 797: 0.9243487, 380: 0.9286591, 1386: 0.9299386, 1007: 0.94424945, 1205: 0.9351552, 234: 0.92912316, 584: 0.93212825, 1680: 0.92362624, 1230: 0.92969704, 1041: 0.93755966, 426: 0.93895113, 1032: 0.9280536, 1065: 0.94107574, 277: 0.9378472, 1164: 0.94167745, 736: 0.9417359, 173: 0.9387672, 1576: 0.9293105, 906: 0.94427747, 1256: 0.92957467, 963: 0.9324475, 587: 0.9437855, 26: 0.9359127, 774: 0.9255797, 150: 0.9310511, 651: 0.94004804, 1405: 0.94076407, 1174: 0.92478806, 926: 0.9318385, 1114: 0.93483245, 1613: 0.9452105, 700: 0.94436824, 1687: 0.93353903, 366: 0.92339015, 1434: 0.9394915, 1689: 0.93762755, 959: 0.93652445, 683: 0.9420498, 114: 0.9334269, 1403: 0.93727285, 1477: 0.9423385, 6: 0.9437016, 1088: 0.92579764, 545: 0.94367516, 510: 0.93101996, 1473: 0.9403103, 641: 0.9429317, 1116: 0.9329354, 1141: 0.93690616, 671: 0.9389819, 1100: 0.92714596, 1712: 0.92081743, 1709: 0.92732644, 1669: 0.9330869, 1362: 0.9414874, 839: 0.94093543, 957: 0.93373066, 918: 0.9278364, 1184: 0.9324673, 1545: 0.93799776, 1118: 0.9352522, 208: 0.9334316, 161: 0.9266924, 1435: 0.93577844, 606: 0.930209, 378: 0.9329815, 998: 0.922797, 1060: 0.93021417, 636: 0.9347509, 310: 0.9335181, 540: 0.935145, 1552: 0.9266737, 902: 0.9242417, 108: 0.9340384, 2: 0.91572833, 1486: 0.9452793, 1427: 0.9405478, 1645: 0.9337002, 514: 0.9300413, 535: 0.93215847, 1049: 0.9396449, 1541: 0.9329846, 217: 0.9346439, 1274: 0.927961, 1374: 0.93156946, 971: 0.92873794, 1535: 0.9342045, 1499: 0.92875385, 1412: 0.9266481, 1586: 0.9396834, 743: 0.9300375, 1682: 0.92953014, 975: 0.9272968, 1445: 0.92934704, 586: 0.9379921, 1252: 0.9293442, 567: 0.9437617, 819: 0.9388683, 1210: 0.9235764, 763: 0.93163556, 489: 0.93375164, 254: 0.93619806, 1108: 0.92852545, 543: 0.92793125, 570: 0.9286286, 771: 0.9453769, 38: 0.94045514, 925: 0.94031703, 792: 0.92755467, 1600: 0.9369545, 399: 0.9327459, 22: 0.9321319, 1564: 0.9412271, 407: 0.9450844, 916: 0.9364473, 897: 0.9380303, 356: 0.92377067, 185: 0.9381599, 127: 0.93088585, 115: 0.92979306, 1512: 0.93864685, 1018: 0.9359314, 181: 0.9322474, 602: 0.93702304, 467: 0.92335206, 132: 0.9288406, 647: 0.94462764, 1424: 0.93528116, 1262: 0.9288226, 585: 0.94036186, 1690: 0.9396017, 755: 0.9250652, 938: 0.9294257, 1587: 0.93715423, 610: 0.93378055, 471: 0.9386731, 215: 0.93774426, 335: 0.9329829, 1013: 0.9311688, 1404: 0.93130493, 373: 0.92924565, 1223: 0.9386237, 1216: 0.93780357, 1438: 0.9398334, 60: 0.9383602, 689: 0.9411312, 109: 0.9411906, 1720: 0.9374989, 1702: 0.92623895, 306: 0.9463295, 1322: 0.93550795, 1158: 0.93657434, 1463: 0.9378758, 433: 0.9304833, 375: 0.9319281, 465: 0.93287075, 620: 0.93263274, 23: 0.9297468, 754: 0.9416457, 1521: 0.93909174, 257: 0.9404721, 1286: 0.9427346, 264: 0.93580174, 1105: 0.93165886, 195: 0.93620497, 1318: 0.9398114, 833: 0.929224, 597: 0.9267948, 1294: 0.9208237, 481: 0.9312191, 204: 0.93233925, 737: 0.9271549, 1567: 0.92968386, 531: 0.9462108, 206: 0.92674536, 1281: 0.9345817, 1430: 0.92886204, 318: 0.9353553, 1267: 0.92498094, 1460: 0.9223951, 804: 0.9368239, 699: 0.9262783, 1361: 0.9380263, 490: 0.93973434, 53: 0.93028706, 887: 0.92788786, 568: 0.9293353, 1371: 0.9279858, 811: 0.9296069, 890: 0.93955016, 1532: 0.9353845, 164: 0.9380008, 782: 0.9240012, 769: 0.9288052, 1103: 0.93874156, 598: 0.93271893, 237: 0.932999, 1547: 0.92470056, 592: 0.9287191, 1191: 0.92796993, 1447: 0.9211066, 654: 0.9344651, 596: 0.9337845, 1608: 0.9281705, 1695: 0.92840415, 1306: 0.93291247, 962: 0.93531966, 428: 0.92375183, 712: 0.9402435, 457: 0.93131465, 46: 0.9417924, 562: 0.93799126, 317: 0.9280381, 142: 0.92802125, 894: 0.9293176, 847: 0.92816883, 1125: 0.9456834, 1612: 0.943222, 96: 0.92537576, 1127: 0.92766905, 1542: 0.93393177, 1227: 0.94127893, 90: 0.9378349, 1155: 0.9280307, 1516: 0.9177332, 321: 0.93716395, 1342: 0.9251578, 229: 0.9435377, 274: 0.92991006, 1285: 0.93687457, 709: 0.92602974, 1550: 0.9289866, 1211: 0.92872804, 1642: 0.9398294, 1301: 0.9367735, 593: 0.924509, 1183: 0.9389711, 492: 0.9402237, 291: 0.92407286, 210: 0.9291776, 65: 0.94300884, 547: 0.9239309, 544: 0.930888, 186: 0.9367059, 1525: 0.9219369, 789: 0.9263669, 1480: 0.93599457, 124: 0.9376944, 1021: 0.93579316, 1472: 0.9370856, 1694: 0.9389028, 1005: 0.9369143, 91: 0.9363543, 1429: 0.94212717, 738: 0.92397714, 1030: 0.9422808, 972: 0.94123465, 89: 0.92592555, 826: 0.92411226, 171: 0.9395598, 1075: 0.9315699, 1282: 0.9377846, 853: 0.94471633, 760: 0.94156176, 1514: 0.940106, 932: 0.9357009, 162: 0.9298534, 880: 0.9308593, 777: 0.92835575, 1325: 0.9379698, 1616: 0.9355511, 1627: 0.9314216, 207: 0.9431925, 1206: 0.92950267, 430: 0.9331552, 1566: 0.93124723, 669: 0.93580997, 762: 0.9407572, 1539: 0.929469, 1459: 0.93635815, 151: 0.91997135, 1467: 0.9431874, 1017: 0.9332184, 1711: 0.9210154, 942: 0.9374017, 347: 0.9286394, 180: 0.9301855, 1703: 0.9414878, 1115: 0.9351279, 989: 0.93378097, 135: 0.9290669, 1387: 0.94154555, 3: 0.92452765, 1592: 0.93441635, 1292: 0.9420072, 1270: 0.9320259, 1265: 0.9377765, 533: 0.9376914, 905: 0.93487406, 1649: 0.9222925, 372: 0.9338634, 1305: 0.9384654, 192: 0.9340802, 988: 0.9302568, 885: 0.92516774, 860: 0.93200356, 1302: 0.9411564, 1138: 0.9367143, 298: 0.939081, 275: 0.93869454, 649: 0.9406773, 778: 0.93107367, 1528: 0.9248399, 1708: 0.9356033, 434: 0.9402612, 1111: 0.92906696, 1295: 0.93539476, 1574: 0.9231562, 820: 0.9423189, 947: 0.9358005, 1484: 0.9384965, 165: 0.92021173, 101: 0.9355861, 1364: 0.9249258, 715: 0.9274926, 1629: 0.9330752, 794: 0.92520225, 285: 0.93710566, 571: 0.9399367, 64: 0.92638624, 1453: 0.9286716, 1581: 0.9391853, 911: 0.9370286, 850: 0.9365451, 403: 0.9276212, 930: 0.9298543, 1055: 0.9451265, 1381: 0.9440982, 420: 0.92387503, 1259: 0.927128, 556: 0.9334711, 459: 0.93481344, 1159: 0.93537736, 870: 0.92554003, 36: 0.93746275, 1046: 0.9340698, 1218: 0.9308079, 1540: 0.92703027, 1053: 0.94206095, 1456: 0.9306488, 1636: 0.9339375, 355: 0.93000376, 1025: 0.9338013, 1119: 0.9427206, 904: 0.9392655, 1568: 0.9303864, 1335: 0.9262998, 1704: 0.92090416, 1417: 0.9346474, 1040: 0.93968856, 1440: 0.9252801, 631: 0.928386, 371: 0.9309466, 282: 0.9230298, 1144: 0.9346753, 834: 0.9266987, 697: 0.9370572, 878: 0.9357056, 1122: 0.9418363, 452: 0.9328913, 466: 0.93431187, 408: 0.9209396, 242: 0.9419891, 1042: 0.93679816, 387: 0.9303288, 1329: 0.9395286, 247: 0.9347126, 157: 0.9334802, 1078: 0.9215089, 1316: 0.92682433, 442: 0.9292747, 624: 0.92462087, 1308: 0.928103, 99: 0.92883396, 1683: 0.9388367, 1507: 0.9323631, 913: 0.92683333, 1498: 0.9315246, 652: 0.9414814, 595: 0.9383234, 296: 0.9440903, 27: 0.9235587, 299: 0.9347186, 1455: 0.9224851, 21: 0.9283215, 245: 0.9311746, 367: 0.9378426, 1610: 0.928517, 779: 0.936495, 517: 0.9249713, 1297: 0.9256275, 174: 0.9393196, 1143: 0.9253401, 1398: 0.9276339, 1602: 0.9375778, 1715: 0.9320805, 406: 0.9259856, 1451: 0.924507, 169: 0.936534, 1599: 0.9385993, 440: 0.93575984, 910: 0.9290853, 405: 0.9258336, 1553: 0.9148819, 122: 0.940487, 178: 0.9327136, 1506: 0.9395358, 346: 0.9373124, 246: 0.94000393, 1572: 0.93426496, 1150: 0.93653136, 427: 0.9260789, 153: 0.9364325, 1607: 0.9280532, 1337: 0.93088615, 1083: 0.925736, 1076: 0.9244609, 908: 0.93033004, 44: 0.93473047, 1527: 0.92320144, 77: 0.9341293, 1696: 0.9395077, 1001: 0.9216115, 147: 0.9265947, 1: 0.9323117, 1175: 0.9276478, 1107: 0.9381006, 82: 0.91777694, 389: 0.9328241, 1326: 0.9381352, 611: 0.9376149, 1691: 0.91319686, 955: 0.9312592, 1026: 0.9378705, 1353: 0.9420954, 1714: 0.94313216, 845: 0.9358982, 1112: 0.92987305, 1358: 0.93918025, 482: 0.9309054, 1400: 0.92057335, 1137: 0.9449919, 822: 0.93472767, 1168: 0.94075197, 859: 0.9230027, 840: 0.94253516, 1718: 0.9294354, 732: 0.9432678, 31: 0.9265583, 1045: 0.9374536, 409: 0.9337708, 973: 0.931888, 1120: 0.9384463, 1686: 0.9227876, 1303: 0.9443517, 453: 0.92754084, 499: 0.9318374, 680: 0.9405704, 95: 0.93969464, 863: 0.93746924, 725: 0.9404592, 308: 0.94047457, 844: 0.9464357, 107: 0.94126225, 1071: 0.93049175, 1132: 0.93961203, 519: 0.9210466, 550: 0.9352408, 666: 0.9248857, 1336: 0.9365189, 650: 0.9306165, 1289: 0.9305938, 1271: 0.92472667, 1047: 0.93143874, 1123: 0.9426775, 1716: 0.93472946, 444: 0.9423373, 731: 0.92380893, 212: 0.9317308, 594: 0.93673664, 872: 0.93845123, 145: 0.9274868, 477: 0.93972474, 268: 0.936161, 59: 0.93807447, 1713: 0.9204638, 625: 0.92249227, 179: 0.940265, 1491: 0.92532367, 739: 0.93559456, 609: 0.9405697, 218: 0.94289076, 723: 0.92982316, 431: 0.92979944, 472: 0.9302934, 1443: 0.9390668, 263: 0.9412903, 1029: 0.94362307, 980: 0.92721903, 222: 0.91378766, 1003: 0.9295522, 1523: 0.9342348, 1307: 0.932496, 892: 0.92503756, 812: 0.9439045, 413: 0.93133855, 572: 0.93720007, 1069: 0.9238648, 1419: 0.93442833, 915: 0.928951, 163: 0.9381755, 1197: 0.9367998, 326: 0.9294775, 858: 0.933653, 1239: 0.92681754, 131: 0.93236977, 358: 0.92948604, 48: 0.9316867, 1722: 0.93502337, 98: 0.93682635, 333: 0.92860633, 869: 0.9318526, 29: 0.92820674, 698: 0.93196183, 1367: 0.93678665, 526: 0.9333277, 1109: 0.94380313, 1034: 0.9307936, 985: 0.93212825, 1130: 0.92573565, 1129: 0.92961943, 899: 0.924901, 658: 0.93420553, 97: 0.9405949, 787: 0.9278287, 1618: 0.92147744, 485: 0.92765266, 1681: 0.9372113, 1350: 0.91873324, 441: 0.9255831, 1196: 0.94331425, 110: 0.9358419, 1556: 0.93845, 532: 0.93292105, 991: 0.93685794, 634: 0.9218492, 1483: 0.9408277, 461: 0.94345295, 677: 0.94143903, 886: 0.93585676, 446: 0.93625546, 646: 0.93621653, 1152: 0.92260695, 1464: 0.9207386, 682: 0.93907535, 202: 0.9222498, 155: 0.927902, 172: 0.93510604, 513: 0.9324587, 200: 0.93383, 1121: 0.94388056, 1628: 0.928277, 1375: 0.9396453, 744: 0.9432726, 1024: 0.92651445, 655: 0.92590165, 758: 0.9360626, 205: 0.93960285, 47: 0.9355223, 382: 0.9349359, 1634: 0.92495096, 1351: 0.93495405, 718: 0.9246871, 1095: 0.938945, 1508: 0.94078803, 1091: 0.9277411, 601: 0.92539364, 1588: 0.9393192, 1432: 0.9327309, 868: 0.9265701, 566: 0.9383937, 1015: 0.93348897, 1110: 0.93460846, 922: 0.9327299, 1468: 0.9356248, 1662: 0.9334093, 58: 0.94347227, 1090: 0.93888134, 1249: 0.93172914, 719: 0.9383858, 1373: 0.9325858, 1157: 0.93697786, 1234: 0.93792415, 1237: 0.9205543, 936: 0.9293824, 548: 0.9327636, 1343: 0.9279683, 1061: 0.9248588, 1725: 0.9282184, 1277: 0.94025844, 78: 0.9434663, 302: 0.93432134, 1011: 0.93427736, 284: 0.92392355, 119: 0.9385366, 518: 0.92439103, 1149: 0.9355286, 823: 0.94377995, 1363: 0.9149773, 775: 0.9393474, 133: 0.938235, 287: 0.92892396, 424: 0.92588776, 1555: 0.93891644, 51: 0.9324123, 1388: 0.9218149, 1349: 0.93627965, 927: 0.93549675, 1006: 0.9354244, 139: 0.93487436, 1442: 0.94064224, 230: 0.93184, 104: 0.93351126, 508: 0.9325955, 1314: 0.94156164, 1675: 0.9476189, 343: 0.937793, 883: 0.9350655, 1139: 0.9336294, 1243: 0.9315178, 502: 0.94258195, 1101: 0.93087053, 1585: 0.94077843, 1058: 0.9382093, 1726: 0.9246375, 244: 0.92343414, 941: 0.93988645, 1671: 0.9244306, 278: 0.93367606, 711: 0.92080367, 1089: 0.92899257, 484: 0.9344398, 943: 0.92385024, 1096: 0.93924063, 856: 0.9326783, 1663: 0.9235174, 111: 0.93540454, 1039: 0.9297269, 710: 0.9264699, 1012: 0.91953844, 565: 0.92727363, 305: 0.9411847, 1392: 0.94307303, 177: 0.9361234, 1515: 0.9397025, 626: 0.92205894, 1457: 0.93277717, 232: 0.93819356, 817: 0.9340932, 1309: 0.9350976, 672: 0.9368739, 251: 0.924461, 1530: 0.9224289, 241: 0.9315942, 63: 0.93656975, 199: 0.9265997, 622: 0.934431, 209: 0.9250966, 1052: 0.92752844, 1082: 0.9339394, 1667: 0.9270101, 1266: 0.9299892, 216: 0.92491263, 965: 0.92546445, 39: 0.93434894, 1357: 0.92759985, 1461: 0.9352253, 1263: 0.94152784, 790: 0.9264821, 992: 0.9365545, 357: 0.9324399, 470: 0.9368995, 52: 0.93899345, 884: 0.9372824, 515: 0.9381691, 695: 0.934511, 454: 0.927218, 1561: 0.93231803, 855: 0.92901874}, 'azure/Phi-3-small-8k-instruct': {182: 0.9629114, 825: 0.9421819, 1240: 0.7849695, 505: 0.96862274, 1482: 0.9177633, 1549: 0.9270324, 842: 0.95065475, 1605: 0.9329969, 386: 0.9609994, 1622: 0.6869699, 1182: 0.9691056, 1212: 0.9711288, 487: 0.94205606, 148: 0.94032073, 661: 0.96573967, 950: 0.97210354, 393: 0.9463253, 1056: 0.89394736, 259: 0.9771945, 1415: 0.9569485, 523: 0.9678822, 353: 0.9480548, 1391: 0.9732573, 874: 0.9273871, 12: 0.96115303, 1700: 0.97610086, 527: 0.95504487, 496: 0.9124463, 483: 0.74687415, 365: 0.94899994, 674: 0.96395695, 93: 0.9349642, 729: 0.9513796, 370: 0.9591952, 714: 0.945984, 898: 0.9687298, 1344: 0.9680513, 831: 0.944005, 1723: 0.975864, 203: 0.97244227, 345: 0.96374875, 67: 0.9632589, 1383: 0.9651644, 319: 0.9620662, 852: 0.97795504, 1311: 0.9716907, 45: 0.9382594, 582: 0.9399151, 791: 0.9483259, 781: 0.9489311, 221: 0.8227258, 316: 0.9461263, 857: 0.7467539, 578: 0.9613015, 137: 0.96590436, 639: 0.8945529, 1257: 0.9620475, 390: 0.9607756, 5: 0.96467775, 628: 0.93501085, 1402: 0.96791506, 806: 0.9628804, 243: 0.9075366, 720: 0.9463034, 919: 0.9595088, 491: 0.96269083, 768: 0.7543563, 35: 0.92179304, 462: 0.6884416, 414: 0.97131616, 475: 0.8789156, 301: 0.96111786, 923: 0.9762024, 815: 0.8995996, 558: 0.96042144, 1458: 0.963639, 25: 0.87218124, 810: 0.9725902, 557: 0.9641573, 1368: 0.9573534, 369: 0.96458054, 1470: 0.97236776, 57: 0.9188665, 152: 0.9691711, 307: 0.94821703, 1598: 0.96477103, 1380: 0.8907714, 159: 0.93514836, 1382: 0.96410567, 509: 0.732147, 1665: 0.8651711, 615: 0.97032106, 404: 0.96293914, 396: 0.9450229, 1423: 0.94721746, 1179: 0.9558601, 224: 0.9720463, 1084: 0.9648393, 1359: 0.9655321, 660: 0.9525973, 1099: 0.97263116, 590: 0.9649194, 290: 0.9545686, 1548: 0.90732616, 1420: 0.96995306, 1410: 0.9763941, 967: 0.9526657, 979: 0.8921181, 1421: 0.97568387, 512: 0.9199285, 198: 0.8625551, 102: 0.9618677, 479: 0.9605587, 678: 0.91623944, 970: 0.96871424, 1135: 0.9692304, 1583: 0.96418655, 1028: 0.9674335, 397: 0.9723344, 1522: 0.93009037, 555: 0.9705932, 293: 0.9700115, 1504: 0.8159877, 1167: 0.81540424, 1360: 0.95343727, 1469: 0.9232953, 1081: 0.9508515, 1192: 0.9603251, 538: 0.9722534, 924: 0.9717041, 394: 0.96865135, 1606: 0.93596596, 1397: 0.7080095, 105: 0.7750213, 997: 0.9584926, 144: 0.91570944, 1288: 0.9355344, 1272: 0.965719, 100: 0.92628884, 1579: 0.9406951, 1557: 0.92592597, 564: 0.9242409, 501: 0.83872604, 613: 0.97148174, 757: 0.9701183, 1475: 0.95092404, 865: 0.9618591, 1571: 0.96034247, 1511: 0.77331424, 785: 0.9384785, 1251: 0.95413953, 1490: 0.9704897, 1481: 0.96306473, 24: 0.96178424, 648: 0.926941, 149: 0.95932966, 1339: 0.929458, 843: 0.96181047, 253: 0.92730945, 379: 0.96525127, 1575: 0.9636568, 272: 0.97796375, 670: 0.89222246, 1502: 0.9343997, 1657: 0.93905044, 996: 0.9049635, 702: 0.9738677, 276: 0.9574563, 1070: 0.9655066, 1462: 0.9757878, 603: 0.9631957, 588: 0.94063824, 733: 0.9454229, 220: 0.95527285, 542: 0.95059973, 1355: 0.9598848, 1352: 0.9527838, 197: 0.9776814, 449: 0.7977508, 334: 0.9747738, 614: 0.96188813, 451: 0.96212894, 691: 0.9759395, 681: 0.9630591, 1626: 0.944351, 766: 0.96338505, 665: 0.82048005, 616: 0.9623694, 612: 0.9723752, 154: 0.8777188, 190: 0.96990955, 15: 0.9645344, 1268: 0.9406498, 8: 0.87652767, 1296: 0.81875217, 329: 0.9438849, 1611: 0.95587295, 1678: 0.94257784, 780: 0.9645497, 4: 0.83931094, 1661: 0.45010188, 1293: 0.9704352, 294: 0.9613696, 1637: 0.9118988, 1365: 0.93892, 686: 0.97219735, 1333: 0.9567867, 1474: 0.92678875, 759: 0.9336791, 1584: 0.9182044, 504: 0.9573991, 395: 0.7866496, 1573: 0.9504024, 240: 0.9216882, 92: 0.9577708, 85: 0.8821705, 1146: 0.9432538, 735: 0.952357, 1140: 0.94296443, 528: 0.8196562, 1510: 0.89144546, 495: 0.81513405, 574: 0.96368665, 627: 0.82181555, 261: 0.9168408, 1298: 0.9595575, 1232: 0.8238058, 1648: 0.9575247, 821: 0.96544904, 94: 0.9697341, 1495: 0.9391868, 437: 0.93886334, 280: 0.9624878, 120: 0.95828515, 1597: 0.88016725, 520: 0.9604597, 42: 0.9458759, 498: 0.9743302, 1633: 0.9247617, 1092: 0.9741666, 835: 0.975022, 1043: 0.95939976, 1181: 0.9723636, 300: 0.91745186, 920: 0.96414244, 86: 0.96216327, 1569: 0.95333433, 1476: 0.913483, 1166: 0.9754556, 1016: 0.97279876, 79: 0.9635122, 752: 0.95442855, 986: 0.9601211, 1399: 0.93677294, 1496: 0.9753254, 516: 0.95466894, 1580: 0.9374272, 75: 0.95464927, 969: 0.9285205, 41: 0.5048081, 158: 0.9634551, 1596: 0.966932, 138: 0.8940461, 832: 0.9738756, 645: 0.9585826, 252: 0.70655096, 724: 0.94388086, 561: 0.95029646, 337: 0.96706724, 1176: 0.91078293, 960: 0.9536108, 1719: 0.9299574, 1591: 0.81201446, 61: 0.94291896, 1142: 0.96145904, 1169: 0.96926695, 1331: 0.9652551, 1465: 0.93154734, 539: 0.95631003, 1631: 0.9773203, 312: 0.9722714, 415: 0.9659664, 747: 0.9516842, 953: 0.96242577, 50: 0.96083283, 1638: 0.9721396, 1699: 0.9647445, 1407: 0.86403, 1560: 0.8417589, 340: 0.9050074, 608: 0.9510213, 524: 0.9430427, 638: 0.9435879, 213: 0.9222602, 1519: 0.96245724, 1356: 0.9525294, 889: 0.9603565, 304: 0.96246463, 1276: 0.9218898, 659: 0.8702297, 801: 0.96779513, 796: 0.8603564, 1093: 0.9538965, 425: 0.95914125, 876: 0.96355236, 381: 0.9128667, 106: 0.8847537, 128: 0.9651097, 1705: 0.96039426, 1098: 0.9405159, 829: 0.8822078, 788: 0.95845556, 248: 0.77199817, 34: 0.90541977, 632: 0.95727235, 1698: 0.9664559, 9: 0.9236702, 418: 0.9268432, 40: 0.9539346, 604: 0.96189195, 1235: 0.94954747, 577: 0.96125036, 1666: 0.9614946, 1245: 0.9540086, 1673: 0.9698542, 1684: 0.94787997, 68: 0.96003026, 629: 0.96078146, 11: 0.97556555, 1394: 0.3990943, 1582: 0.9615943, 1471: 0.8882391, 384: 0.9433078, 987: 0.9520092, 54: 0.6455746, 944: 0.9709579, 1697: 0.7922233, 809: 0.8802224, 675: 0.95161164, 1219: 0.94605, 309: 0.9483899, 1048: 0.61592585, 1051: 0.95932114, 1204: 0.96646166, 436: 0.97054446, 643: 0.92854947, 981: 0.97026306, 827: 0.9571132, 1377: 0.9579272, 1173: 0.96130955, 551: 0.9467053, 1073: 0.96422744, 412: 0.9447517, 1097: 0.96806717, 363: 0.9551898, 322: 0.9508703, 968: 0.96008456, 907: 0.9590129, 331: 0.96294713, 1086: 0.8940287, 507: 0.96915674, 940: 0.7759014, 1536: 0.8090934, 828: 0.9019865, 786: 0.93103987, 1444: 0.93254614, 534: 0.95642734, 297: 0.94347256, 635: 0.96791714, 581: 0.90352094, 1258: 0.89231247, 1604: 0.9608909, 136: 0.777139, 939: 0.956972, 1500: 0.9653185, 269: 0.96075195, 288: 0.9686497, 1224: 0.9635323, 1493: 0.9596677, 1340: 0.95388144, 260: 0.96398455, 362: 0.9667231, 722: 0.93221766, 1248: 0.9562031, 767: 0.93948394, 866: 0.9595417, 875: 0.9697001, 756: 0.9571665, 706: 0.95967525, 1376: 0.9661559, 49: 0.9757614, 1595: 0.9771004, 935: 0.950407, 984: 0.9613537, 679: 0.85953546, 188: 0.9538028, 1186: 0.96273494, 848: 0.95895684, 1685: 0.90311444, 1724: 0.96282166, 1414: 0.96106327, 1354: 0.9544582, 281: 0.9517826, 522: 0.951507, 1677: 0.9772183, 103: 0.9586104, 456: 0.964872, 644: 0.67280155, 1228: 0.9145043, 895: 0.9150744, 541: 0.94439995, 1128: 0.9598756, 1323: 0.75592196, 830: 0.93112534, 1554: 0.97439086, 1020: 0.9732179, 1603: 0.97354966, 1538: 0.92833114, 377: 0.94610023, 473: 0.96889806, 398: 0.9733881, 419: 0.9730578, 129: 0.8114202, 1156: 0.97671074, 1275: 0.9438681, 360: 0.94288844, 751: 0.9672665, 1106: 0.95373994, 1437: 0.9618918, 673: 0.9465138, 1578: 0.9581303, 891: 0.9677989, 599: 0.97102284, 351: 0.9020034, 882: 0.94776505, 1036: 0.94581807, 1721: 0.9424313, 1134: 0.9724387, 1153: 0.95513785, 1074: 0.92181116, 901: 0.9699405, 17: 0.9575769, 286: 0.9616334, 344: 0.85571367, 359: 0.9360141, 749: 0.95934594, 348: 0.9700323, 1446: 0.9773117, 249: 0.95207715, 914: 0.9740927, 1347: 0.9262053, 1231: 0.94488055, 929: 0.9587856, 864: 0.9392093, 1190: 0.9523562, 7: 0.9579081, 1198: 0.9429275, 851: 0.9667612, 1384: 0.8805143, 201: 0.9722962, 1450: 0.8550285, 480: 0.93165785, 1113: 0.937143, 1077: 0.9636612, 867: 0.9677384, 18: 0.9687076, 1131: 0.97185826, 1619: 0.9672492, 1346: 0.963419, 862: 0.73667437, 1050: 0.97171336, 74: 0.97234523, 770: 0.96743953, 1085: 0.9128423, 982: 0.94938874, 170: 0.96241784, 464: 0.94599164, 696: 0.9670085, 1544: 0.75484204, 223: 0.97331166, 1038: 0.90765005, 1280: 0.83161986, 1366: 0.97064006, 1479: 0.9705949, 974: 0.9714488, 83: 0.9663983, 814: 0.9590282, 1433: 0.9680903, 1203: 0.96748793, 270: 0.90662956, 1054: 0.96861166, 1624: 0.943438, 383: 0.96819156, 1385: 0.9670204, 1505: 0.93972856, 1485: 0.91297334, 1080: 0.960441, 1023: 0.89710546, 20: 0.939533, 1067: 0.93804145, 385: 0.96365756, 332: 0.97199744, 903: 0.962451, 324: 0.9163796, 227: 0.7276353, 1408: 0.9751057, 1389: 0.94675434, 1488: 0.96066725, 439: 0.96595377, 361: 0.9670711, 1654: 0.9399699, 753: 0.88827556, 1425: 0.9632376, 990: 0.9647261, 554: 0.7274613, 909: 0.90379214, 1180: 0.9611315, 888: 0.96314657, 958: 0.957099, 530: 0.9716471, 1441: 0.95508033, 469: 0.96056473, 1233: 0.85236126, 1215: 0.9716185, 368: 0.92573166, 1520: 0.94585985, 1570: 0.96152955, 1124: 0.7419727, 560: 0.9483535, 928: 0.93613714, 266: 0.97151506, 1236: 0.8948617, 460: 0.9718807, 1546: 0.9643131, 500: 0.9638079, 1133: 0.9612432, 1031: 0.9691112, 325: 0.97550565, 802: 0.8382285, 476: 0.9563185, 730: 0.9651309, 250: 0.9578455, 765: 0.9490606, 900: 0.87977767, 421: 0.90345377, 685: 0.9467896, 70: 0.8026937, 1247: 0.9307552, 799: 0.8895838, 16: 0.92913973, 1396: 0.9274281, 211: 0.87129784, 113: 0.9714712, 87: 0.8771517, 1037: 0.9390839, 1170: 0.9518172, 1014: 0.9269483, 80: 0.96730673, 1655: 0.9702654, 1533: 0.9316747, 1422: 0.9701474, 1162: 0.9643703, 978: 0.9592952, 1674: 0.9567367, 1154: 0.96336335, 748: 0.9582302, 1526: 0.962976, 703: 0.88657457, 349: 0.94857, 315: 0.9646916, 1321: 0.9615477, 289: 0.95765746, 1658: 0.94200104, 295: 0.9349253, 1348: 0.8999957, 1284: 0.96345997, 1379: 0.95833564, 1225: 0.9611472, 400: 0.9134921, 1660: 0.9619333, 1220: 0.9324349, 1395: 0.70775795, 1701: 0.95067966, 684: 0.97504234, 553: 0.9366637, 62: 0.90159255, 1283: 0.957341, 313: 0.899748, 262: 0.96237755, 1200: 0.9602798, 69: 0.9605656, 1577: 0.94365716, 1253: 0.9197913, 854: 0.97122204, 734: 0.9640911, 66: 0.96401656, 1614: 0.9539345, 708: 0.95585346, 559: 0.8329393, 1213: 0.67765385, 966: 0.9580292, 795: 0.96748716, 116: 0.64756006, 303: 0.94135463, 1632: 0.97536045, 563: 0.87697995, 374: 0.96288985, 402: 0.96664286, 10: 0.8718118, 1209: 0.95765764, 793: 0.96474373, 474: 0.93851304, 896: 0.92992276, 1242: 0.9706863, 271: 0.960375, 589: 0.9646685, 1217: 0.8802325, 417: 0.9412519, 497: 0.94610846, 1639: 0.8925362, 656: 0.9206038, 196: 0.95906186, 653: 0.95461136, 1222: 0.96407926, 118: 0.9728343, 994: 0.9730698, 949: 0.9561951, 912: 0.73781866, 0: 0.95985305, 1452: 0.9539209, 1492: 0.6471633, 130: 0.9535401, 713: 0.39894307, 1593: 0.9710599, 1063: 0.9619636, 1334: 0.9630748, 1199: 0.96364415, 1717: 0.9525563, 391: 0.96019286, 1620: 0.9628254, 1411: 0.68418497, 701: 0.9235325, 1478: 0.9722322, 704: 0.92867386, 125: 0.8259371, 1551: 0.8926074, 1019: 0.92069733, 273: 0.94025224, 1529: 0.95181495, 1559: 0.8808909, 447: 0.96916294, 236: 0.94337666, 956: 0.94170547, 81: 0.965578, 761: 0.9558261, 600: 0.95714843, 1185: 0.96677643, 235: 0.96973544, 1656: 0.9750251, 1406: 0.96629626, 1647: 0.9563847, 468: 0.9270573, 28: 0.8152564, 1672: 0.8622387, 1589: 0.9481109, 1250: 0.67275184, 1707: 0.9671165, 350: 0.9730907, 976: 0.947446, 740: 0.9627577, 1194: 0.9637201, 1454: 0.93437785, 1693: 0.960594, 1022: 0.9598851, 871: 0.96075153, 1537: 0.9328095, 1372: 0.9655628, 401: 0.95164514, 255: 0.9647107, 977: 0.8061313, 175: 0.9258155, 705: 0.959945, 964: 0.9381711, 797: 0.92351264, 380: 0.90842813, 1386: 0.9469101, 1007: 0.9743766, 1205: 0.927865, 234: 0.88597447, 584: 0.9572469, 1680: 0.91303205, 1230: 0.69466645, 1041: 0.95626485, 426: 0.9632262, 1032: 0.95225924, 1065: 0.97318304, 277: 0.9383041, 1164: 0.9719616, 736: 0.96518886, 173: 0.9282054, 1576: 0.91185457, 906: 0.9593086, 1256: 0.39991382, 963: 0.9615216, 587: 0.97174376, 26: 0.9399397, 774: 0.7829113, 150: 0.9570279, 651: 0.9726996, 1405: 0.9771035, 1174: 0.9604955, 926: 0.94946235, 1114: 0.963507, 1613: 0.97728544, 700: 0.9706711, 1687: 0.9641399, 366: 0.8121077, 1434: 0.67247653, 1689: 0.9487244, 959: 0.9610478, 683: 0.97324705, 114: 0.9452831, 1403: 0.9625216, 1477: 0.96703243, 6: 0.96876234, 1088: 0.73570365, 545: 0.96504277, 510: 0.9706021, 1473: 0.9654469, 641: 0.9755622, 1116: 0.9540627, 1141: 0.9717416, 671: 0.9463554, 1100: 0.9231563, 1712: 0.9192609, 1709: 0.93368584, 1669: 0.9410503, 1362: 0.95799494, 839: 0.97391605, 957: 0.8984232, 918: 0.9617152, 1184: 0.9580046, 1545: 0.97458524, 1118: 0.95350564, 208: 0.8219815, 161: 0.96823364, 1435: 0.9084898, 606: 0.93586135, 378: 0.95573485, 998: 0.9378346, 1060: 0.9542906, 636: 0.9540833, 310: 0.9723489, 540: 0.97446793, 1552: 0.9309195, 902: 0.96258384, 108: 0.9592333, 2: 0.9736891, 1486: 0.96922594, 1427: 0.9512874, 1645: 0.9643884, 514: 0.9160205, 535: 0.95303464, 1049: 0.9641081, 1541: 0.9754784, 217: 0.9720867, 1274: 0.96783596, 1374: 0.8550509, 971: 0.9380089, 1535: 0.95937675, 1499: 0.91150045, 1412: 0.965948, 1586: 0.96748203, 743: 0.9673255, 1682: 0.9537315, 975: 0.9637854, 1445: 0.9518127, 586: 0.95625234, 1252: 0.91571033, 567: 0.9636435, 819: 0.86384887, 1210: 0.9597339, 763: 0.94866186, 489: 0.93932414, 254: 0.9657705, 1108: 0.3941098, 543: 0.7797426, 570: 0.9210898, 771: 0.9552038, 38: 0.97041154, 925: 0.9729566, 792: 0.92159265, 1600: 0.9371915, 399: 0.9625357, 22: 0.96300584, 1564: 0.95566505, 407: 0.96399355, 916: 0.9613988, 897: 0.9014161, 356: 0.6347279, 185: 0.96375054, 127: 0.95341605, 115: 0.97214174, 1512: 0.9088433, 1018: 0.9358778, 181: 0.9558697, 602: 0.8211329, 467: 0.944865, 132: 0.8884005, 647: 0.96687526, 1424: 0.7764523, 1262: 0.9701919, 585: 0.96354276, 1690: 0.9710122, 755: 0.8400733, 938: 0.96031415, 1587: 0.9279406, 610: 0.9748513, 471: 0.9732484, 215: 0.9606752, 335: 0.96925247, 1013: 0.9548867, 1404: 0.9066036, 373: 0.95314944, 1223: 0.9766847, 1216: 0.96305174, 1438: 0.9469853, 60: 0.96410334, 689: 0.9493953, 109: 0.96796477, 1720: 0.95964664, 1702: 0.91752446, 306: 0.97405136, 1322: 0.96902734, 1158: 0.95012605, 1463: 0.95640594, 433: 0.9362498, 375: 0.9769796, 465: 0.9611976, 620: 0.91102797, 23: 0.6959841, 754: 0.9714091, 1521: 0.95519286, 257: 0.966806, 1286: 0.9665708, 264: 0.95064235, 1105: 0.9539053, 195: 0.9497786, 1318: 0.9767273, 833: 0.94447047, 597: 0.9506821, 1294: 0.9163171, 481: 0.970066, 204: 0.9636852, 737: 0.929088, 1567: 0.9430148, 531: 0.9699249, 206: 0.9510436, 1281: 0.95778745, 1430: 0.95264035, 318: 0.95491236, 1267: 0.9340193, 1460: 0.71122277, 804: 0.96246374, 699: 0.9002413, 1361: 0.97487634, 490: 0.95662975, 53: 0.9555681, 887: 0.959338, 568: 0.93808955, 1371: 0.88303274, 811: 0.84817666, 890: 0.9716897, 1532: 0.93116, 164: 0.97112536, 782: 0.95444494, 769: 0.9396872, 1103: 0.9646421, 598: 0.9466876, 237: 0.97341305, 1547: 0.9477459, 592: 0.95953935, 1191: 0.9402673, 1447: 0.959311, 654: 0.93937296, 596: 0.94882005, 1608: 0.95413196, 1695: 0.9425788, 1306: 0.9593052, 962: 0.94667304, 428: 0.890733, 712: 0.96815634, 457: 0.9665237, 46: 0.9600653, 562: 0.95208323, 317: 0.9273657, 142: 0.9328389, 894: 0.951104, 847: 0.974163, 1125: 0.963652, 1612: 0.97098786, 96: 0.9510556, 1127: 0.87336147, 1542: 0.9289504, 1227: 0.95388114, 90: 0.96130455, 1155: 0.92760146, 1516: 0.9570917, 321: 0.9446766, 1342: 0.93051606, 229: 0.9272333, 274: 0.96761346, 1285: 0.9704779, 709: 0.8265989, 1550: 0.9501068, 1211: 0.40228057, 1642: 0.97743636, 1301: 0.93963814, 593: 0.8051404, 1183: 0.9581779, 492: 0.94667464, 291: 0.93996483, 210: 0.9213361, 65: 0.9656885, 547: 0.9629407, 544: 0.9449636, 186: 0.9453016, 1525: 0.9510378, 789: 0.718507, 1480: 0.9671504, 124: 0.97062355, 1021: 0.95026666, 1472: 0.9696833, 1694: 0.9489074, 1005: 0.96629035, 91: 0.9633593, 1429: 0.97620004, 738: 0.86020046, 1030: 0.96839035, 972: 0.9697232, 89: 0.9422347, 826: 0.96333826, 171: 0.96903783, 1075: 0.8508579, 1282: 0.9606109, 853: 0.94221836, 760: 0.92530596, 1514: 0.9150217, 932: 0.95826745, 162: 0.8683049, 880: 0.8954978, 777: 0.920782, 1325: 0.9154916, 1616: 0.81311697, 1627: 0.9605062, 207: 0.9538944, 1206: 0.91549677, 430: 0.97107625, 1566: 0.9499491, 669: 0.9616367, 762: 0.9762605, 1539: 0.94581616, 1459: 0.95251065, 151: 0.9478017, 1467: 0.955347, 1017: 0.958408, 1711: 0.9474584, 942: 0.96256626, 347: 0.9628322, 180: 0.9657567, 1703: 0.9651581, 1115: 0.92660826, 989: 0.9447689, 135: 0.90523654, 1387: 0.9683071, 3: 0.8389914, 1592: 0.9656901, 1292: 0.9684254, 1270: 0.8828259, 1265: 0.9626658, 533: 0.9464736, 905: 0.9745851, 1649: 0.87982416, 372: 0.9618556, 1305: 0.9425886, 192: 0.9388246, 988: 0.9236332, 885: 0.9086632, 860: 0.95981133, 1302: 0.9698268, 1138: 0.94995135, 298: 0.9196541, 275: 0.9604056, 649: 0.9693927, 778: 0.964253, 1528: 0.89329517, 1708: 0.97068125, 434: 0.94108427, 1111: 0.888598, 1295: 0.96729904, 1574: 0.9692076, 820: 0.96679014, 947: 0.944704, 1484: 0.9618699, 165: 0.9433937, 101: 0.9689284, 1364: 0.971082, 715: 0.95903575, 1629: 0.9487701, 794: 0.6189507, 285: 0.943543, 571: 0.96285784, 64: 0.93279845, 1453: 0.91191304, 1581: 0.95713264, 911: 0.9241362, 850: 0.9658459, 403: 0.91900814, 930: 0.9494734, 1055: 0.9726346, 1381: 0.970722, 420: 0.93812346, 1259: 0.9687112, 556: 0.9583601, 459: 0.9668606, 1159: 0.9313877, 870: 0.95593995, 36: 0.94423413, 1046: 0.9585197, 1218: 0.9363493, 1540: 0.9409013, 1053: 0.96693087, 1456: 0.9198513, 1636: 0.9588829, 355: 0.95741564, 1025: 0.9696284, 1119: 0.9705775, 904: 0.9415888, 1568: 0.9561489, 1335: 0.95353913, 1704: 0.8008724, 1417: 0.947063, 1040: 0.9350228, 1440: 0.96457666, 631: 0.95596, 371: 0.9424835, 282: 0.94209015, 1144: 0.9572741, 834: 0.9328582, 697: 0.9326937, 878: 0.9538974, 1122: 0.87656665, 452: 0.9482186, 466: 0.9678274, 408: 0.91973555, 242: 0.9653584, 1042: 0.9752162, 387: 0.9548679, 1329: 0.9457628, 247: 0.9723737, 157: 0.90320385, 1078: 0.73764163, 1316: 0.9617732, 442: 0.7177829, 624: 0.7484301, 1308: 0.9595362, 99: 0.87701654, 1683: 0.8860655, 1507: 0.9414584, 913: 0.9620889, 1498: 0.6481795, 652: 0.9747015, 595: 0.96771985, 296: 0.9562202, 27: 0.94896334, 299: 0.8306294, 1455: 0.8041, 21: 0.96946925, 245: 0.87567806, 367: 0.9640501, 1610: 0.95980376, 779: 0.976384, 517: 0.8307488, 1297: 0.8926423, 174: 0.933343, 1143: 0.88752747, 1398: 0.87330484, 1602: 0.9676187, 1715: 0.9686394, 406: 0.9552746, 1451: 0.9633773, 169: 0.9522291, 1599: 0.965734, 440: 0.9639768, 910: 0.9223507, 405: 0.84209037, 1553: 0.8020379, 122: 0.964694, 178: 0.9629804, 1506: 0.9678764, 346: 0.96348035, 246: 0.96256757, 1572: 0.97098845, 1150: 0.92250395, 427: 0.9518999, 153: 0.9603086, 1607: 0.9663402, 1337: 0.9451143, 1083: 0.73426646, 1076: 0.9509951, 908: 0.9619234, 44: 0.94972044, 1527: 0.9734963, 77: 0.9387878, 1696: 0.9621499, 1001: 0.9625993, 147: 0.7408542, 1: 0.9594496, 1175: 0.9565794, 1107: 0.92913777, 82: 0.95871776, 389: 0.9593367, 1326: 0.96426713, 611: 0.9611464, 1691: 0.9417837, 955: 0.95402825, 1026: 0.9742467, 1353: 0.9744874, 1714: 0.9716403, 845: 0.955062, 1112: 0.9610591, 1358: 0.9615307, 482: 0.9485375, 1400: 0.9378248, 1137: 0.9689984, 822: 0.8040198, 1168: 0.92723745, 859: 0.7565606, 840: 0.96473986, 1718: 0.96062016, 732: 0.97279614, 31: 0.9532352, 1045: 0.972008, 409: 0.9614087, 973: 0.9165929, 1120: 0.9648856, 1686: 0.77079046, 1303: 0.97349924, 453: 0.96820503, 499: 0.93391746, 680: 0.97612214, 95: 0.96725065, 863: 0.921019, 725: 0.95969427, 308: 0.97498226, 844: 0.9695061, 107: 0.9754244, 1071: 0.9439469, 1132: 0.92531705, 519: 0.9417871, 550: 0.95526075, 666: 0.91760355, 1336: 0.9673264, 650: 0.94392693, 1289: 0.96703213, 1271: 0.9158094, 1047: 0.9507572, 1123: 0.9713489, 1716: 0.9643223, 444: 0.97611076, 731: 0.9471195, 212: 0.83661973, 594: 0.9533309, 872: 0.9706006, 145: 0.84749454, 477: 0.9679817, 268: 0.9692918, 59: 0.92923814, 1713: 0.7768148, 625: 0.9397777, 179: 0.9309381, 1491: 0.9622412, 739: 0.96082133, 609: 0.9716907, 218: 0.9273763, 723: 0.97144026, 431: 0.95442235, 472: 0.9402554, 1443: 0.97617924, 263: 0.9768132, 1029: 0.9524521, 980: 0.95219517, 222: 0.966127, 1003: 0.9490861, 1523: 0.970812, 1307: 0.7532924, 892: 0.84563696, 812: 0.9395617, 413: 0.96675694, 572: 0.9646015, 1069: 0.9527983, 1419: 0.9465664, 915: 0.9606321, 163: 0.9643775, 1197: 0.9687492, 326: 0.8811489, 858: 0.91300315, 1239: 0.95618594, 131: 0.9476416, 358: 0.952778, 48: 0.7335318, 1722: 0.9528529, 98: 0.96749353, 333: 0.817561, 869: 0.9727121, 29: 0.7799243, 698: 0.9632602, 1367: 0.96053886, 526: 0.93582666, 1109: 0.96155876, 1034: 0.9689024, 985: 0.91864777, 1130: 0.9419946, 1129: 0.9446987, 899: 0.9521613, 658: 0.933633, 97: 0.94426876, 787: 0.9423429, 1618: 0.9170864, 485: 0.9210889, 1681: 0.9565368, 1350: 0.9493893, 441: 0.95785254, 1196: 0.9655845, 110: 0.9536261, 1556: 0.95842475, 532: 0.9658486, 991: 0.88573796, 634: 0.77335215, 1483: 0.97600716, 461: 0.9683377, 677: 0.9627607, 886: 0.9674085, 446: 0.9483624, 646: 0.95960516, 1152: 0.84742725, 1464: 0.92779404, 682: 0.96251833, 202: 0.8397659, 155: 0.96593314, 172: 0.8898908, 513: 0.96605045, 200: 0.9490069, 1121: 0.9738513, 1628: 0.93132126, 1375: 0.9772075, 744: 0.96742445, 1024: 0.763624, 655: 0.9472378, 758: 0.9498024, 205: 0.9358882, 47: 0.9657795, 382: 0.96000904, 1634: 0.93443835, 1351: 0.9452525, 718: 0.970882, 1095: 0.9624136, 1508: 0.9636607, 1091: 0.95028836, 601: 0.86878335, 1588: 0.97146386, 1432: 0.95225805, 868: 0.96680784, 566: 0.96728766, 1015: 0.946688, 1110: 0.9499069, 922: 0.93104434, 1468: 0.93051153, 1662: 0.95146537, 58: 0.9644119, 1090: 0.95765406, 1249: 0.9365176, 719: 0.9554001, 1373: 0.9333821, 1157: 0.9630096, 1234: 0.91640437, 1237: 0.9262334, 936: 0.41166827, 548: 0.9594901, 1343: 0.8668609, 1061: 0.9475452, 1725: 0.89570284, 1277: 0.97717535, 78: 0.95731777, 302: 0.9457178, 1011: 0.93598914, 284: 0.9159639, 119: 0.9595676, 518: 0.934683, 1149: 0.94231087, 823: 0.9764038, 1363: 0.97256035, 775: 0.44151852, 133: 0.83622587, 287: 0.9687459, 424: 0.78367245, 1555: 0.74960965, 51: 0.92917514, 1388: 0.9140933, 1349: 0.9674625, 927: 0.966854, 1006: 0.94424593, 139: 0.95189315, 1442: 0.9654976, 230: 0.93738, 104: 0.94387025, 508: 0.9653899, 1314: 0.9664324, 1675: 0.96682215, 343: 0.9548917, 883: 0.96392775, 1139: 0.8917199, 1243: 0.9556494, 502: 0.9531448, 1101: 0.9697306, 1585: 0.977505, 1058: 0.9439981, 1726: 0.9306172, 244: 0.85331386, 941: 0.9601035, 1671: 0.9323618, 278: 0.94124013, 711: 0.9495915, 1089: 0.9100612, 484: 0.9709815, 943: 0.871894, 1096: 0.957928, 856: 0.9705273, 1663: 0.9574078, 111: 0.97388804, 1039: 0.9640693, 710: 0.93417734, 1012: 0.9484852, 565: 0.94428086, 305: 0.9770766, 1392: 0.96975714, 177: 0.97319317, 1515: 0.9735728, 626: 0.9316728, 1457: 0.9533435, 232: 0.9552737, 817: 0.9622506, 1309: 0.96325666, 672: 0.9609204, 251: 0.8643122, 1530: 0.9421961, 241: 0.96548724, 63: 0.96378165, 199: 0.8023325, 622: 0.9620732, 209: 0.9509912, 1052: 0.9640079, 1082: 0.9465147, 1667: 0.9505369, 1266: 0.9645457, 216: 0.95330465, 965: 0.84205925, 39: 0.9595169, 1357: 0.9508501, 1461: 0.89523625, 1263: 0.9665926, 790: 0.9582925, 992: 0.9498645, 357: 0.96059775, 470: 0.9564486, 52: 0.95650065, 884: 0.9623605, 515: 0.95417297, 695: 0.96383655, 454: 0.9610655, 1561: 0.9700022, 855: 0.94416684}, 'azure/Phi-3-medium-4k-instruct': {182: 0.97163117, 825: 0.97372943, 1240: 0.97132486, 505: 0.9714405, 1482: 0.9732719, 1549: 0.9712811, 842: 0.97187054, 1605: 0.9729571, 386: 0.9712252, 1622: 0.9721967, 1182: 0.97179776, 1212: 0.97360975, 487: 0.9725133, 148: 0.97210467, 661: 0.9715527, 950: 0.9734514, 393: 0.97144556, 1056: 0.9727623, 259: 0.9713198, 1415: 0.9713188, 523: 0.97289723, 353: 0.9732902, 1391: 0.9739327, 874: 0.97183007, 12: 0.9724817, 1700: 0.9708133, 527: 0.96979123, 496: 0.97161275, 483: 0.9723474, 365: 0.9714953, 674: 0.9716029, 93: 0.9718482, 729: 0.97113997, 370: 0.9726323, 714: 0.97310764, 898: 0.9738743, 1344: 0.9713287, 831: 0.97313505, 1723: 0.9716626, 203: 0.9711782, 345: 0.9707419, 67: 0.9705658, 1383: 0.9713875, 319: 0.9729056, 852: 0.97093934, 1311: 0.9704742, 45: 0.97280246, 582: 0.9717971, 791: 0.9709762, 781: 0.9728756, 221: 0.9722868, 316: 0.9709081, 857: 0.9722261, 578: 0.9739208, 137: 0.97083527, 639: 0.9704075, 1257: 0.9711373, 390: 0.9718456, 5: 0.9713761, 628: 0.97111344, 1402: 0.97316957, 806: 0.97108984, 243: 0.97297657, 720: 0.9726126, 919: 0.9735348, 491: 0.9721663, 768: 0.9720532, 35: 0.97087055, 462: 0.9716538, 414: 0.9739248, 475: 0.97202736, 301: 0.9706661, 923: 0.9705969, 815: 0.9724638, 558: 0.97229093, 1458: 0.97263473, 25: 0.97115135, 810: 0.9730515, 557: 0.9704297, 1368: 0.9720703, 369: 0.9722438, 1470: 0.970102, 57: 0.97151554, 152: 0.97327834, 307: 0.9722358, 1598: 0.97260803, 1380: 0.9710547, 159: 0.9723653, 1382: 0.97152823, 509: 0.9720224, 1665: 0.972244, 615: 0.97086906, 404: 0.9723283, 396: 0.97269195, 1423: 0.9714608, 1179: 0.9715238, 224: 0.9731309, 1084: 0.9711642, 1359: 0.9711603, 660: 0.97143495, 1099: 0.9726848, 590: 0.97269857, 290: 0.97124743, 1548: 0.97258455, 1420: 0.9734936, 1410: 0.9709688, 967: 0.97327787, 979: 0.9717794, 1421: 0.9718227, 512: 0.9723178, 198: 0.97289205, 102: 0.972831, 479: 0.97297364, 678: 0.9726502, 970: 0.97102755, 1135: 0.97368884, 1583: 0.9710288, 1028: 0.97163916, 397: 0.97040355, 1522: 0.97348964, 555: 0.9711899, 293: 0.9710631, 1504: 0.97140074, 1167: 0.9716984, 1360: 0.9728689, 1469: 0.9725355, 1081: 0.97119594, 1192: 0.9714047, 538: 0.9720827, 924: 0.9718114, 394: 0.9716159, 1606: 0.97263193, 1397: 0.97144645, 105: 0.9714518, 997: 0.97165346, 144: 0.97302026, 1288: 0.9730551, 1272: 0.9732265, 100: 0.9732169, 1579: 0.9714442, 1557: 0.9735386, 564: 0.9728397, 501: 0.9700714, 613: 0.97123545, 757: 0.9739624, 1475: 0.97187895, 865: 0.9712452, 1571: 0.9730407, 1511: 0.9732728, 785: 0.96829724, 1251: 0.9717924, 1490: 0.97321135, 1481: 0.97251093, 24: 0.9714139, 648: 0.9732816, 149: 0.9728473, 1339: 0.97380936, 843: 0.97234714, 253: 0.9712427, 379: 0.9730461, 1575: 0.97276115, 272: 0.9708599, 670: 0.9733767, 1502: 0.97223425, 1657: 0.97218746, 996: 0.97312105, 702: 0.9732686, 276: 0.97212166, 1070: 0.9718677, 1462: 0.9705384, 603: 0.96955645, 588: 0.9726293, 733: 0.97270435, 220: 0.97330815, 542: 0.97296, 1355: 0.9719082, 1352: 0.9713767, 197: 0.97154295, 449: 0.969714, 334: 0.97279966, 614: 0.9702847, 451: 0.97077674, 691: 0.9706176, 681: 0.9714054, 1626: 0.97258514, 766: 0.9720038, 665: 0.9721367, 616: 0.97161734, 612: 0.97133845, 154: 0.9721319, 190: 0.9716822, 15: 0.9715949, 1268: 0.971357, 8: 0.9710161, 1296: 0.9707074, 329: 0.9727496, 1611: 0.9720738, 1678: 0.9728367, 780: 0.97205204, 4: 0.97194415, 1661: 0.699047, 1293: 0.97104484, 294: 0.9734876, 1637: 0.9712218, 1365: 0.9720204, 686: 0.9702461, 1333: 0.97184616, 1474: 0.97358096, 759: 0.9717713, 1584: 0.9729126, 504: 0.97332203, 395: 0.97155714, 1573: 0.9709853, 240: 0.9708028, 92: 0.97145754, 85: 0.9721111, 1146: 0.9722812, 735: 0.97184616, 1140: 0.9710534, 528: 0.97301155, 1510: 0.97214186, 495: 0.9735922, 574: 0.9716276, 627: 0.9723112, 261: 0.97105366, 1298: 0.97163916, 1232: 0.9721267, 1648: 0.9724327, 821: 0.97292423, 94: 0.9722188, 1495: 0.9730585, 437: 0.97335714, 280: 0.9719749, 120: 0.97307587, 1597: 0.97333, 520: 0.9706782, 42: 0.9724525, 498: 0.972955, 1633: 0.971901, 1092: 0.9704185, 835: 0.971369, 1043: 0.9731406, 1181: 0.97074956, 300: 0.9722109, 920: 0.97165537, 86: 0.97233397, 1569: 0.9732439, 1476: 0.9724373, 1166: 0.97129, 1016: 0.97086114, 79: 0.973196, 752: 0.97365576, 986: 0.97198236, 1399: 0.9733499, 1496: 0.9703898, 516: 0.9714093, 1580: 0.9705047, 75: 0.9709706, 969: 0.97259504, 41: 0.70701486, 158: 0.9726228, 1596: 0.9715413, 138: 0.9704925, 832: 0.9738193, 645: 0.9710604, 252: 0.9713553, 724: 0.9719203, 561: 0.9732405, 337: 0.97345656, 1176: 0.97303617, 960: 0.9739561, 1719: 0.9720418, 1591: 0.97360164, 61: 0.9724887, 1142: 0.97254163, 1169: 0.9709253, 1331: 0.97215605, 1465: 0.9731949, 539: 0.97229713, 1631: 0.9706032, 312: 0.9720138, 415: 0.97235155, 747: 0.97206014, 953: 0.9729706, 50: 0.9717791, 1638: 0.97211546, 1699: 0.97312254, 1407: 0.9714991, 1560: 0.97283113, 340: 0.97216225, 608: 0.97300804, 524: 0.9736486, 638: 0.97378325, 213: 0.9734288, 1519: 0.97283494, 1356: 0.97087383, 889: 0.97201836, 304: 0.9734629, 1276: 0.97254455, 659: 0.97176963, 801: 0.9711888, 796: 0.9726077, 1093: 0.9712792, 425: 0.9730707, 876: 0.970588, 381: 0.971932, 106: 0.97270906, 128: 0.9721791, 1705: 0.9704216, 1098: 0.97221684, 829: 0.9707244, 788: 0.97307265, 248: 0.97206926, 34: 0.9726165, 632: 0.9719267, 1698: 0.97121584, 9: 0.9723528, 418: 0.9728941, 40: 0.9732834, 604: 0.9718929, 1235: 0.9718563, 577: 0.97314554, 1666: 0.9709036, 1245: 0.9717752, 1673: 0.9711604, 1684: 0.9730661, 68: 0.9715135, 629: 0.97157156, 11: 0.9703095, 1394: 0.6408945, 1582: 0.97157854, 1471: 0.97363144, 384: 0.97315603, 987: 0.9710848, 54: 0.9714433, 944: 0.9703553, 1697: 0.97225845, 809: 0.9699953, 675: 0.9712208, 1219: 0.9724258, 309: 0.9715162, 1048: 0.97256696, 1051: 0.97232956, 1204: 0.97258544, 436: 0.9725514, 643: 0.97327536, 981: 0.9722271, 827: 0.97025126, 1377: 0.9729806, 1173: 0.9719015, 551: 0.9724725, 1073: 0.97172314, 412: 0.9709537, 1097: 0.97323734, 363: 0.9710783, 322: 0.9716097, 968: 0.9725667, 907: 0.97234714, 331: 0.97337747, 1086: 0.9720363, 507: 0.9730406, 940: 0.9713407, 1536: 0.9718159, 828: 0.9730128, 786: 0.9695208, 1444: 0.9713021, 534: 0.97328705, 297: 0.9732391, 635: 0.97299373, 581: 0.9722906, 1258: 0.97337115, 1604: 0.97342944, 136: 0.9723289, 939: 0.97170246, 1500: 0.971299, 269: 0.97314286, 288: 0.97097325, 1224: 0.9713922, 1493: 0.9722012, 1340: 0.9714273, 260: 0.9733084, 362: 0.973214, 722: 0.97066665, 1248: 0.97289366, 767: 0.9735067, 866: 0.9719876, 875: 0.97224784, 756: 0.9715127, 706: 0.9727615, 1376: 0.9734588, 49: 0.97053134, 1595: 0.97114897, 935: 0.97135305, 984: 0.97363585, 679: 0.97269577, 188: 0.9725542, 1186: 0.97213644, 848: 0.97305614, 1685: 0.97107613, 1724: 0.9710661, 1414: 0.97324425, 1354: 0.972696, 281: 0.97312826, 522: 0.9718765, 1677: 0.9708499, 103: 0.97261876, 456: 0.97116864, 644: 0.97093946, 1228: 0.9722148, 895: 0.97291505, 541: 0.9726169, 1128: 0.9709556, 1323: 0.97245276, 830: 0.9726829, 1554: 0.97365177, 1020: 0.9734042, 1603: 0.97065306, 1538: 0.97341377, 377: 0.9728923, 473: 0.9706187, 398: 0.97118485, 419: 0.9727787, 129: 0.9731862, 1156: 0.97109026, 1275: 0.9733567, 360: 0.97189415, 751: 0.97297126, 1106: 0.9730277, 1437: 0.9710958, 673: 0.971034, 1578: 0.97136474, 891: 0.9714096, 599: 0.96994734, 351: 0.97220695, 882: 0.9726523, 1036: 0.9724138, 1721: 0.9727076, 1134: 0.9726642, 1153: 0.97159374, 1074: 0.9722028, 901: 0.97191745, 17: 0.97176784, 286: 0.97116435, 344: 0.96888304, 359: 0.97211367, 749: 0.9726447, 348: 0.9713498, 1446: 0.9705174, 249: 0.9725046, 914: 0.9705784, 1347: 0.9738628, 1231: 0.97083235, 929: 0.97084, 864: 0.9714059, 1190: 0.9725577, 7: 0.9710108, 1198: 0.9732895, 851: 0.9735372, 1384: 0.97263205, 201: 0.97041816, 1450: 0.97181094, 480: 0.97144634, 1113: 0.9723157, 1077: 0.97495043, 867: 0.9738843, 18: 0.97087866, 1131: 0.9705319, 1619: 0.9730795, 1346: 0.9724969, 862: 0.97218883, 1050: 0.9732292, 74: 0.97078675, 770: 0.97200507, 1085: 0.97321635, 982: 0.97308254, 170: 0.97307795, 464: 0.97222215, 696: 0.9727538, 1544: 0.9731055, 223: 0.97091806, 1038: 0.9729494, 1280: 0.97014725, 1366: 0.9711089, 1479: 0.9704456, 974: 0.9704283, 83: 0.9715304, 814: 0.97180474, 1433: 0.9722198, 1203: 0.97364163, 270: 0.97293174, 1054: 0.9727294, 1624: 0.97181726, 383: 0.9714509, 1385: 0.9719355, 1505: 0.97260475, 1485: 0.9721567, 1080: 0.9716619, 1023: 0.971077, 20: 0.97264624, 1067: 0.9711066, 385: 0.97156173, 332: 0.9711878, 903: 0.97361565, 324: 0.97204226, 227: 0.973664, 1408: 0.97133136, 1389: 0.97163916, 1488: 0.9712881, 439: 0.9721382, 361: 0.9710951, 1654: 0.97222996, 753: 0.9723884, 1425: 0.9713778, 990: 0.97091526, 554: 0.97157675, 909: 0.97134393, 1180: 0.97162825, 888: 0.97140956, 958: 0.9737263, 530: 0.9723139, 1441: 0.97335964, 469: 0.9721301, 1233: 0.96870184, 1215: 0.97011214, 368: 0.97332126, 1520: 0.97432965, 1570: 0.97096056, 1124: 0.97267073, 560: 0.97058713, 928: 0.9730576, 266: 0.9720548, 1236: 0.9722578, 460: 0.97337276, 1546: 0.9732314, 500: 0.97191626, 1133: 0.9716655, 1031: 0.9733227, 325: 0.9716134, 802: 0.9586933, 476: 0.97175467, 730: 0.9742063, 250: 0.97195387, 765: 0.9729941, 900: 0.97166157, 421: 0.9731094, 685: 0.9721531, 70: 0.9728196, 1247: 0.9728536, 799: 0.9708736, 16: 0.97238827, 1396: 0.9732228, 211: 0.9712125, 113: 0.9728285, 87: 0.9717945, 1037: 0.9717425, 1170: 0.9726208, 1014: 0.973301, 80: 0.9730049, 1655: 0.9717628, 1533: 0.97248983, 1422: 0.9721529, 1162: 0.97126704, 978: 0.971095, 1674: 0.97251964, 1154: 0.97254455, 748: 0.9705983, 1526: 0.9711292, 703: 0.9720853, 349: 0.9732363, 315: 0.97128737, 1321: 0.9715665, 289: 0.97326285, 1658: 0.97042453, 295: 0.9718071, 1348: 0.9732583, 1284: 0.97269833, 1379: 0.9705414, 1225: 0.97261244, 400: 0.9720852, 1660: 0.9727429, 1220: 0.97350514, 1395: 0.9728491, 1701: 0.97218263, 684: 0.9706807, 553: 0.97220594, 62: 0.97218025, 1283: 0.9716195, 313: 0.97139883, 262: 0.97141135, 1200: 0.9724646, 69: 0.97134507, 1577: 0.97303265, 1253: 0.97108513, 854: 0.971825, 734: 0.96982545, 66: 0.97331387, 1614: 0.9713524, 708: 0.97146994, 559: 0.9726351, 1213: 0.97245646, 966: 0.970708, 795: 0.971476, 116: 0.9722463, 303: 0.9720986, 1632: 0.97265434, 563: 0.9719267, 374: 0.9712316, 402: 0.97205645, 10: 0.97261333, 1209: 0.9711882, 793: 0.9709328, 474: 0.97235435, 896: 0.9705711, 1242: 0.971657, 271: 0.973238, 589: 0.9709084, 1217: 0.97302645, 417: 0.973887, 497: 0.9709575, 1639: 0.97293663, 656: 0.97238433, 196: 0.9717414, 653: 0.9715043, 1222: 0.9727888, 118: 0.97269565, 994: 0.9712154, 949: 0.9718026, 912: 0.9729241, 0: 0.9720194, 1452: 0.9740856, 1492: 0.9723384, 130: 0.9727853, 713: 0.64104414, 1593: 0.97129256, 1063: 0.97195387, 1334: 0.9724205, 1199: 0.9725955, 1717: 0.9729356, 391: 0.9714391, 1620: 0.97120374, 1411: 0.9714012, 701: 0.97188514, 1478: 0.97071147, 704: 0.9730949, 125: 0.9718683, 1551: 0.9728895, 1019: 0.97080237, 273: 0.9732283, 1529: 0.97273785, 1559: 0.97051764, 447: 0.9728064, 236: 0.9708495, 956: 0.97059935, 81: 0.9714315, 761: 0.9712984, 600: 0.9716585, 1185: 0.97236216, 235: 0.9708365, 1656: 0.9706454, 1406: 0.9730163, 1647: 0.9720818, 468: 0.9711509, 28: 0.96910805, 1672: 0.9732661, 1589: 0.9729215, 1250: 0.9709524, 1707: 0.972259, 350: 0.971704, 976: 0.9734288, 740: 0.97208583, 1194: 0.9710343, 1454: 0.9726925, 1693: 0.9720062, 1022: 0.9727779, 871: 0.9718327, 1537: 0.9715327, 1372: 0.9729854, 401: 0.9724826, 255: 0.9713507, 977: 0.97139627, 175: 0.9706274, 705: 0.97094774, 964: 0.96994543, 797: 0.97303224, 380: 0.9730328, 1386: 0.9710208, 1007: 0.972088, 1205: 0.9739217, 234: 0.9712503, 584: 0.97099787, 1680: 0.9728407, 1230: 0.96826684, 1041: 0.9725284, 426: 0.97161305, 1032: 0.97130686, 1065: 0.972306, 277: 0.97053313, 1164: 0.9729058, 736: 0.97357404, 173: 0.9732484, 1576: 0.9711161, 906: 0.9728274, 1256: 0.6221373, 963: 0.9718959, 587: 0.9724051, 26: 0.9716249, 774: 0.97019607, 150: 0.9731776, 651: 0.9734214, 1405: 0.9705809, 1174: 0.9734765, 926: 0.9729149, 1114: 0.971115, 1613: 0.9708463, 700: 0.97384113, 1687: 0.97239584, 366: 0.9722143, 1434: 0.97143215, 1689: 0.97360975, 959: 0.9731443, 683: 0.9734795, 114: 0.97283226, 1403: 0.9714569, 1477: 0.9726254, 6: 0.97414035, 1088: 0.97268754, 545: 0.9720625, 510: 0.9716448, 1473: 0.97285247, 641: 0.9726557, 1116: 0.9725586, 1141: 0.97170466, 671: 0.97270423, 1100: 0.97141594, 1712: 0.9709817, 1709: 0.9711684, 1669: 0.97245795, 1362: 0.9732738, 839: 0.97281784, 957: 0.9720919, 918: 0.9716642, 1184: 0.9722826, 1545: 0.9740825, 1118: 0.97328377, 208: 0.97323924, 161: 0.9713993, 1435: 0.9733878, 606: 0.9706203, 378: 0.97218996, 998: 0.97195935, 1060: 0.97149354, 636: 0.97280425, 310: 0.9710371, 540: 0.9704526, 1552: 0.9723102, 902: 0.9731268, 108: 0.9711637, 2: 0.970108, 1486: 0.97273433, 1427: 0.9723051, 1645: 0.9703359, 514: 0.9717852, 535: 0.9721706, 1049: 0.9729934, 1541: 0.97079945, 217: 0.9704615, 1274: 0.97248185, 1374: 0.97297984, 971: 0.972307, 1535: 0.9718635, 1499: 0.9707479, 1412: 0.971545, 1586: 0.97211736, 743: 0.97115445, 1682: 0.9726273, 975: 0.9727728, 1445: 0.97430295, 586: 0.97350603, 1252: 0.9720551, 567: 0.9719794, 819: 0.9730426, 1210: 0.97085315, 763: 0.9729561, 489: 0.97214025, 254: 0.9713193, 1108: 0.64233345, 543: 0.972446, 570: 0.97181386, 771: 0.9724195, 38: 0.9718991, 925: 0.97156155, 792: 0.9721185, 1600: 0.9733551, 399: 0.97069204, 22: 0.9711927, 1564: 0.9723479, 407: 0.9734693, 916: 0.97322446, 897: 0.9703983, 356: 0.9710034, 185: 0.9712029, 127: 0.9734378, 115: 0.97132677, 1512: 0.9726963, 1018: 0.9728248, 181: 0.9710027, 602: 0.9725709, 467: 0.9728635, 132: 0.97241706, 647: 0.9702829, 1424: 0.97301495, 1262: 0.9705385, 585: 0.97154003, 1690: 0.9747424, 755: 0.97281915, 938: 0.97134584, 1587: 0.9728496, 610: 0.97241116, 471: 0.9710606, 215: 0.9716206, 335: 0.9722607, 1013: 0.9727074, 1404: 0.97179216, 373: 0.9727145, 1223: 0.97139907, 1216: 0.9730007, 1438: 0.9720515, 60: 0.97085243, 689: 0.9716821, 109: 0.972314, 1720: 0.9715848, 1702: 0.97411454, 306: 0.97201884, 1322: 0.97356814, 1158: 0.97153574, 1463: 0.9740171, 433: 0.970531, 375: 0.97050786, 465: 0.9716305, 620: 0.9718541, 23: 0.9737458, 754: 0.97248006, 1521: 0.97181433, 257: 0.9722615, 1286: 0.97411287, 264: 0.9734664, 1105: 0.972981, 195: 0.97269565, 1318: 0.9709084, 833: 0.9728463, 597: 0.9712497, 1294: 0.97130907, 481: 0.97173285, 204: 0.9718394, 737: 0.9725884, 1567: 0.97199845, 531: 0.9722926, 206: 0.9724745, 1281: 0.97116333, 1430: 0.9713414, 318: 0.972321, 1267: 0.9718194, 1460: 0.9722854, 804: 0.9716196, 699: 0.9717163, 1361: 0.9706572, 490: 0.97161376, 53: 0.97154284, 887: 0.97212887, 568: 0.9726279, 1371: 0.97093666, 811: 0.9726169, 890: 0.9715737, 1532: 0.9727055, 164: 0.97178257, 782: 0.97232145, 769: 0.973076, 1103: 0.97164, 598: 0.97339207, 237: 0.9704278, 1547: 0.97134125, 592: 0.97151875, 1191: 0.9716817, 1447: 0.97324026, 654: 0.9730118, 596: 0.9726548, 1608: 0.97101665, 1695: 0.9725524, 1306: 0.9715964, 962: 0.97148454, 428: 0.97275734, 712: 0.9712994, 457: 0.9719267, 46: 0.97325313, 562: 0.9729793, 317: 0.97298765, 142: 0.9734082, 894: 0.97162265, 847: 0.97233844, 1125: 0.97308785, 1612: 0.9715919, 96: 0.9719259, 1127: 0.97192544, 1542: 0.9726881, 1227: 0.9722571, 90: 0.9718645, 1155: 0.97214997, 1516: 0.9710278, 321: 0.97129, 1342: 0.9703921, 229: 0.97054523, 274: 0.9737781, 1285: 0.9720231, 709: 0.97301435, 1550: 0.97307444, 1211: 0.6260554, 1642: 0.9707301, 1301: 0.9718598, 593: 0.9724744, 1183: 0.9731829, 492: 0.97030455, 291: 0.9707357, 210: 0.9708111, 65: 0.9735065, 547: 0.9711003, 544: 0.97237873, 186: 0.971949, 1525: 0.9720086, 789: 0.9706341, 1480: 0.9735494, 124: 0.9702115, 1021: 0.97221214, 1472: 0.97148997, 1694: 0.9711872, 1005: 0.97060925, 91: 0.97184414, 1429: 0.971609, 738: 0.9715848, 1030: 0.97405314, 972: 0.97228503, 89: 0.9714253, 826: 0.9716774, 171: 0.97416884, 1075: 0.9734108, 1282: 0.97105026, 853: 0.9725955, 760: 0.9735395, 1514: 0.9738115, 932: 0.97304374, 162: 0.97247934, 880: 0.9717246, 777: 0.9727409, 1325: 0.9735961, 1616: 0.97074157, 1627: 0.97221553, 207: 0.97263044, 1206: 0.97121, 430: 0.9704552, 1566: 0.9711794, 669: 0.9726868, 762: 0.97086, 1539: 0.9723068, 1459: 0.9734465, 151: 0.9731525, 1467: 0.9712073, 1017: 0.9719106, 1711: 0.9721457, 942: 0.9721705, 347: 0.97080415, 180: 0.97218215, 1703: 0.9731265, 1115: 0.9724504, 989: 0.9714792, 135: 0.97232527, 1387: 0.97322494, 3: 0.97289217, 1592: 0.9718037, 1292: 0.9740825, 1270: 0.97259855, 1265: 0.9730108, 533: 0.97334844, 905: 0.9718202, 1649: 0.97154284, 372: 0.9713594, 1305: 0.97120756, 192: 0.9718186, 988: 0.9723766, 885: 0.9732328, 860: 0.9715408, 1302: 0.97147244, 1138: 0.9736917, 298: 0.9740912, 275: 0.97225285, 649: 0.9711207, 778: 0.97182715, 1528: 0.9728625, 1708: 0.9717112, 434: 0.97423923, 1111: 0.9724019, 1295: 0.97287375, 1574: 0.9713155, 820: 0.9736602, 947: 0.9717467, 1484: 0.9719116, 165: 0.9718184, 101: 0.97231275, 1364: 0.97181165, 715: 0.9724017, 1629: 0.970921, 794: 0.9704273, 285: 0.9715915, 571: 0.97307056, 64: 0.9729959, 1453: 0.97240776, 1581: 0.9731905, 911: 0.9716898, 850: 0.97350425, 403: 0.97244406, 930: 0.9729883, 1055: 0.9733085, 1381: 0.9733729, 420: 0.97190315, 1259: 0.9734509, 556: 0.9708477, 459: 0.9708486, 1159: 0.9712315, 870: 0.97354984, 36: 0.97205013, 1046: 0.97225755, 1218: 0.97084653, 1540: 0.9732511, 1053: 0.9726002, 1456: 0.9732198, 1636: 0.97287476, 355: 0.9720615, 1025: 0.971858, 1119: 0.97359234, 904: 0.97336745, 1568: 0.9731347, 1335: 0.97410995, 1704: 0.9723899, 1417: 0.971601, 1040: 0.9709401, 1440: 0.97171617, 631: 0.97164583, 371: 0.9718965, 282: 0.97084606, 1144: 0.9726759, 834: 0.97201794, 697: 0.97245175, 878: 0.9723475, 1122: 0.9723308, 452: 0.97125715, 466: 0.97176725, 408: 0.97101825, 242: 0.9726505, 1042: 0.9704944, 387: 0.9720733, 1329: 0.972651, 247: 0.97138166, 157: 0.97359765, 1078: 0.9729994, 1316: 0.9724017, 442: 0.9726668, 624: 0.97238696, 1308: 0.9730267, 99: 0.9723936, 1683: 0.9735333, 1507: 0.97371995, 913: 0.97314703, 1498: 0.9697796, 652: 0.9715135, 595: 0.9735231, 296: 0.97370243, 27: 0.97123295, 299: 0.97127736, 1455: 0.97141683, 21: 0.9704744, 245: 0.9722713, 367: 0.9739458, 1610: 0.97181803, 779: 0.97173405, 517: 0.97271246, 1297: 0.9712828, 174: 0.97138083, 1143: 0.97198945, 1398: 0.97446376, 1602: 0.97256976, 1715: 0.9733285, 406: 0.9724753, 1451: 0.9729445, 169: 0.97225374, 1599: 0.97287333, 440: 0.97106534, 910: 0.972801, 405: 0.9732178, 1553: 0.97174174, 122: 0.9719239, 178: 0.97114223, 1506: 0.9734623, 346: 0.9732294, 246: 0.97056615, 1572: 0.9723441, 1150: 0.9723947, 427: 0.97123116, 153: 0.9712176, 1607: 0.9716196, 1337: 0.9721335, 1083: 0.9712928, 1076: 0.97140324, 908: 0.9717723, 44: 0.97315234, 1527: 0.9703221, 77: 0.97108555, 1696: 0.9719064, 1001: 0.9706434, 147: 0.9707527, 1: 0.9723379, 1175: 0.9710904, 1107: 0.9720799, 82: 0.9723511, 389: 0.97094786, 1326: 0.97355324, 611: 0.9718461, 1691: 0.970659, 955: 0.9698297, 1026: 0.9707037, 1353: 0.97318053, 1714: 0.97147346, 845: 0.973003, 1112: 0.9717874, 1358: 0.9715888, 482: 0.9712902, 1400: 0.9731067, 1137: 0.9718506, 822: 0.9724894, 1168: 0.9726418, 859: 0.97347724, 840: 0.9735955, 1718: 0.96897364, 732: 0.97201985, 31: 0.97184306, 1045: 0.9716859, 409: 0.9731811, 973: 0.9722262, 1120: 0.97122014, 1686: 0.9724988, 1303: 0.9716898, 453: 0.9729548, 499: 0.97388613, 680: 0.9707639, 95: 0.9730737, 863: 0.9740397, 725: 0.9717763, 308: 0.9707342, 844: 0.97264206, 107: 0.972172, 1071: 0.9731846, 1132: 0.9717591, 519: 0.9709405, 550: 0.9730684, 666: 0.97260904, 1336: 0.97024035, 650: 0.97329265, 1289: 0.9711247, 1271: 0.9730839, 1047: 0.97338957, 1123: 0.9714792, 1716: 0.9716635, 444: 0.97078663, 731: 0.97349405, 212: 0.971448, 594: 0.9711632, 872: 0.9709302, 145: 0.9723894, 477: 0.97080505, 268: 0.9714598, 59: 0.9702234, 1713: 0.9727377, 625: 0.9736736, 179: 0.97279793, 1491: 0.9729285, 739: 0.9713426, 609: 0.973757, 218: 0.97364354, 723: 0.9737679, 431: 0.97422487, 472: 0.9737442, 1443: 0.9707718, 263: 0.97068137, 1029: 0.9733175, 980: 0.973214, 222: 0.97139525, 1003: 0.97242326, 1523: 0.97331625, 1307: 0.97269416, 892: 0.9715, 812: 0.9720557, 413: 0.9721754, 572: 0.97233224, 1069: 0.9721291, 1419: 0.97218037, 915: 0.97092134, 163: 0.9720872, 1197: 0.9712923, 326: 0.9726087, 858: 0.9724583, 1239: 0.972323, 131: 0.9686118, 358: 0.9715043, 48: 0.97162914, 1722: 0.9731554, 98: 0.97177976, 333: 0.972932, 869: 0.97077775, 29: 0.97188157, 698: 0.9724166, 1367: 0.9732108, 526: 0.972041, 1109: 0.9730716, 1034: 0.97336406, 985: 0.97288203, 1130: 0.9708189, 1129: 0.9708073, 899: 0.9702654, 658: 0.97216874, 97: 0.97202516, 787: 0.9711655, 1618: 0.9730426, 485: 0.97222304, 1681: 0.9715215, 1350: 0.97091675, 441: 0.9717168, 1196: 0.9725309, 110: 0.97108716, 1556: 0.9717147, 532: 0.9715304, 991: 0.9715082, 634: 0.9736573, 1483: 0.97110736, 461: 0.97267216, 677: 0.97119945, 886: 0.9736953, 446: 0.9723733, 646: 0.97117245, 1152: 0.9711691, 1464: 0.9729638, 682: 0.97118294, 202: 0.971686, 155: 0.9736484, 172: 0.97296745, 513: 0.9714135, 200: 0.9724067, 1121: 0.9728574, 1628: 0.97257286, 1375: 0.97097576, 744: 0.9741402, 1024: 0.97174495, 655: 0.97209495, 758: 0.9712379, 205: 0.9737545, 47: 0.9717036, 382: 0.9720337, 1634: 0.9727649, 1351: 0.97017753, 718: 0.97042793, 1095: 0.97297025, 1508: 0.9742595, 1091: 0.9725353, 601: 0.9731968, 1588: 0.9721016, 1432: 0.9738097, 868: 0.9710287, 566: 0.97166944, 1015: 0.97121036, 1110: 0.97334427, 922: 0.9717694, 1468: 0.97275203, 1662: 0.97140133, 58: 0.9731958, 1090: 0.9713869, 1249: 0.9720861, 719: 0.97388214, 1373: 0.97339576, 1157: 0.97397465, 1234: 0.9723866, 1237: 0.9731468, 936: 0.6654327, 548: 0.97155523, 1343: 0.97293675, 1061: 0.97328067, 1725: 0.97298414, 1277: 0.9708956, 78: 0.9720178, 302: 0.9718099, 1011: 0.97105825, 284: 0.972761, 119: 0.9722777, 518: 0.97072875, 1149: 0.97045016, 823: 0.9722601, 1363: 0.97212034, 775: 0.6819241, 133: 0.9712219, 287: 0.97021836, 424: 0.97148174, 1555: 0.97204643, 51: 0.97297305, 1388: 0.97317725, 1349: 0.97146535, 927: 0.9714608, 1006: 0.97098744, 139: 0.9710878, 1442: 0.97228414, 230: 0.97190946, 104: 0.9721271, 508: 0.9722029, 1314: 0.9718687, 1675: 0.9744504, 343: 0.9729777, 883: 0.97173566, 1139: 0.9724168, 1243: 0.9711708, 502: 0.971922, 1101: 0.9705321, 1585: 0.97094595, 1058: 0.97223324, 1726: 0.9708039, 244: 0.9735352, 941: 0.97177404, 1671: 0.9724357, 278: 0.97397524, 711: 0.9716542, 1089: 0.9716793, 484: 0.9707568, 943: 0.97164506, 1096: 0.9729, 856: 0.9710428, 1663: 0.97051674, 111: 0.9709591, 1039: 0.9726838, 710: 0.9710391, 1012: 0.973443, 565: 0.9715997, 305: 0.9707987, 1392: 0.9719642, 177: 0.971024, 1515: 0.9708471, 626: 0.9721129, 1457: 0.9726458, 232: 0.971342, 817: 0.97185856, 1309: 0.9714509, 672: 0.9724638, 251: 0.97308433, 1530: 0.9715062, 241: 0.9702105, 63: 0.9721087, 199: 0.973409, 622: 0.9710796, 209: 0.9728969, 1052: 0.9732134, 1082: 0.97342503, 1667: 0.971893, 1266: 0.9727226, 216: 0.971934, 965: 0.9736864, 39: 0.97212964, 1357: 0.9724133, 1461: 0.9715257, 1263: 0.97241104, 790: 0.9716414, 992: 0.9711005, 357: 0.97199553, 470: 0.97277695, 52: 0.97090316, 884: 0.9713803, 515: 0.97142774, 695: 0.9701123, 454: 0.9717399, 1561: 0.97313166, 855: 0.9713538}, 'deepinfra/llama-3-8B': {182: 0.94930494, 825: 0.9500783, 1240: 0.94444066, 505: 0.9461028, 1482: 0.95036656, 1549: 0.94463074, 842: 0.9464674, 1605: 0.9473761, 386: 0.9443286, 1622: 0.94558734, 1182: 0.94955456, 1212: 0.94971323, 487: 0.95069593, 148: 0.94516015, 661: 0.9501479, 950: 0.950718, 393: 0.9491657, 1056: 0.9499977, 259: 0.94427717, 1415: 0.94330645, 523: 0.9513767, 353: 0.94918644, 1391: 0.9511367, 874: 0.9455243, 12: 0.9494593, 1700: 0.9461222, 527: 0.946391, 496: 0.9441135, 483: 0.95183784, 365: 0.95095104, 674: 0.9463335, 93: 0.94708323, 729: 0.9452515, 370: 0.9512168, 714: 0.946111, 898: 0.9493436, 1344: 0.9506059, 831: 0.95057523, 1723: 0.9465228, 203: 0.9457314, 345: 0.945643, 67: 0.94466996, 1383: 0.9418017, 319: 0.94708997, 852: 0.9461721, 1311: 0.9457512, 45: 0.94815916, 582: 0.94356275, 791: 0.9467555, 781: 0.94931364, 221: 0.95201945, 316: 0.94918674, 857: 0.9537299, 578: 0.9470924, 137: 0.95215476, 639: 0.94449663, 1257: 0.95104295, 390: 0.9499003, 5: 0.951309, 628: 0.95047325, 1402: 0.9473072, 806: 0.9508123, 243: 0.94990563, 720: 0.9486904, 919: 0.94902927, 491: 0.95040476, 768: 0.9427522, 35: 0.94476724, 462: 0.9542471, 414: 0.94603384, 475: 0.9540254, 301: 0.9456007, 923: 0.94478893, 815: 0.9492629, 558: 0.94996864, 1458: 0.9462709, 25: 0.94476414, 810: 0.95135826, 557: 0.9447633, 1368: 0.95020056, 369: 0.9436138, 1470: 0.94584674, 57: 0.9455519, 152: 0.94895035, 307: 0.9493699, 1598: 0.95140755, 1380: 0.943253, 159: 0.95037955, 1382: 0.9433063, 509: 0.9421782, 1665: 0.94563246, 615: 0.94507366, 404: 0.9460515, 396: 0.9508684, 1423: 0.9439694, 1179: 0.94947857, 224: 0.94968504, 1084: 0.95134866, 1359: 0.944875, 660: 0.9429526, 1099: 0.94580024, 590: 0.9508528, 290: 0.9517586, 1548: 0.9509109, 1420: 0.9501104, 1410: 0.9449892, 967: 0.95048994, 979: 0.9448347, 1421: 0.9471161, 512: 0.94447523, 198: 0.94907755, 102: 0.95069367, 479: 0.95226747, 678: 0.9453237, 970: 0.9442412, 1135: 0.9487243, 1583: 0.95011175, 1028: 0.94626075, 397: 0.94468635, 1522: 0.95143855, 555: 0.9436901, 293: 0.9451836, 1504: 0.94486237, 1167: 0.94782805, 1360: 0.95032156, 1469: 0.94616956, 1081: 0.9509084, 1192: 0.9501954, 538: 0.94539577, 924: 0.9495251, 394: 0.94578, 1606: 0.951258, 1397: 0.94682276, 105: 0.9443294, 997: 0.943006, 144: 0.9455641, 1288: 0.94987184, 1272: 0.94939345, 100: 0.94969547, 1579: 0.9494644, 1557: 0.94839746, 564: 0.94817376, 501: 0.94918966, 613: 0.95050365, 757: 0.94877476, 1475: 0.9512192, 865: 0.9504934, 1571: 0.95224684, 1511: 0.9497583, 785: 0.9479267, 1251: 0.9432368, 1490: 0.94976246, 1481: 0.9502385, 24: 0.95024145, 648: 0.95126706, 149: 0.95072407, 1339: 0.951248, 843: 0.9471228, 253: 0.95173633, 379: 0.9490735, 1575: 0.94961905, 272: 0.94580483, 670: 0.9502421, 1502: 0.9465464, 1657: 0.94435346, 996: 0.9507402, 702: 0.950217, 276: 0.9484393, 1070: 0.94595456, 1462: 0.94555515, 603: 0.9461316, 588: 0.94987863, 733: 0.9510928, 220: 0.9508456, 542: 0.9511278, 1355: 0.94899875, 1352: 0.9423147, 197: 0.9439059, 449: 0.94558597, 334: 0.95022035, 614: 0.94579846, 451: 0.94990873, 691: 0.9465224, 681: 0.95066196, 1626: 0.94877976, 766: 0.9494221, 665: 0.943906, 616: 0.95065475, 612: 0.9450381, 154: 0.9424909, 190: 0.9502202, 15: 0.9448034, 1268: 0.9489557, 8: 0.9509124, 1296: 0.9512685, 329: 0.9458006, 1611: 0.94930506, 1678: 0.9508413, 780: 0.95052046, 4: 0.9522049, 1661: 0.94630545, 1293: 0.9464188, 294: 0.9491566, 1637: 0.94364345, 1365: 0.94979334, 686: 0.9448398, 1333: 0.9506897, 1474: 0.9476252, 759: 0.9488521, 1584: 0.95056856, 504: 0.95055825, 395: 0.9439772, 1573: 0.94507354, 240: 0.9432137, 92: 0.9507761, 85: 0.95040035, 1146: 0.9455415, 735: 0.9507679, 1140: 0.9447373, 528: 0.9482742, 1510: 0.946707, 495: 0.9498403, 574: 0.9504021, 627: 0.9467131, 261: 0.9504205, 1298: 0.9492838, 1232: 0.9466769, 1648: 0.9502141, 821: 0.95223916, 94: 0.94719577, 1495: 0.9517906, 437: 0.95095557, 280: 0.95108753, 120: 0.9517057, 1597: 0.9512881, 520: 0.94488984, 42: 0.94856673, 498: 0.95099664, 1633: 0.9504001, 1092: 0.9447836, 835: 0.9459661, 1043: 0.9492162, 1181: 0.94586617, 300: 0.9489525, 920: 0.9455204, 86: 0.9511827, 1569: 0.94776326, 1476: 0.94680285, 1166: 0.94648504, 1016: 0.9458654, 79: 0.9503328, 752: 0.951196, 986: 0.9467743, 1399: 0.9502285, 1496: 0.9451553, 516: 0.9459563, 1580: 0.9456326, 75: 0.94990474, 969: 0.94716096, 41: 0.946492, 158: 0.95078236, 1596: 0.9418127, 138: 0.9458281, 832: 0.94986564, 645: 0.9424449, 252: 0.9446165, 724: 0.9499608, 561: 0.95045334, 337: 0.9459302, 1176: 0.94472677, 960: 0.94942945, 1719: 0.9424898, 1591: 0.9505572, 61: 0.94950706, 1142: 0.95122546, 1169: 0.9457041, 1331: 0.94869536, 1465: 0.950592, 539: 0.94227767, 1631: 0.9464192, 312: 0.94981396, 415: 0.9493087, 747: 0.94970816, 953: 0.9504552, 50: 0.9508467, 1638: 0.94286674, 1699: 0.9478305, 1407: 0.95102185, 1560: 0.946406, 340: 0.94728625, 608: 0.94982797, 524: 0.9497346, 638: 0.94754905, 213: 0.9503495, 1519: 0.951583, 1356: 0.94330686, 889: 0.9506469, 304: 0.9516094, 1276: 0.9464605, 659: 0.95156693, 801: 0.9442868, 796: 0.9481147, 1093: 0.95063806, 425: 0.94454414, 876: 0.9448839, 381: 0.94987637, 106: 0.9457191, 128: 0.9491479, 1705: 0.9474405, 1098: 0.94926775, 829: 0.9452158, 788: 0.9462097, 248: 0.9457559, 34: 0.9495591, 632: 0.94919556, 1698: 0.94794, 9: 0.9508597, 418: 0.9510469, 40: 0.95138687, 604: 0.94948417, 1235: 0.9453901, 577: 0.9486507, 1666: 0.94380516, 1245: 0.9515983, 1673: 0.94504386, 1684: 0.94745344, 68: 0.95115113, 629: 0.95026064, 11: 0.9459688, 1394: 0.94912857, 1582: 0.9424164, 1471: 0.9509829, 384: 0.9516056, 987: 0.9434621, 54: 0.946497, 944: 0.94429684, 1697: 0.9496029, 809: 0.94445705, 675: 0.94614387, 1219: 0.9432889, 309: 0.9481172, 1048: 0.9488623, 1051: 0.9493957, 1204: 0.95281845, 436: 0.9491351, 643: 0.9496965, 981: 0.94681865, 827: 0.9462455, 1377: 0.95129967, 1173: 0.95094186, 551: 0.94963354, 1073: 0.94397825, 412: 0.9438409, 1097: 0.9505478, 363: 0.9498557, 322: 0.94437706, 968: 0.95060885, 907: 0.95015836, 331: 0.9511439, 1086: 0.9466416, 507: 0.94691294, 940: 0.94421905, 1536: 0.94367707, 828: 0.95173776, 786: 0.9423422, 1444: 0.9443149, 534: 0.9504835, 297: 0.949304, 635: 0.9509105, 581: 0.9507648, 1258: 0.9476352, 1604: 0.95053834, 136: 0.9467971, 939: 0.94737506, 1500: 0.95104414, 269: 0.9503328, 288: 0.944661, 1224: 0.9460058, 1493: 0.9501331, 1340: 0.95041025, 260: 0.9494645, 362: 0.94943684, 722: 0.9447616, 1248: 0.94897634, 767: 0.9516707, 866: 0.94765115, 875: 0.9468142, 756: 0.95021474, 706: 0.9457401, 1376: 0.9518805, 49: 0.945931, 1595: 0.94502956, 935: 0.94523287, 984: 0.9500278, 679: 0.9520447, 188: 0.95044416, 1186: 0.95310813, 848: 0.9448729, 1685: 0.9493191, 1724: 0.9500691, 1414: 0.95123416, 1354: 0.9484079, 281: 0.95056224, 522: 0.9501149, 1677: 0.9458492, 103: 0.9503065, 456: 0.94350517, 644: 0.9438455, 1228: 0.94454265, 895: 0.9509083, 541: 0.95129555, 1128: 0.9520003, 1323: 0.9498423, 830: 0.9461752, 1554: 0.9497432, 1020: 0.9505703, 1603: 0.9445283, 1538: 0.9518248, 377: 0.9514069, 473: 0.9444097, 398: 0.9443294, 419: 0.95034707, 129: 0.95178086, 1156: 0.9458239, 1275: 0.9469659, 360: 0.9500178, 751: 0.9466914, 1106: 0.9507973, 1437: 0.95052034, 673: 0.9472615, 1578: 0.943897, 891: 0.94612527, 599: 0.94860107, 351: 0.9487544, 882: 0.94606054, 1036: 0.9515122, 1721: 0.9469712, 1134: 0.9463917, 1153: 0.9508319, 1074: 0.9494292, 901: 0.94458735, 17: 0.94963294, 286: 0.9506541, 344: 0.9465724, 359: 0.9449673, 749: 0.94472283, 348: 0.9445198, 1446: 0.9452326, 249: 0.95005137, 914: 0.94442886, 1347: 0.9508116, 1231: 0.9477445, 929: 0.94701964, 864: 0.94422644, 1190: 0.9490986, 7: 0.9455752, 1198: 0.95088106, 851: 0.9455067, 1384: 0.94717896, 201: 0.946245, 1450: 0.949837, 480: 0.94216645, 1113: 0.94993335, 1077: 0.9527501, 867: 0.9485208, 18: 0.94513977, 1131: 0.946129, 1619: 0.9470245, 1346: 0.9497528, 862: 0.94590443, 1050: 0.9517344, 74: 0.9453598, 770: 0.944353, 1085: 0.95110273, 982: 0.950227, 170: 0.9507913, 464: 0.9508744, 696: 0.95232403, 1544: 0.9464873, 223: 0.94758123, 1038: 0.9498541, 1280: 0.94628793, 1366: 0.9443048, 1479: 0.94712055, 974: 0.9472852, 83: 0.95057106, 814: 0.9453548, 1433: 0.94414717, 1203: 0.95116657, 270: 0.9505366, 1054: 0.95091134, 1624: 0.9493771, 383: 0.94347245, 1385: 0.9462444, 1505: 0.94951165, 1485: 0.94451874, 1080: 0.944602, 1023: 0.94541687, 20: 0.950535, 1067: 0.94888, 385: 0.9507173, 332: 0.9445593, 903: 0.94987464, 324: 0.9505296, 227: 0.9516792, 1408: 0.9438609, 1389: 0.9454545, 1488: 0.9518076, 439: 0.94901687, 361: 0.9443446, 1654: 0.94388264, 753: 0.95086616, 1425: 0.9492348, 990: 0.950393, 554: 0.9460522, 909: 0.9451881, 1180: 0.94979805, 888: 0.95016116, 958: 0.9495982, 530: 0.9458185, 1441: 0.9507346, 469: 0.95199156, 1233: 0.9471756, 1215: 0.94702286, 368: 0.9478183, 1520: 0.94717896, 1570: 0.9499081, 1124: 0.94499487, 560: 0.9454506, 928: 0.94547087, 266: 0.94633716, 1236: 0.9475921, 460: 0.9467969, 1546: 0.9511037, 500: 0.94958884, 1133: 0.9495351, 1031: 0.95090467, 325: 0.94415545, 802: 0.9469247, 476: 0.9497552, 730: 0.9498403, 250: 0.9464875, 765: 0.94994026, 900: 0.9435978, 421: 0.94937164, 685: 0.94563395, 70: 0.94983184, 1247: 0.94973236, 799: 0.9463737, 16: 0.94400257, 1396: 0.9513647, 211: 0.9510209, 113: 0.9521354, 87: 0.94410723, 1037: 0.94593954, 1170: 0.9504105, 1014: 0.95164955, 80: 0.95040476, 1655: 0.94449, 1533: 0.94946414, 1422: 0.94665605, 1162: 0.9445772, 978: 0.95029116, 1674: 0.95021075, 1154: 0.95007366, 748: 0.94365096, 1526: 0.9499923, 703: 0.9527281, 349: 0.9482894, 315: 0.95154524, 1321: 0.9506439, 289: 0.95064205, 1658: 0.94474703, 295: 0.9485016, 1348: 0.95222044, 1284: 0.9492207, 1379: 0.9505808, 1225: 0.9460576, 400: 0.94583684, 1660: 0.94599724, 1220: 0.95070916, 1395: 0.9463222, 1701: 0.9492502, 684: 0.9461171, 553: 0.9458432, 62: 0.9443198, 1283: 0.9501634, 313: 0.94414186, 262: 0.9448494, 1200: 0.94869643, 69: 0.9506204, 1577: 0.9476439, 1253: 0.9472545, 854: 0.95106035, 734: 0.95025104, 66: 0.95028484, 1614: 0.94448894, 708: 0.9433153, 559: 0.94617206, 1213: 0.94606704, 966: 0.9504124, 795: 0.9439943, 116: 0.9472394, 303: 0.94420445, 1632: 0.9467599, 563: 0.9497226, 374: 0.9491106, 402: 0.94624996, 10: 0.9451602, 1209: 0.9497889, 793: 0.95020914, 474: 0.9502448, 896: 0.94421625, 1242: 0.94981194, 271: 0.95095843, 589: 0.94558364, 1217: 0.95405316, 417: 0.95237213, 497: 0.9454684, 1639: 0.9458023, 656: 0.9488779, 196: 0.94985753, 653: 0.9442002, 1222: 0.9495277, 118: 0.94789875, 994: 0.9457349, 949: 0.9463832, 912: 0.94704753, 0: 0.94916755, 1452: 0.9476978, 1492: 0.9482612, 130: 0.95072865, 713: 0.94864833, 1593: 0.9453973, 1063: 0.95169693, 1334: 0.9496311, 1199: 0.94833565, 1717: 0.951535, 391: 0.9496465, 1620: 0.9487973, 1411: 0.9453196, 701: 0.949423, 1478: 0.9446918, 704: 0.9512942, 125: 0.94461817, 1551: 0.9518426, 1019: 0.9466488, 273: 0.9521638, 1529: 0.95160335, 1559: 0.9448827, 447: 0.9519297, 236: 0.9518315, 956: 0.9449538, 81: 0.94689745, 761: 0.9428978, 600: 0.94312274, 1185: 0.9522841, 235: 0.9509, 1656: 0.9462195, 1406: 0.95185506, 1647: 0.94961476, 468: 0.94969916, 28: 0.94495845, 1672: 0.9491392, 1589: 0.9493988, 1250: 0.94983035, 1707: 0.9499654, 350: 0.9435978, 976: 0.94812405, 740: 0.94193166, 1194: 0.9495883, 1454: 0.949347, 1693: 0.9488737, 1022: 0.95028055, 871: 0.9504249, 1537: 0.94746643, 1372: 0.9507457, 401: 0.94979453, 255: 0.95018893, 977: 0.94691145, 175: 0.94643915, 705: 0.94489473, 964: 0.94622624, 797: 0.9467892, 380: 0.9462052, 1386: 0.9460407, 1007: 0.94469064, 1205: 0.9481172, 234: 0.9505596, 584: 0.95117486, 1680: 0.9506889, 1230: 0.9473285, 1041: 0.9507664, 426: 0.9504469, 1032: 0.9451514, 1065: 0.94961476, 277: 0.94434816, 1164: 0.9457037, 736: 0.9514737, 173: 0.9509261, 1576: 0.9470012, 906: 0.9486215, 1256: 0.9488419, 963: 0.94895494, 587: 0.9475251, 26: 0.9489671, 774: 0.94393533, 150: 0.9504194, 651: 0.949599, 1405: 0.9469884, 1174: 0.9500823, 926: 0.94999105, 1114: 0.9495686, 1613: 0.9452924, 700: 0.95098776, 1687: 0.94544894, 366: 0.94337803, 1434: 0.94389033, 1689: 0.95094305, 959: 0.95004934, 683: 0.94686097, 114: 0.948821, 1403: 0.94979256, 1477: 0.950461, 6: 0.9498895, 1088: 0.9482894, 545: 0.9434897, 510: 0.9448664, 1473: 0.94908506, 641: 0.94516015, 1116: 0.95233786, 1141: 0.94504213, 671: 0.9521654, 1100: 0.94444364, 1712: 0.9428301, 1709: 0.94526076, 1669: 0.9465281, 1362: 0.9507656, 839: 0.9499121, 957: 0.9452562, 918: 0.9426888, 1184: 0.950079, 1545: 0.9503534, 1118: 0.946627, 208: 0.9510213, 161: 0.94584846, 1435: 0.9522745, 606: 0.950481, 378: 0.9428188, 998: 0.9459695, 1060: 0.9503261, 636: 0.9500787, 310: 0.9462898, 540: 0.9455643, 1552: 0.94631696, 902: 0.9493728, 108: 0.9429259, 2: 0.94626075, 1486: 0.9465223, 1427: 0.9500912, 1645: 0.945909, 514: 0.9470551, 535: 0.94476575, 1049: 0.9518286, 1541: 0.9462542, 217: 0.94594395, 1274: 0.94555336, 1374: 0.9495325, 971: 0.9522208, 1535: 0.949394, 1499: 0.945403, 1412: 0.9431998, 1586: 0.9492217, 743: 0.9492942, 1682: 0.9456902, 975: 0.9504375, 1445: 0.9503651, 586: 0.95138955, 1252: 0.9447316, 567: 0.9529474, 819: 0.9522077, 1210: 0.94455755, 763: 0.9481852, 489: 0.9501792, 254: 0.9501311, 1108: 0.9483737, 543: 0.94405323, 570: 0.9455522, 771: 0.9475517, 38: 0.94699407, 925: 0.9516094, 792: 0.94700634, 1600: 0.94849443, 399: 0.9447218, 22: 0.95028174, 1564: 0.94942796, 407: 0.95039153, 916: 0.9497595, 897: 0.9450153, 356: 0.94599366, 185: 0.9505731, 127: 0.95002955, 115: 0.9446436, 1512: 0.95033985, 1018: 0.9489052, 181: 0.9506551, 602: 0.9524355, 467: 0.9503125, 132: 0.94555813, 647: 0.94851017, 1424: 0.95296526, 1262: 0.9465801, 585: 0.9420256, 1690: 0.9480995, 755: 0.9484319, 938: 0.9437129, 1587: 0.9452395, 610: 0.944972, 471: 0.9461259, 215: 0.9510792, 335: 0.94498837, 1013: 0.9478215, 1404: 0.9505839, 373: 0.95251966, 1223: 0.9493509, 1216: 0.9521366, 1438: 0.95092106, 60: 0.9509416, 689: 0.94690794, 109: 0.9509343, 1720: 0.9499223, 1702: 0.95105755, 306: 0.9468129, 1322: 0.94907326, 1158: 0.9503986, 1463: 0.9460261, 433: 0.94741225, 375: 0.9460376, 465: 0.95048445, 620: 0.94945806, 23: 0.94841784, 754: 0.94478405, 1521: 0.9491477, 257: 0.94714946, 1286: 0.9495365, 264: 0.95073956, 1105: 0.9507453, 195: 0.95207566, 1318: 0.94549793, 833: 0.94934994, 597: 0.9461934, 1294: 0.9436255, 481: 0.9430167, 204: 0.94421, 737: 0.9463065, 1567: 0.9471208, 531: 0.94735503, 206: 0.94488376, 1281: 0.95148915, 1430: 0.9428124, 318: 0.94989365, 1267: 0.9454085, 1460: 0.95123214, 804: 0.95063674, 699: 0.9474304, 1361: 0.9462138, 490: 0.9503782, 53: 0.9444854, 887: 0.9446419, 568: 0.94596183, 1371: 0.94299966, 811: 0.9505763, 890: 0.94571507, 1532: 0.95061845, 164: 0.9452739, 782: 0.9465113, 769: 0.9468806, 1103: 0.9503543, 598: 0.9526003, 237: 0.9458886, 1547: 0.9446308, 592: 0.95073974, 1191: 0.94444484, 1447: 0.9511037, 654: 0.949898, 596: 0.9496711, 1608: 0.9450659, 1695: 0.94339746, 1306: 0.9506773, 962: 0.9515657, 428: 0.9512634, 712: 0.951111, 457: 0.9455389, 46: 0.95236456, 562: 0.9517238, 317: 0.94741154, 142: 0.95207864, 894: 0.9452111, 847: 0.94951564, 1125: 0.9518184, 1612: 0.9453345, 96: 0.9496541, 1127: 0.9508359, 1542: 0.950729, 1227: 0.94878805, 90: 0.94860256, 1155: 0.9452074, 1516: 0.9511739, 321: 0.95079917, 1342: 0.94549507, 229: 0.9475396, 274: 0.9492424, 1285: 0.9479871, 709: 0.9510669, 1550: 0.94640285, 1211: 0.94816446, 1642: 0.9465418, 1301: 0.9500358, 593: 0.9500604, 1183: 0.9504926, 492: 0.94745356, 291: 0.94497496, 210: 0.9451659, 65: 0.9501904, 547: 0.9455822, 544: 0.94535846, 186: 0.94949245, 1525: 0.95072794, 789: 0.94499713, 1480: 0.9472646, 124: 0.9473103, 1021: 0.9460281, 1472: 0.95064324, 1694: 0.9517483, 1005: 0.9456134, 91: 0.94907176, 1429: 0.9452686, 738: 0.943617, 1030: 0.9473851, 972: 0.94847596, 89: 0.94603044, 826: 0.9441751, 171: 0.94926775, 1075: 0.9502851, 1282: 0.9510945, 853: 0.9499363, 760: 0.95102626, 1514: 0.94829094, 932: 0.94996244, 162: 0.9469132, 880: 0.9442559, 777: 0.95113623, 1325: 0.95108354, 1616: 0.9446587, 1627: 0.9453395, 207: 0.9497788, 1206: 0.9502107, 430: 0.9460531, 1566: 0.9464258, 669: 0.95117, 762: 0.9449343, 1539: 0.9430409, 1459: 0.9505935, 151: 0.9473856, 1467: 0.9451268, 1017: 0.94983494, 1711: 0.9498867, 942: 0.94576603, 347: 0.94519526, 180: 0.9470376, 1703: 0.9500226, 1115: 0.9491267, 989: 0.9507541, 135: 0.9473755, 1387: 0.95030475, 3: 0.9443637, 1592: 0.94374335, 1292: 0.94932836, 1270: 0.9498578, 1265: 0.9509203, 533: 0.9453915, 905: 0.94290626, 1649: 0.9439614, 372: 0.94387203, 1305: 0.944607, 192: 0.9479313, 988: 0.950888, 885: 0.94616455, 860: 0.94312656, 1302: 0.94674546, 1138: 0.9497031, 298: 0.94989645, 275: 0.94995964, 649: 0.9467415, 778: 0.94458616, 1528: 0.95067984, 1708: 0.944488, 434: 0.94687265, 1111: 0.9447422, 1295: 0.949924, 1574: 0.95007515, 820: 0.94937027, 947: 0.949555, 1484: 0.9503409, 165: 0.95029527, 101: 0.95022285, 1364: 0.9445501, 715: 0.94866323, 1629: 0.94478863, 794: 0.9446834, 285: 0.95012724, 571: 0.9504085, 64: 0.9450474, 1453: 0.9462867, 1581: 0.95061934, 911: 0.9443001, 850: 0.9492642, 403: 0.94992465, 930: 0.94994897, 1055: 0.9495354, 1381: 0.9484879, 420: 0.9459305, 1259: 0.94935554, 556: 0.9502401, 459: 0.9461402, 1159: 0.9504564, 870: 0.9463686, 36: 0.9496369, 1046: 0.9495575, 1218: 0.9449969, 1540: 0.94796675, 1053: 0.94549197, 1456: 0.94942474, 1636: 0.9468809, 355: 0.94912714, 1025: 0.9502353, 1119: 0.9502901, 904: 0.95173454, 1568: 0.950852, 1335: 0.94616884, 1704: 0.95081544, 1417: 0.9512857, 1040: 0.9473453, 1440: 0.9491772, 631: 0.95039487, 371: 0.9520936, 282: 0.9440187, 1144: 0.9500171, 834: 0.9498599, 697: 0.94886166, 878: 0.9444774, 1122: 0.9490678, 452: 0.9444911, 466: 0.9502134, 408: 0.95173454, 242: 0.95214045, 1042: 0.94599926, 387: 0.9452053, 1329: 0.9509368, 247: 0.94424784, 157: 0.9502252, 1078: 0.9447141, 1316: 0.94433147, 442: 0.94794726, 624: 0.9480712, 1308: 0.9498284, 99: 0.9457637, 1683: 0.95008063, 1507: 0.9516421, 913: 0.9497091, 1498: 0.9462787, 652: 0.9453672, 595: 0.9463424, 296: 0.9481055, 27: 0.943648, 299: 0.94486535, 1455: 0.94404006, 21: 0.9506809, 245: 0.94769067, 367: 0.9467617, 1610: 0.943029, 779: 0.94802976, 517: 0.9474387, 1297: 0.94462997, 174: 0.9497271, 1143: 0.949948, 1398: 0.9449511, 1602: 0.9499008, 1715: 0.9501844, 406: 0.9447156, 1451: 0.95180047, 169: 0.9502978, 1599: 0.95133483, 440: 0.94500554, 910: 0.95010334, 405: 0.9451603, 1553: 0.9457639, 122: 0.9500389, 178: 0.94625634, 1506: 0.9503018, 346: 0.95218, 246: 0.9462902, 1572: 0.9454801, 1150: 0.94697464, 427: 0.94955015, 153: 0.9492084, 1607: 0.94305456, 1337: 0.94668466, 1083: 0.94481105, 1076: 0.9504373, 908: 0.9504541, 44: 0.9490172, 1527: 0.94469243, 77: 0.94482213, 1696: 0.94964796, 1001: 0.95087004, 147: 0.94595695, 1: 0.9487009, 1175: 0.94480956, 1107: 0.94856167, 82: 0.94457406, 389: 0.9448102, 1326: 0.9469774, 611: 0.9501804, 1691: 0.9447301, 955: 0.9457768, 1026: 0.94608283, 1353: 0.9500004, 1714: 0.9464479, 845: 0.950194, 1112: 0.9507817, 1358: 0.95059013, 482: 0.9436652, 1400: 0.9479224, 1137: 0.945471, 822: 0.95190895, 1168: 0.9512388, 859: 0.9487363, 840: 0.9491862, 1718: 0.9459714, 732: 0.94565076, 31: 0.94756335, 1045: 0.94628465, 409: 0.95134646, 973: 0.9459149, 1120: 0.94953287, 1686: 0.94782096, 1303: 0.95134175, 453: 0.95013285, 499: 0.95092493, 680: 0.9454254, 95: 0.94881207, 863: 0.9494949, 725: 0.94507337, 308: 0.9452878, 844: 0.94887114, 107: 0.9484864, 1071: 0.94920975, 1132: 0.95049924, 519: 0.9451201, 550: 0.950956, 666: 0.9489107, 1336: 0.94614035, 650: 0.9515758, 1289: 0.95104426, 1271: 0.95228994, 1047: 0.9496624, 1123: 0.94369715, 1716: 0.9491801, 444: 0.9461331, 731: 0.94895935, 212: 0.9457628, 594: 0.9458109, 872: 0.9441934, 145: 0.9490288, 477: 0.94664204, 268: 0.9510089, 59: 0.9453632, 1713: 0.9465768, 625: 0.94615346, 179: 0.95026064, 1491: 0.95078856, 739: 0.9496772, 609: 0.9507017, 218: 0.9505342, 723: 0.9502516, 431: 0.9510916, 472: 0.9445687, 1443: 0.9461588, 263: 0.9453011, 1029: 0.9496861, 980: 0.9500346, 222: 0.9428587, 1003: 0.9506814, 1523: 0.94658864, 1307: 0.9471553, 892: 0.9442856, 812: 0.9511877, 413: 0.94643307, 572: 0.94927955, 1069: 0.9499496, 1419: 0.94892436, 915: 0.9447321, 163: 0.9493786, 1197: 0.95047593, 326: 0.9485473, 858: 0.9500873, 1239: 0.9486766, 131: 0.949032, 358: 0.9520684, 48: 0.9505763, 1722: 0.9524818, 98: 0.94973195, 333: 0.95048124, 869: 0.9443069, 29: 0.95005506, 698: 0.94899416, 1367: 0.9507666, 526: 0.9443367, 1109: 0.9476958, 1034: 0.9506171, 985: 0.94600075, 1130: 0.94301766, 1129: 0.94555986, 899: 0.9458731, 658: 0.9447537, 97: 0.94399226, 787: 0.94510293, 1618: 0.9467251, 485: 0.94517833, 1681: 0.94362277, 1350: 0.9455927, 441: 0.94256085, 1196: 0.9503395, 110: 0.94351596, 1556: 0.9465912, 532: 0.9494859, 991: 0.95046896, 634: 0.95014566, 1483: 0.9460207, 461: 0.94871145, 677: 0.9481072, 886: 0.9481857, 446: 0.9488362, 646: 0.9502647, 1152: 0.9441823, 1464: 0.9510733, 682: 0.9508644, 202: 0.94305867, 155: 0.94687957, 172: 0.94577724, 513: 0.9442021, 200: 0.94667006, 1121: 0.9497073, 1628: 0.95136636, 1375: 0.9432271, 744: 0.9515949, 1024: 0.94672143, 655: 0.9488155, 758: 0.94404584, 205: 0.94683844, 47: 0.9488658, 382: 0.9449358, 1634: 0.95017076, 1351: 0.9508108, 718: 0.94601893, 1095: 0.9521553, 1508: 0.94980955, 1091: 0.9485385, 601: 0.94955367, 1588: 0.9486951, 1432: 0.9500674, 868: 0.94391453, 566: 0.95064056, 1015: 0.9508004, 1110: 0.9507348, 922: 0.9498183, 1468: 0.95232594, 1662: 0.95035106, 58: 0.9520698, 1090: 0.9499125, 1249: 0.95029503, 719: 0.94683516, 1373: 0.9511366, 1157: 0.9482993, 1234: 0.9514275, 1237: 0.9498519, 936: 0.9473463, 548: 0.9507545, 1343: 0.9517584, 1061: 0.95115155, 1725: 0.94551957, 1277: 0.94508326, 78: 0.94898254, 302: 0.950542, 1011: 0.94393843, 284: 0.9500445, 119: 0.94956636, 518: 0.94272244, 1149: 0.945643, 823: 0.94671494, 1363: 0.9454637, 775: 0.9500924, 133: 0.9436572, 287: 0.9451202, 424: 0.94613034, 1555: 0.9443805, 51: 0.95121485, 1388: 0.9499565, 1349: 0.9449028, 927: 0.9505708, 1006: 0.951226, 139: 0.9500973, 1442: 0.94569695, 230: 0.94544816, 104: 0.94901323, 508: 0.9483056, 1314: 0.94989306, 1675: 0.9490065, 343: 0.9510448, 883: 0.9499428, 1139: 0.9497396, 1243: 0.94380087, 502: 0.946967, 1101: 0.9453008, 1585: 0.945616, 1058: 0.9504129, 1726: 0.94530475, 244: 0.9514146, 941: 0.95083696, 1671: 0.94452757, 278: 0.94824064, 711: 0.95012885, 1089: 0.9459294, 484: 0.94399756, 943: 0.94364536, 1096: 0.94926476, 856: 0.9497967, 1663: 0.9446031, 111: 0.9464486, 1039: 0.94618493, 710: 0.9478919, 1012: 0.95007724, 565: 0.9430395, 305: 0.9465471, 1392: 0.94896805, 177: 0.94428384, 1515: 0.9442454, 626: 0.945029, 1457: 0.94947106, 232: 0.9475765, 817: 0.9502596, 1309: 0.94171023, 672: 0.9499422, 251: 0.95035017, 1530: 0.9503772, 241: 0.94456, 63: 0.9497959, 199: 0.9525473, 622: 0.9510305, 209: 0.94664246, 1052: 0.950623, 1082: 0.9465472, 1667: 0.9458036, 1266: 0.9459309, 216: 0.9436582, 965: 0.9475765, 39: 0.94954264, 1357: 0.9491969, 1461: 0.948386, 1263: 0.9506974, 790: 0.9491397, 992: 0.9448193, 357: 0.9474397, 470: 0.9442544, 52: 0.9450085, 884: 0.94350016, 515: 0.9504963, 695: 0.9452311, 454: 0.94641703, 1561: 0.9492214, 855: 0.9436913}, 'deepinfra/llama-3-70B': {182: 0.99374205, 825: 0.99372745, 1240: 0.8966408, 505: 0.969185, 1482: 0.99349123, 1549: 0.9886447, 842: 0.8166383, 1605: 0.9892708, 386: 0.8418906, 1622: 0.9091515, 1182: 0.9941298, 1212: 0.9933202, 487: 0.9937687, 148: 0.8383288, 661: 0.99405104, 950: 0.9940989, 393: 0.99372673, 1056: 0.99381155, 259: 0.9424301, 1415: 0.8729769, 523: 0.9931815, 353: 0.9937056, 1391: 0.9936352, 874: 0.99304926, 12: 0.992411, 1700: 0.9295775, 527: 0.76720774, 496: 0.8586617, 483: 0.99280214, 365: 0.9939102, 674: 0.92307985, 93: 0.98167247, 729: 0.89013433, 370: 0.9919608, 714: 0.9874182, 898: 0.91780525, 1344: 0.99400914, 831: 0.9929462, 1723: 0.9684515, 203: 0.9563765, 345: 0.85333127, 67: 0.919956, 1383: 0.85669345, 319: 0.9446756, 852: 0.9495677, 1311: 0.84413266, 45: 0.9850921, 582: 0.80573213, 791: 0.8598078, 781: 0.9931217, 221: 0.6751205, 316: 0.9938146, 857: 0.78553593, 578: 0.99403, 137: 0.99402255, 639: 0.8745631, 1257: 0.99298567, 390: 0.99325174, 5: 0.9931618, 628: 0.99234855, 1402: 0.9366252, 806: 0.9940906, 243: 0.9930177, 720: 0.9871465, 919: 0.99352443, 491: 0.99403065, 768: 0.78856015, 35: 0.85569346, 462: 0.9022095, 414: 0.92309517, 475: 0.9926479, 301: 0.9072243, 923: 0.8889923, 815: 0.9932347, 558: 0.9937915, 1458: 0.9864804, 25: 0.83656794, 810: 0.9933153, 557: 0.9881322, 1368: 0.99392253, 369: 0.86810637, 1470: 0.8434089, 57: 0.80618393, 152: 0.99389887, 307: 0.9928007, 1598: 0.99347043, 1380: 0.875684, 159: 0.9931277, 1382: 0.85643315, 509: 0.8037533, 1665: 0.7981806, 615: 0.9010833, 404: 0.93492925, 396: 0.9934761, 1423: 0.87984604, 1179: 0.99373204, 224: 0.9941346, 1084: 0.9940983, 1359: 0.9081677, 660: 0.8353041, 1099: 0.9163407, 590: 0.99353987, 290: 0.99162453, 1548: 0.9934685, 1420: 0.99215734, 1410: 0.9252058, 967: 0.99399453, 979: 0.8313938, 1421: 0.8513325, 512: 0.9886258, 198: 0.81455356, 102: 0.9928664, 479: 0.9936792, 678: 0.9907073, 970: 0.87582946, 1135: 0.99361885, 1583: 0.9941419, 1028: 0.96126866, 397: 0.90112036, 1522: 0.7215911, 555: 0.8561696, 293: 0.933945, 1504: 0.82244027, 1167: 0.77748215, 1360: 0.9938067, 1469: 0.795589, 1081: 0.86898756, 1192: 0.9938453, 538: 0.8431882, 924: 0.99399287, 394: 0.9676995, 1606: 0.9927073, 1397: 0.8362729, 105: 0.98166156, 997: 0.8931467, 144: 0.7919624, 1288: 0.99316967, 1272: 0.99385625, 100: 0.99298394, 1579: 0.99408495, 1557: 0.9938585, 564: 0.8405263, 501: 0.82412535, 613: 0.9935381, 757: 0.99379456, 1475: 0.9910535, 865: 0.99385273, 1571: 0.99338704, 1511: 0.9929107, 785: 0.7919838, 1251: 0.819483, 1490: 0.993569, 1481: 0.99359965, 24: 0.99369204, 648: 0.99325895, 149: 0.9939468, 1339: 0.99354905, 843: 0.98821545, 253: 0.993779, 379: 0.99368393, 1575: 0.828432, 272: 0.96471345, 670: 0.9918562, 1502: 0.98830146, 1657: 0.9342357, 996: 0.9925472, 702: 0.99365133, 276: 0.9925654, 1070: 0.9377696, 1462: 0.95092505, 603: 0.922222, 588: 0.99053884, 733: 0.99264, 220: 0.987755, 542: 0.9930113, 1355: 0.9920305, 1352: 0.86342025, 197: 0.91668487, 449: 0.99212027, 334: 0.9938261, 614: 0.9884292, 451: 0.9923799, 691: 0.9480949, 681: 0.99382246, 1626: 0.9917762, 766: 0.9942257, 665: 0.898359, 616: 0.9935888, 612: 0.87176466, 154: 0.8718273, 190: 0.993761, 15: 0.86801946, 1268: 0.991755, 8: 0.8205268, 1296: 0.9921003, 329: 0.9387703, 1611: 0.9938081, 1678: 0.9930629, 780: 0.99357903, 4: 0.75907505, 1661: 0.6497734, 1293: 0.95319986, 294: 0.9932407, 1637: 0.8848259, 1365: 0.988247, 686: 0.89454967, 1333: 0.9936202, 1474: 0.98847824, 759: 0.9933496, 1584: 0.9893763, 504: 0.99146104, 395: 0.9918556, 1573: 0.8340115, 240: 0.8887757, 92: 0.99370265, 85: 0.9934685, 1146: 0.98772764, 735: 0.99385023, 1140: 0.826289, 528: 0.992993, 1510: 0.80305284, 495: 0.9869898, 574: 0.9913003, 627: 0.9894449, 261: 0.8695964, 1298: 0.9927993, 1232: 0.987541, 1648: 0.9935522, 821: 0.9940006, 94: 0.9341849, 1495: 0.99309075, 437: 0.99157095, 280: 0.99273974, 120: 0.9931664, 1597: 0.9936958, 520: 0.8393169, 42: 0.9934007, 498: 0.99362, 1633: 0.99308807, 1092: 0.87208354, 835: 0.9723461, 1043: 0.99356693, 1181: 0.94774324, 300: 0.99364024, 920: 0.8546968, 86: 0.99355775, 1569: 0.9881809, 1476: 0.70814943, 1166: 0.92327076, 1016: 0.8233531, 79: 0.99389887, 752: 0.99312866, 986: 0.8027566, 1399: 0.9938008, 1496: 0.95032597, 516: 0.8203947, 1580: 0.80698955, 75: 0.9940918, 969: 0.99051815, 41: 0.6663311, 158: 0.99339384, 1596: 0.8087582, 138: 0.85784465, 832: 0.993414, 645: 0.8419945, 252: 0.83270735, 724: 0.9934575, 561: 0.9925447, 337: 0.9873984, 1176: 0.84972674, 960: 0.99349254, 1719: 0.8394873, 1591: 0.99311185, 61: 0.9936726, 1142: 0.99293125, 1169: 0.9349607, 1331: 0.99397004, 1465: 0.99202746, 539: 0.8436571, 1631: 0.92765766, 312: 0.9934674, 415: 0.9938374, 747: 0.9925567, 953: 0.9938624, 50: 0.9935162, 1638: 0.9375405, 1699: 0.99040765, 1407: 0.7414856, 1560: 0.9864673, 340: 0.9860094, 608: 0.9919774, 524: 0.99391264, 638: 0.9837467, 213: 0.9934953, 1519: 0.9938778, 1356: 0.8797223, 889: 0.9933027, 304: 0.9936067, 1276: 0.79673743, 659: 0.85771185, 801: 0.8698737, 796: 0.98896104, 1093: 0.9909067, 425: 0.86966735, 876: 0.8999156, 381: 0.99291515, 106: 0.7881663, 128: 0.9936452, 1705: 0.87763417, 1098: 0.99192667, 829: 0.9072943, 788: 0.98476297, 248: 0.9889488, 34: 0.99367684, 632: 0.99349654, 1698: 0.98679745, 9: 0.99386203, 418: 0.9920149, 40: 0.9916108, 604: 0.86886406, 1235: 0.8438379, 577: 0.99376136, 1666: 0.8093401, 1245: 0.76977986, 1673: 0.94424284, 1684: 0.98386, 68: 0.9934256, 629: 0.99239963, 11: 0.91409385, 1394: 0.56114167, 1582: 0.780865, 1471: 0.992963, 384: 0.99390996, 987: 0.763367, 54: 0.9838673, 944: 0.8827503, 1697: 0.9925092, 809: 0.8562276, 675: 0.8423761, 1219: 0.98852086, 309: 0.8230488, 1048: 0.98708874, 1051: 0.9936261, 1204: 0.9935854, 436: 0.99200785, 643: 0.9934574, 981: 0.8146301, 827: 0.8513219, 1377: 0.99360317, 1173: 0.9937323, 551: 0.9909931, 1073: 0.82280535, 412: 0.8720332, 1097: 0.99394953, 363: 0.9939575, 322: 0.82593507, 968: 0.9937172, 907: 0.99360496, 331: 0.9938112, 1086: 0.92866254, 507: 0.9267343, 940: 0.8445343, 1536: 0.87057495, 828: 0.99332327, 786: 0.7424018, 1444: 0.81548387, 534: 0.9935476, 297: 0.9927977, 635: 0.99306643, 581: 0.9935464, 1258: 0.9905392, 1604: 0.99387884, 136: 0.8216773, 939: 0.9863492, 1500: 0.9941907, 269: 0.9940055, 288: 0.8953725, 1224: 0.98879737, 1493: 0.96458143, 1340: 0.99321556, 260: 0.9937236, 362: 0.9939154, 722: 0.88782865, 1248: 0.99224687, 767: 0.9935796, 866: 0.90294945, 875: 0.9572968, 756: 0.9939506, 706: 0.7945643, 1376: 0.99355185, 49: 0.9227667, 1595: 0.9487796, 935: 0.8343678, 984: 0.9933188, 679: 0.9927683, 188: 0.9931064, 1186: 0.990144, 848: 0.8016472, 1685: 0.6807439, 1724: 0.9930982, 1414: 0.9933611, 1354: 0.9880074, 281: 0.9939786, 522: 0.99393904, 1677: 0.9292543, 103: 0.9937044, 456: 0.84587145, 644: 0.8680465, 1228: 0.8153895, 895: 0.7821928, 541: 0.989498, 1128: 0.993636, 1323: 0.9926456, 830: 0.987588, 1554: 0.9933509, 1020: 0.99328834, 1603: 0.8707983, 1538: 0.99061394, 377: 0.99269414, 473: 0.8444882, 398: 0.85205555, 419: 0.9935243, 129: 0.9821529, 1156: 0.9454598, 1275: 0.9285005, 360: 0.9926351, 751: 0.9863306, 1106: 0.9932047, 1437: 0.887086, 673: 0.74011403, 1578: 0.8307635, 891: 0.9617152, 599: 0.8584501, 351: 0.82222354, 882: 0.7496636, 1036: 0.9934673, 1721: 0.8072357, 1134: 0.93020487, 1153: 0.99070954, 1074: 0.9929992, 901: 0.93939745, 17: 0.99366826, 286: 0.9940737, 344: 0.8060607, 359: 0.83819044, 749: 0.90998256, 348: 0.9855317, 1446: 0.9478278, 249: 0.9936206, 914: 0.85414183, 1347: 0.9923265, 1231: 0.9893562, 929: 0.92107576, 864: 0.8220378, 1190: 0.99326515, 7: 0.8993108, 1198: 0.9940363, 851: 0.8674956, 1384: 0.9875823, 201: 0.8402425, 1450: 0.7943407, 480: 0.81427, 1113: 0.99367803, 1077: 0.99381834, 867: 0.99338573, 18: 0.8788368, 1131: 0.8794686, 1619: 0.9411846, 1346: 0.99190795, 862: 0.8237638, 1050: 0.9939382, 74: 0.8879119, 770: 0.98471546, 1085: 0.9932985, 982: 0.9933814, 170: 0.99374145, 464: 0.99045676, 696: 0.9938612, 1544: 0.9868154, 223: 0.87158895, 1038: 0.99214786, 1280: 0.83877414, 1366: 0.93642694, 1479: 0.8377432, 974: 0.8431766, 83: 0.9942094, 814: 0.9873319, 1433: 0.8142964, 1203: 0.9931912, 270: 0.99337536, 1054: 0.9936341, 1624: 0.99335104, 383: 0.83868194, 1385: 0.98632765, 1505: 0.9933668, 1485: 0.91060084, 1080: 0.98879576, 1023: 0.8733402, 20: 0.9925182, 1067: 0.99276215, 385: 0.9934823, 332: 0.8903552, 903: 0.9931918, 324: 0.9923659, 227: 0.9928757, 1408: 0.8569341, 1389: 0.7831943, 1488: 0.9925809, 439: 0.984938, 361: 0.87488276, 1654: 0.8771163, 753: 0.9904647, 1425: 0.99381, 990: 0.99331206, 554: 0.71050614, 909: 0.98783594, 1180: 0.9928429, 888: 0.99389863, 958: 0.9690184, 530: 0.8632096, 1441: 0.9938996, 469: 0.99349797, 1233: 0.94270164, 1215: 0.78211415, 368: 0.98513085, 1520: 0.9865216, 1570: 0.9940615, 1124: 0.8353594, 560: 0.88865894, 928: 0.8628179, 266: 0.7880701, 1236: 0.8219553, 460: 0.90945894, 1546: 0.9907568, 500: 0.99370605, 1133: 0.9907122, 1031: 0.9937144, 325: 0.9483655, 802: 0.91084635, 476: 0.99352634, 730: 0.99361366, 250: 0.7954454, 765: 0.99335104, 900: 0.7931038, 421: 0.9934813, 685: 0.8308119, 70: 0.931779, 1247: 0.98925614, 799: 0.7670076, 16: 0.8562559, 1396: 0.99220806, 211: 0.99314004, 113: 0.99407804, 87: 0.74420124, 1037: 0.9886368, 1170: 0.99005324, 1014: 0.7641692, 80: 0.9930292, 1655: 0.93432206, 1533: 0.9926116, 1422: 0.98610073, 1162: 0.9866194, 978: 0.9938944, 1674: 0.993182, 1154: 0.99364257, 748: 0.8808875, 1526: 0.993686, 703: 0.9926846, 349: 0.9933248, 315: 0.99385405, 1321: 0.99401975, 289: 0.9933827, 1658: 0.98628646, 295: 0.98697984, 1348: 0.991523, 1284: 0.9928341, 1379: 0.99378043, 1225: 0.98950803, 400: 0.92784095, 1660: 0.7808323, 1220: 0.69356024, 1395: 0.98972917, 1701: 0.99346656, 684: 0.9566556, 553: 0.83238137, 62: 0.79611754, 1283: 0.9822343, 313: 0.7768446, 262: 0.98775804, 1200: 0.99370766, 69: 0.9937447, 1577: 0.9465143, 1253: 0.8560674, 854: 0.8122697, 734: 0.7005494, 66: 0.9930703, 1614: 0.8850769, 708: 0.8193765, 559: 0.80617106, 1213: 0.7976342, 966: 0.99360234, 795: 0.8759459, 116: 0.9851185, 303: 0.98619044, 1632: 0.9788913, 563: 0.78340656, 374: 0.99406344, 402: 0.87002164, 10: 0.8231995, 1209: 0.9934669, 793: 0.9928894, 474: 0.9930178, 896: 0.8438425, 1242: 0.9932954, 271: 0.9935307, 589: 0.96182954, 1217: 0.99299616, 417: 0.9934087, 497: 0.86096954, 1639: 0.777228, 656: 0.992898, 196: 0.9933915, 653: 0.8462466, 1222: 0.9936572, 118: 0.9404383, 994: 0.90338004, 949: 0.8538563, 912: 0.9857717, 0: 0.9934895, 1452: 0.96303976, 1492: 0.7046076, 130: 0.9930211, 713: 0.5693182, 1593: 0.958523, 1063: 0.99384403, 1334: 0.99405766, 1199: 0.99377865, 1717: 0.99315417, 391: 0.9940275, 1620: 0.9940346, 1411: 0.7435157, 701: 0.9934901, 1478: 0.9045549, 704: 0.9932514, 125: 0.8138146, 1551: 0.99287707, 1019: 0.78542465, 273: 0.9923407, 1529: 0.9926449, 1559: 0.8534351, 447: 0.99356234, 236: 0.993755, 956: 0.8428412, 81: 0.83383024, 761: 0.82178116, 600: 0.8405717, 1185: 0.9935235, 235: 0.82658076, 1656: 0.9543465, 1406: 0.9927779, 1647: 0.7956045, 468: 0.9915388, 28: 0.8367255, 1672: 0.99317765, 1589: 0.9934782, 1250: 0.74595374, 1707: 0.9938036, 350: 0.8696935, 976: 0.8678539, 740: 0.78918684, 1194: 0.9936366, 1454: 0.7502895, 1693: 0.9933559, 1022: 0.99379706, 871: 0.99349385, 1537: 0.98943603, 1372: 0.9934906, 401: 0.9925237, 255: 0.9938943, 977: 0.8071131, 175: 0.8510059, 705: 0.916295, 964: 0.9877438, 797: 0.8141525, 380: 0.8335068, 1386: 0.86612296, 1007: 0.9490443, 1205: 0.99337137, 234: 0.99366176, 584: 0.9939203, 1680: 0.9936301, 1230: 0.7869115, 1041: 0.99347514, 426: 0.9938944, 1032: 0.8060199, 1065: 0.9933401, 277: 0.9042459, 1164: 0.94221985, 736: 0.992943, 173: 0.99336135, 1576: 0.822517, 906: 0.9935481, 1256: 0.5693976, 963: 0.9934529, 587: 0.93863404, 26: 0.9934788, 774: 0.8604851, 150: 0.9931016, 651: 0.9937959, 1405: 0.90520936, 1174: 0.9934657, 926: 0.99335456, 1114: 0.9940526, 1613: 0.95705354, 700: 0.9927285, 1687: 0.799229, 366: 0.8571296, 1434: 0.98561054, 1689: 0.9933955, 959: 0.9929166, 683: 0.9249364, 114: 0.99319696, 1403: 0.9939711, 1477: 0.99403536, 6: 0.9936392, 1088: 0.9934608, 545: 0.92755574, 510: 0.884661, 1473: 0.9937395, 641: 0.9250652, 1116: 0.9928704, 1141: 0.94508314, 671: 0.9929709, 1100: 0.7598597, 1712: 0.9134932, 1709: 0.8172073, 1669: 0.98894775, 1362: 0.99347407, 839: 0.9940374, 957: 0.83280164, 918: 0.87173843, 1184: 0.9927907, 1545: 0.9931415, 1118: 0.98870426, 208: 0.992766, 161: 0.9077398, 1435: 0.9915575, 606: 0.99284333, 378: 0.98736584, 998: 0.98763543, 1060: 0.99377453, 636: 0.99332494, 310: 0.8630769, 540: 0.90954083, 1552: 0.98818237, 902: 0.99202865, 108: 0.8422724, 2: 0.7271542, 1486: 0.8884577, 1427: 0.99085426, 1645: 0.8922003, 514: 0.784692, 535: 0.98875624, 1049: 0.9932376, 1541: 0.9423217, 217: 0.91834605, 1274: 0.9350427, 1374: 0.9843407, 971: 0.9930528, 1535: 0.99392587, 1499: 0.99164397, 1412: 0.8732822, 1586: 0.99405056, 743: 0.9937023, 1682: 0.8357569, 975: 0.9929709, 1445: 0.99338114, 586: 0.9938095, 1252: 0.78148144, 567: 0.99373466, 819: 0.9919482, 1210: 0.8936002, 763: 0.9941754, 489: 0.9931358, 254: 0.9939466, 1108: 0.5656672, 543: 0.882874, 570: 0.9889081, 771: 0.9411651, 38: 0.9678322, 925: 0.9936247, 792: 0.98946065, 1600: 0.9940281, 399: 0.9885775, 22: 0.99376464, 1564: 0.9933891, 407: 0.99384165, 916: 0.993334, 897: 0.90201765, 356: 0.7529064, 185: 0.99364316, 127: 0.993936, 115: 0.90401596, 1512: 0.99372685, 1018: 0.9931629, 181: 0.99357295, 602: 0.9933321, 467: 0.99328715, 132: 0.8382487, 647: 0.9523335, 1424: 0.99232763, 1262: 0.9351648, 585: 0.8758934, 1690: 0.986914, 755: 0.98736435, 938: 0.8273267, 1587: 0.78067476, 610: 0.8540518, 471: 0.9624435, 215: 0.99345315, 335: 0.84217215, 1013: 0.94371444, 1404: 0.9912369, 373: 0.9905256, 1223: 0.99410456, 1216: 0.9936035, 1438: 0.99382824, 60: 0.9935581, 689: 0.8011616, 109: 0.993735, 1720: 0.98979175, 1702: 0.99288917, 306: 0.8300458, 1322: 0.9934803, 1158: 0.98464847, 1463: 0.9858811, 433: 0.7859108, 375: 0.9088756, 465: 0.9938403, 620: 0.9927367, 23: 0.98717725, 754: 0.8677024, 1521: 0.99316, 257: 0.92693585, 1286: 0.99367416, 264: 0.9936976, 1105: 0.99330163, 195: 0.9926979, 1318: 0.96096736, 833: 0.99313956, 597: 0.9936446, 1294: 0.98623174, 481: 0.8391802, 204: 0.85455304, 737: 0.99006325, 1567: 0.8026819, 531: 0.9600417, 206: 0.9227007, 1281: 0.993786, 1430: 0.89474326, 318: 0.99297583, 1267: 0.9880369, 1460: 0.98258173, 804: 0.9936935, 699: 0.8360777, 1361: 0.95807624, 490: 0.9940111, 53: 0.8832556, 887: 0.88825977, 568: 0.7948213, 1371: 0.8600318, 811: 0.7840682, 890: 0.93567395, 1532: 0.99297696, 164: 0.95826614, 782: 0.7909335, 769: 0.98790634, 1103: 0.99372697, 598: 0.99322355, 237: 0.8410005, 1547: 0.80799943, 592: 0.9939349, 1191: 0.98721176, 1447: 0.99374855, 654: 0.99335104, 596: 0.9935768, 1608: 0.8521407, 1695: 0.85036486, 1306: 0.9936894, 962: 0.9941099, 428: 0.9896513, 712: 0.990642, 457: 0.900836, 46: 0.9935563, 562: 0.99335265, 317: 0.82418835, 142: 0.99304694, 894: 0.98866177, 847: 0.9939375, 1125: 0.99273515, 1612: 0.945385, 96: 0.9934289, 1127: 0.9934448, 1542: 0.9821806, 1227: 0.9926519, 90: 0.87255657, 1155: 0.7656695, 1516: 0.9937144, 321: 0.99385697, 1342: 0.8581343, 229: 0.8046415, 274: 0.9938205, 1285: 0.88715214, 709: 0.8593269, 1550: 0.9443686, 1211: 0.5649192, 1642: 0.95186496, 1301: 0.9928584, 593: 0.99295324, 1183: 0.993971, 492: 0.79521614, 291: 0.8315288, 210: 0.88220865, 65: 0.9934772, 547: 0.98414326, 544: 0.756904, 186: 0.9935787, 1525: 0.9927133, 789: 0.86366534, 1480: 0.8985306, 124: 0.93808776, 1021: 0.987288, 1472: 0.99416095, 1694: 0.99380255, 1005: 0.9612659, 91: 0.9939889, 1429: 0.9571288, 738: 0.80733764, 1030: 0.98362595, 972: 0.88943654, 89: 0.8974557, 826: 0.89539105, 171: 0.9861456, 1075: 0.99368554, 1282: 0.9940592, 853: 0.9936167, 760: 0.93160194, 1514: 0.96016574, 932: 0.9915394, 162: 0.9860523, 880: 0.8994876, 777: 0.99345464, 1325: 0.991738, 1616: 0.9020896, 1627: 0.9269389, 207: 0.99366766, 1206: 0.9934608, 430: 0.9871083, 1566: 0.8970439, 669: 0.9929965, 762: 0.96161896, 1539: 0.8005705, 1459: 0.99354494, 151: 0.9876918, 1467: 0.82276183, 1017: 0.99373007, 1711: 0.99360067, 942: 0.82799524, 347: 0.8941745, 180: 0.8341788, 1703: 0.99330306, 1115: 0.97125834, 989: 0.9934081, 135: 0.7855318, 1387: 0.99380624, 3: 0.7622577, 1592: 0.8553202, 1292: 0.99347275, 1270: 0.9930744, 1265: 0.99052155, 533: 0.9935394, 905: 0.88138473, 1649: 0.8386024, 372: 0.89364344, 1305: 0.89622223, 192: 0.9935762, 988: 0.9931874, 885: 0.9876517, 860: 0.81156605, 1302: 0.96600795, 1138: 0.6980249, 298: 0.99370277, 275: 0.99351305, 649: 0.9610059, 778: 0.78957963, 1528: 0.99159324, 1708: 0.9340531, 434: 0.87811875, 1111: 0.98902553, 1295: 0.99400055, 1574: 0.99393773, 820: 0.9939573, 947: 0.99313605, 1484: 0.99390703, 165: 0.9902256, 101: 0.993899, 1364: 0.8420471, 715: 0.9934876, 1629: 0.8577529, 794: 0.70596635, 285: 0.9928883, 571: 0.99359494, 64: 0.989661, 1453: 0.9831838, 1581: 0.99259466, 911: 0.8298515, 850: 0.994034, 403: 0.98966295, 930: 0.993731, 1055: 0.993005, 1381: 0.9435495, 420: 0.7706284, 1259: 0.9938591, 556: 0.9938736, 459: 0.93247795, 1159: 0.9927164, 870: 0.9886674, 36: 0.9934449, 1046: 0.99322903, 1218: 0.9007286, 1540: 0.8958818, 1053: 0.9011919, 1456: 0.99224913, 1636: 0.98912114, 355: 0.9937249, 1025: 0.99334323, 1119: 0.99396414, 904: 0.9941023, 1568: 0.9937162, 1335: 0.95469856, 1704: 0.99131656, 1417: 0.9928935, 1040: 0.94750965, 1440: 0.99380386, 631: 0.98958766, 371: 0.99212426, 282: 0.88137144, 1144: 0.9930016, 834: 0.99354124, 697: 0.8854215, 878: 0.6804785, 1122: 0.99334246, 452: 0.9887517, 466: 0.993757, 408: 0.8287201, 242: 0.9938198, 1042: 0.95865685, 387: 0.81326336, 1329: 0.9938308, 247: 0.81970143, 157: 0.9933286, 1078: 0.98673356, 1316: 0.84845024, 442: 0.8272915, 624: 0.98307943, 1308: 0.99376535, 99: 0.7895686, 1683: 0.99345326, 1507: 0.9932747, 913: 0.99354666, 1498: 0.8227015, 652: 0.9353471, 595: 0.9471538, 296: 0.9858665, 27: 0.78273237, 299: 0.72830397, 1455: 0.82624537, 21: 0.99323696, 245: 0.6964038, 367: 0.9885367, 1610: 0.8806051, 779: 0.8445775, 517: 0.9801033, 1297: 0.8804428, 174: 0.99314016, 1143: 0.66827023, 1398: 0.95330507, 1602: 0.9926467, 1715: 0.9936273, 406: 0.8078077, 1451: 0.9934917, 169: 0.9936324, 1599: 0.9939037, 440: 0.9002189, 910: 0.99272126, 405: 0.83132, 1553: 0.9868946, 122: 0.9938391, 178: 0.9177416, 1506: 0.99326694, 346: 0.9938036, 246: 0.82929504, 1572: 0.83259046, 1150: 0.8331853, 427: 0.99236816, 153: 0.9927267, 1607: 0.81343675, 1337: 0.9272766, 1083: 0.98906344, 1076: 0.9932469, 908: 0.9935441, 44: 0.99328184, 1527: 0.94604516, 77: 0.8053314, 1696: 0.99387544, 1001: 0.992943, 147: 0.80113196, 1: 0.9936745, 1175: 0.9891367, 1107: 0.9934767, 82: 0.8595671, 389: 0.8166153, 1326: 0.99397993, 611: 0.99351305, 1691: 0.87034446, 955: 0.8413811, 1026: 0.9016404, 1353: 0.993662, 1714: 0.9589339, 845: 0.99312663, 1112: 0.99352646, 1358: 0.9938028, 482: 0.8069261, 1400: 0.9175814, 1137: 0.9367713, 822: 0.7490999, 1168: 0.9929899, 859: 0.9880504, 840: 0.99333763, 1718: 0.8313335, 732: 0.9696576, 31: 0.81286806, 1045: 0.9208504, 409: 0.99271154, 973: 0.98766565, 1120: 0.9942649, 1686: 0.9845212, 1303: 0.82136554, 453: 0.99400055, 499: 0.9913093, 680: 0.9479911, 95: 0.9354732, 863: 0.9938798, 725: 0.93633056, 308: 0.91578877, 844: 0.93388957, 107: 0.9260968, 1071: 0.9938262, 1132: 0.99394727, 519: 0.98694825, 550: 0.9932248, 666: 0.9932841, 1336: 0.89728606, 650: 0.99345666, 1289: 0.99377775, 1271: 0.8805404, 1047: 0.9930621, 1123: 0.9376354, 1716: 0.99365133, 444: 0.9653679, 731: 0.98611253, 212: 0.8265229, 594: 0.85498786, 872: 0.849188, 145: 0.9933994, 477: 0.85308444, 268: 0.9934922, 59: 0.8052717, 1713: 0.9842195, 625: 0.9092268, 179: 0.99387205, 1491: 0.9933176, 739: 0.9940514, 609: 0.9938339, 218: 0.9937034, 723: 0.993775, 431: 0.9928583, 472: 0.8291427, 1443: 0.9606285, 263: 0.9332174, 1029: 0.9935616, 980: 0.69677764, 222: 0.8047249, 1003: 0.9899204, 1523: 0.9661122, 1307: 0.93801564, 892: 0.83383834, 812: 0.99362904, 413: 0.98732936, 572: 0.99322224, 1069: 0.9926156, 1419: 0.9934237, 915: 0.98730123, 163: 0.9939282, 1197: 0.9933674, 326: 0.76101714, 858: 0.8843884, 1239: 0.9941731, 131: 0.81855106, 358: 0.9938275, 48: 0.99326044, 1722: 0.99309945, 98: 0.9936039, 333: 0.9930441, 869: 0.98734736, 29: 0.98981726, 698: 0.9939407, 1367: 0.99377173, 526: 0.85132885, 1109: 0.8302958, 1034: 0.9911629, 985: 0.81241685, 1130: 0.79474473, 1129: 0.9845169, 899: 0.8923287, 658: 0.8162427, 97: 0.80011064, 787: 0.9026977, 1618: 0.98794985, 485: 0.87759924, 1681: 0.8235359, 1350: 0.8938026, 441: 0.8461459, 1196: 0.9934964, 110: 0.99001276, 1556: 0.9890505, 532: 0.9940071, 991: 0.9931403, 634: 0.993299, 1483: 0.95850056, 461: 0.9306127, 677: 0.9696665, 886: 0.9926112, 446: 0.9935394, 646: 0.9938111, 1152: 0.98954964, 1464: 0.99092835, 682: 0.99395305, 202: 0.8283816, 155: 0.982441, 172: 0.992601, 513: 0.9895719, 200: 0.98517275, 1121: 0.92568207, 1628: 0.76784194, 1375: 0.9573512, 744: 0.9936666, 1024: 0.8180378, 655: 0.9938547, 758: 0.985024, 205: 0.99354327, 47: 0.9937318, 382: 0.81055933, 1634: 0.99035805, 1351: 0.9931632, 718: 0.904272, 1095: 0.99372756, 1508: 0.9930697, 1091: 0.9927158, 601: 0.99322367, 1588: 0.9938181, 1432: 0.9929765, 868: 0.9867519, 566: 0.9932112, 1015: 0.81820697, 1110: 0.99319446, 922: 0.987728, 1468: 0.9928779, 1662: 0.9934633, 58: 0.99401456, 1090: 0.99377865, 1249: 0.99282324, 719: 0.9473145, 1373: 0.99308926, 1157: 0.98713243, 1234: 0.99341244, 1237: 0.9930748, 936: 0.5858392, 548: 0.9919636, 1343: 0.9900519, 1061: 0.99239105, 1725: 0.986832, 1277: 0.9667994, 78: 0.9422748, 302: 0.99410254, 1011: 0.98775345, 284: 0.9925493, 119: 0.9924285, 518: 0.8785547, 1149: 0.9523811, 823: 0.9119313, 1363: 0.79067063, 775: 0.9686601, 133: 0.82096964, 287: 0.79537696, 424: 0.8239925, 1555: 0.8487251, 51: 0.9937079, 1388: 0.9930434, 1349: 0.84062505, 927: 0.9936883, 1006: 0.9926313, 139: 0.9934349, 1442: 0.9457072, 230: 0.85251856, 104: 0.991757, 508: 0.95235604, 1314: 0.9938996, 1675: 0.99404186, 343: 0.993555, 883: 0.9918508, 1139: 0.7568882, 1243: 0.86606854, 502: 0.8004604, 1101: 0.8312506, 1585: 0.97448325, 1058: 0.99298006, 1726: 0.8129027, 244: 0.99226487, 941: 0.9935502, 1671: 0.781226, 278: 0.9880982, 711: 0.9928558, 1089: 0.8304648, 484: 0.79380816, 943: 0.98848116, 1096: 0.9936469, 856: 0.9936919, 1663: 0.9820816, 111: 0.96980715, 1039: 0.9864662, 710: 0.8546949, 1012: 0.9934289, 565: 0.8203458, 305: 0.93946236, 1392: 0.99381363, 177: 0.928902, 1515: 0.8097806, 626: 0.7888418, 1457: 0.9938267, 232: 0.8175252, 817: 0.99381316, 1309: 0.85848, 672: 0.9932968, 251: 0.99288905, 1530: 0.8301953, 241: 0.89250135, 63: 0.99335504, 199: 0.99200976, 622: 0.9930447, 209: 0.9888272, 1052: 0.99327856, 1082: 0.9675551, 1667: 0.97944427, 1266: 0.9892279, 216: 0.9020979, 965: 0.9883058, 39: 0.99307764, 1357: 0.9935581, 1461: 0.8123434, 1263: 0.99376184, 790: 0.99336034, 992: 0.9157626, 357: 0.9045566, 470: 0.81417745, 52: 0.86191833, 884: 0.88457483, 515: 0.99114203, 695: 0.87451714, 454: 0.8243635, 1561: 0.993601, 855: 0.7938204}, 'deepinfra/mixtral-8x7B': {182: 0.9631803, 825: 0.96725446, 1240: 0.94920963, 505: 0.9512987, 1482: 0.9670929, 1549: 0.9607535, 842: 0.9510806, 1605: 0.9617635, 386: 0.94453317, 1622: 0.9491781, 1182: 0.9634779, 1212: 0.9690185, 487: 0.96601707, 148: 0.9507217, 661: 0.9627453, 950: 0.96895075, 393: 0.96649843, 1056: 0.9676972, 259: 0.9514464, 1415: 0.9485515, 523: 0.96685034, 353: 0.9674919, 1391: 0.97042006, 874: 0.9491888, 12: 0.9659456, 1700: 0.953849, 527: 0.95471084, 496: 0.9490085, 483: 0.96891236, 365: 0.96222144, 674: 0.95246696, 93: 0.9562447, 729: 0.9512533, 370: 0.96714836, 714: 0.9575124, 898: 0.95726335, 1344: 0.96833706, 831: 0.96796876, 1723: 0.95096457, 203: 0.9490812, 345: 0.9490243, 67: 0.9480486, 1383: 0.946244, 319: 0.95243615, 852: 0.9504891, 1311: 0.94904286, 45: 0.9631323, 582: 0.9481576, 791: 0.9521759, 781: 0.9646024, 221: 0.97012043, 316: 0.9519636, 857: 0.95337313, 578: 0.9684659, 137: 0.96519107, 639: 0.94741005, 1257: 0.9646949, 390: 0.97122765, 5: 0.961818, 628: 0.9652282, 1402: 0.95481724, 806: 0.962737, 243: 0.9661344, 720: 0.9592042, 919: 0.96493727, 491: 0.96637714, 768: 0.94963056, 35: 0.946931, 462: 0.95180416, 414: 0.9509053, 475: 0.9664629, 301: 0.9505257, 923: 0.9506902, 815: 0.96477383, 558: 0.96452534, 1458: 0.9544752, 25: 0.949236, 810: 0.96566254, 557: 0.9526514, 1368: 0.9639745, 369: 0.95001954, 1470: 0.9473808, 57: 0.9522992, 152: 0.96788555, 307: 0.9668933, 1598: 0.967793, 1380: 0.94623375, 159: 0.9679805, 1382: 0.94724613, 509: 0.947655, 1665: 0.95043504, 615: 0.9459764, 404: 0.9511549, 396: 0.9682008, 1423: 0.94573957, 1179: 0.9627252, 224: 0.96405965, 1084: 0.96140033, 1359: 0.9477457, 660: 0.94675606, 1099: 0.95567137, 590: 0.9650805, 290: 0.96407837, 1548: 0.9672599, 1420: 0.9662982, 1410: 0.9582924, 967: 0.96824, 979: 0.950428, 1421: 0.95363754, 512: 0.9552331, 198: 0.95226693, 102: 0.96876884, 479: 0.9674155, 678: 0.95312756, 970: 0.94864565, 1135: 0.96575433, 1583: 0.963628, 1028: 0.95493716, 397: 0.9451102, 1522: 0.9667713, 555: 0.94826335, 293: 0.9496526, 1504: 0.95392394, 1167: 0.95105094, 1360: 0.9644395, 1469: 0.9531621, 1081: 0.9629854, 1192: 0.96288335, 538: 0.9510932, 924: 0.96531695, 394: 0.95664537, 1606: 0.9658837, 1397: 0.9490466, 105: 0.9520402, 997: 0.9470878, 144: 0.9506718, 1288: 0.9695067, 1272: 0.96583575, 100: 0.96340877, 1579: 0.96424526, 1557: 0.96699077, 564: 0.95711887, 501: 0.9568719, 613: 0.9666616, 757: 0.9613384, 1475: 0.9663285, 865: 0.9642179, 1571: 0.967653, 1511: 0.96898997, 785: 0.9563377, 1251: 0.9504499, 1490: 0.96617067, 1481: 0.96650296, 24: 0.96227264, 648: 0.96654934, 149: 0.96814436, 1339: 0.9688394, 843: 0.9559798, 253: 0.96422225, 379: 0.96830016, 1575: 0.95818996, 272: 0.9506681, 670: 0.9684368, 1502: 0.95913094, 1657: 0.95112795, 996: 0.96637774, 702: 0.97129077, 276: 0.96989274, 1070: 0.95258594, 1462: 0.9478266, 603: 0.9523113, 588: 0.9663452, 733: 0.9679367, 220: 0.96584463, 542: 0.9624181, 1355: 0.96630204, 1352: 0.9487446, 197: 0.9485049, 449: 0.9627536, 334: 0.9655905, 614: 0.95618194, 451: 0.9621967, 691: 0.9540653, 681: 0.9624606, 1626: 0.96551913, 766: 0.9652072, 665: 0.94879043, 616: 0.9639996, 612: 0.9489458, 154: 0.9487627, 190: 0.96636283, 15: 0.9465474, 1268: 0.9635694, 8: 0.9491879, 1296: 0.9695174, 329: 0.9504078, 1611: 0.9653876, 1678: 0.9634995, 780: 0.96707404, 4: 0.9561292, 1661: 0.9350196, 1293: 0.95214295, 294: 0.9694792, 1637: 0.94616085, 1365: 0.9643859, 686: 0.94779676, 1333: 0.96668506, 1474: 0.9602927, 759: 0.96463734, 1584: 0.96497124, 504: 0.96658486, 395: 0.95064217, 1573: 0.9560505, 240: 0.94739383, 92: 0.96202713, 85: 0.9506191, 1146: 0.9553727, 735: 0.9620685, 1140: 0.9473149, 528: 0.9685801, 1510: 0.9524634, 495: 0.96012604, 574: 0.9637875, 627: 0.95739, 261: 0.94693124, 1298: 0.96153134, 1232: 0.95696217, 1648: 0.96504843, 821: 0.9675992, 94: 0.95413923, 1495: 0.9671609, 437: 0.9641503, 280: 0.9709673, 120: 0.9651479, 1597: 0.9680216, 520: 0.94777524, 42: 0.9627379, 498: 0.96972835, 1633: 0.96641636, 1092: 0.9492582, 835: 0.95447826, 1043: 0.9655903, 1181: 0.9460826, 300: 0.9657321, 920: 0.9524848, 86: 0.9654309, 1569: 0.96215314, 1476: 0.9482145, 1166: 0.9515051, 1016: 0.95132405, 79: 0.9645201, 752: 0.9661822, 986: 0.9541042, 1399: 0.96584755, 1496: 0.9461193, 516: 0.95410776, 1580: 0.9519382, 75: 0.96187764, 969: 0.95802593, 41: 0.9430596, 158: 0.96701115, 1596: 0.9499336, 138: 0.9529848, 832: 0.96729213, 645: 0.9479659, 252: 0.9492265, 724: 0.9630692, 561: 0.96747094, 337: 0.95874745, 1176: 0.9510645, 960: 0.9670665, 1719: 0.944659, 1591: 0.9662723, 61: 0.9659913, 1142: 0.9641155, 1169: 0.9493193, 1331: 0.9628857, 1465: 0.9672806, 539: 0.9492726, 1631: 0.95072067, 312: 0.96873605, 415: 0.96452487, 747: 0.96484864, 953: 0.9648416, 50: 0.96194583, 1638: 0.9531472, 1699: 0.9609525, 1407: 0.9598451, 1560: 0.96034294, 340: 0.9589911, 608: 0.9657569, 524: 0.96791214, 638: 0.95841724, 213: 0.9665945, 1519: 0.9675033, 1356: 0.94552684, 889: 0.9636802, 304: 0.9662158, 1276: 0.95209324, 659: 0.9576628, 801: 0.9467767, 796: 0.9603743, 1093: 0.9627136, 425: 0.948448, 876: 0.9470473, 381: 0.9660177, 106: 0.94894314, 128: 0.96356124, 1705: 0.9490435, 1098: 0.9628451, 829: 0.9439653, 788: 0.95489645, 248: 0.9693862, 34: 0.9662872, 632: 0.96358436, 1698: 0.9556868, 9: 0.970425, 418: 0.9656613, 40: 0.9666421, 604: 0.9562216, 1235: 0.9525133, 577: 0.9654331, 1666: 0.9461872, 1245: 0.96661055, 1673: 0.949713, 1684: 0.9583746, 68: 0.9643716, 629: 0.96770066, 11: 0.94627345, 1394: 0.8953082, 1582: 0.9462474, 1471: 0.97026414, 384: 0.9669836, 987: 0.9466474, 54: 0.9509056, 944: 0.94652635, 1697: 0.9658287, 809: 0.94408077, 675: 0.96096057, 1219: 0.9498055, 309: 0.9542331, 1048: 0.9583066, 1051: 0.9652153, 1204: 0.9674338, 436: 0.9649447, 643: 0.9663203, 981: 0.9541432, 827: 0.9544582, 1377: 0.96820664, 1173: 0.96260357, 551: 0.9668852, 1073: 0.9490229, 412: 0.94489676, 1097: 0.9737737, 363: 0.9610686, 322: 0.94897676, 968: 0.9651739, 907: 0.9681408, 331: 0.96653336, 1086: 0.9567811, 507: 0.94920236, 940: 0.95018184, 1536: 0.9446309, 828: 0.96991247, 786: 0.9245958, 1444: 0.95299476, 534: 0.96622056, 297: 0.96827465, 635: 0.96584845, 581: 0.9665921, 1258: 0.9590601, 1604: 0.9685305, 136: 0.9529402, 939: 0.9560891, 1500: 0.963157, 269: 0.9669926, 288: 0.94406664, 1224: 0.9545942, 1493: 0.95631915, 1340: 0.96268964, 260: 0.96591115, 362: 0.9633358, 722: 0.95006216, 1248: 0.96171254, 767: 0.9674388, 866: 0.95589113, 875: 0.95571905, 756: 0.96198046, 706: 0.9479754, 1376: 0.9653171, 49: 0.9525257, 1595: 0.9548257, 935: 0.9505731, 984: 0.9654787, 679: 0.9679965, 188: 0.9655272, 1186: 0.9676801, 848: 0.95136416, 1685: 0.963718, 1724: 0.9638141, 1414: 0.9678614, 1354: 0.96008277, 281: 0.96428776, 522: 0.9639262, 1677: 0.94745034, 103: 0.96641266, 456: 0.9463928, 644: 0.9471714, 1228: 0.94669235, 895: 0.9665317, 541: 0.9655108, 1128: 0.96821713, 1323: 0.96713, 830: 0.95000696, 1554: 0.9659869, 1020: 0.96549183, 1603: 0.9484394, 1538: 0.9672587, 377: 0.9663567, 473: 0.9484143, 398: 0.9446552, 419: 0.9683026, 129: 0.9509661, 1156: 0.95075864, 1275: 0.95168453, 360: 0.9660036, 751: 0.95774424, 1106: 0.96664757, 1437: 0.96330565, 673: 0.9551799, 1578: 0.949527, 891: 0.94799995, 599: 0.95062816, 351: 0.95138824, 882: 0.95037174, 1036: 0.96935344, 1721: 0.9487379, 1134: 0.9490056, 1153: 0.96349573, 1074: 0.9621656, 901: 0.9500171, 17: 0.9631433, 286: 0.96161103, 344: 0.96111995, 359: 0.94752634, 749: 0.94874203, 348: 0.94729406, 1446: 0.9483773, 249: 0.9657031, 914: 0.94584525, 1347: 0.9677461, 1231: 0.9587052, 929: 0.9487225, 864: 0.9472833, 1190: 0.96492517, 7: 0.94818074, 1198: 0.9679595, 851: 0.9537364, 1384: 0.9576766, 201: 0.944463, 1450: 0.9525392, 480: 0.9499294, 1113: 0.96590424, 1077: 0.9698747, 867: 0.9662594, 18: 0.94558203, 1131: 0.945026, 1619: 0.9561742, 1346: 0.94747144, 862: 0.95252115, 1050: 0.96663207, 74: 0.9523012, 770: 0.95713633, 1085: 0.97051346, 982: 0.96430737, 170: 0.9652991, 464: 0.96749264, 696: 0.96810615, 1544: 0.95952404, 223: 0.95199835, 1038: 0.9666676, 1280: 0.94479656, 1366: 0.9473502, 1479: 0.95161575, 974: 0.95116794, 83: 0.9632369, 814: 0.95437294, 1433: 0.9488422, 1203: 0.9681516, 270: 0.971068, 1054: 0.96820396, 1624: 0.9649827, 383: 0.9450467, 1385: 0.9566551, 1505: 0.9667208, 1485: 0.9496631, 1080: 0.95321226, 1023: 0.9469323, 20: 0.9623752, 1067: 0.96454096, 385: 0.9628224, 332: 0.94594646, 903: 0.9646886, 324: 0.965551, 227: 0.96776766, 1408: 0.948848, 1389: 0.94956726, 1488: 0.9638026, 439: 0.9552934, 361: 0.9449527, 1654: 0.94884694, 753: 0.96573967, 1425: 0.96428937, 990: 0.96682745, 554: 0.9649357, 909: 0.9523683, 1180: 0.96229285, 888: 0.9634218, 958: 0.9531398, 530: 0.94871616, 1441: 0.96603364, 469: 0.97022027, 1233: 0.95889705, 1215: 0.9526101, 368: 0.9566099, 1520: 0.95820045, 1570: 0.9639142, 1124: 0.95113635, 560: 0.94467956, 928: 0.9513655, 266: 0.9502336, 1236: 0.9510556, 460: 0.955069, 1546: 0.96720916, 500: 0.9627511, 1133: 0.9633252, 1031: 0.9628891, 325: 0.94945407, 802: 0.95548904, 476: 0.9645345, 730: 0.9689565, 250: 0.95493704, 765: 0.9673863, 900: 0.9495756, 421: 0.9704334, 685: 0.95098656, 70: 0.9566011, 1247: 0.9680619, 799: 0.9520781, 16: 0.94780105, 1396: 0.9671154, 211: 0.96584165, 113: 0.9671231, 87: 0.951171, 1037: 0.95037615, 1170: 0.96461296, 1014: 0.96496314, 80: 0.96646714, 1655: 0.9518192, 1533: 0.9653791, 1422: 0.9570494, 1162: 0.95397645, 978: 0.96334666, 1674: 0.96709466, 1154: 0.9684815, 748: 0.9485118, 1526: 0.96237963, 703: 0.96905667, 349: 0.9700075, 315: 0.9648041, 1321: 0.96427065, 289: 0.96717227, 1658: 0.9588244, 295: 0.9596711, 1348: 0.96659285, 1284: 0.96383303, 1379: 0.96404904, 1225: 0.9579435, 400: 0.9537613, 1660: 0.9508432, 1220: 0.96499246, 1395: 0.9581778, 1701: 0.96322143, 684: 0.94648224, 553: 0.95089656, 62: 0.9502226, 1283: 0.959818, 313: 0.953497, 262: 0.9471232, 1200: 0.9642546, 69: 0.9625646, 1577: 0.9576922, 1253: 0.9578241, 854: 0.9593492, 734: 0.9673392, 66: 0.96953803, 1614: 0.9450837, 708: 0.9506238, 559: 0.9565401, 1213: 0.9507633, 966: 0.9616722, 795: 0.9481179, 116: 0.95395714, 303: 0.9547956, 1632: 0.9542264, 563: 0.9578032, 374: 0.9608389, 402: 0.95473474, 10: 0.94812113, 1209: 0.9635416, 793: 0.9624663, 474: 0.9683944, 896: 0.95159036, 1242: 0.9656074, 271: 0.966579, 589: 0.94691324, 1217: 0.9682824, 417: 0.96571535, 497: 0.9475045, 1639: 0.9504595, 656: 0.966978, 196: 0.9617429, 653: 0.9496893, 1222: 0.965693, 118: 0.95394677, 994: 0.9457783, 949: 0.9502106, 912: 0.9594758, 0: 0.96291167, 1452: 0.9541031, 1492: 0.951472, 130: 0.97057647, 713: 0.89351124, 1593: 0.94959205, 1063: 0.9675685, 1334: 0.9668296, 1199: 0.9631057, 1717: 0.96922463, 391: 0.96234506, 1620: 0.96232015, 1411: 0.95371777, 701: 0.9634167, 1478: 0.95158833, 704: 0.96664363, 125: 0.94996876, 1551: 0.969942, 1019: 0.9554072, 273: 0.96786445, 1529: 0.96557003, 1559: 0.948038, 447: 0.9682405, 236: 0.9646072, 956: 0.95084065, 81: 0.95100695, 761: 0.94607985, 600: 0.94636023, 1185: 0.9714967, 235: 0.9636382, 1656: 0.94403625, 1406: 0.9657159, 1647: 0.97098774, 468: 0.96206737, 28: 0.94941443, 1672: 0.9672966, 1589: 0.9652416, 1250: 0.96833926, 1707: 0.96342415, 350: 0.94787204, 976: 0.955858, 740: 0.947782, 1194: 0.961785, 1454: 0.9672564, 1693: 0.96498513, 1022: 0.96375495, 871: 0.96454096, 1537: 0.9592607, 1372: 0.966463, 401: 0.9700795, 255: 0.9686141, 977: 0.95623183, 175: 0.9510836, 705: 0.94616497, 964: 0.9532405, 797: 0.95225906, 380: 0.9518205, 1386: 0.9460105, 1007: 0.9479129, 1205: 0.9650254, 234: 0.96435004, 584: 0.96324205, 1680: 0.96765757, 1230: 0.9572447, 1041: 0.9661794, 426: 0.96424353, 1032: 0.95195407, 1065: 0.9652245, 277: 0.9441709, 1164: 0.957258, 736: 0.96703386, 173: 0.9673331, 1576: 0.9533986, 906: 0.96851236, 1256: 0.8968743, 963: 0.9637604, 587: 0.95487255, 26: 0.9639657, 774: 0.94722676, 150: 0.966225, 651: 0.9655924, 1405: 0.9497354, 1174: 0.9669222, 926: 0.9664733, 1114: 0.96329933, 1613: 0.9477411, 700: 0.9626099, 1687: 0.94995713, 366: 0.9471537, 1434: 0.95054275, 1689: 0.9647964, 959: 0.9638537, 683: 0.95795786, 114: 0.9652938, 1403: 0.96242756, 1477: 0.96895915, 6: 0.9698215, 1088: 0.9655708, 545: 0.9491653, 510: 0.9560539, 1473: 0.96935666, 641: 0.95244306, 1116: 0.97007096, 1141: 0.949813, 671: 0.9655318, 1100: 0.95116276, 1712: 0.9471418, 1709: 0.9503015, 1669: 0.9561484, 1362: 0.96654284, 839: 0.96708304, 957: 0.9507705, 918: 0.9470203, 1184: 0.9646429, 1545: 0.9708246, 1118: 0.95511925, 208: 0.97213167, 161: 0.94446343, 1435: 0.9682092, 606: 0.9486474, 378: 0.9535285, 998: 0.95802975, 1060: 0.9659463, 636: 0.96542156, 310: 0.9525303, 540: 0.95873356, 1552: 0.952658, 902: 0.96531904, 108: 0.9449524, 2: 0.9504529, 1486: 0.95305467, 1427: 0.9698529, 1645: 0.9446436, 514: 0.9519744, 535: 0.957243, 1049: 0.9685121, 1541: 0.9545881, 217: 0.94922316, 1274: 0.95147663, 1374: 0.9619296, 971: 0.9683436, 1535: 0.96459, 1499: 0.94824815, 1412: 0.9463219, 1586: 0.9640497, 743: 0.9647272, 1682: 0.9526953, 975: 0.965015, 1445: 0.966561, 586: 0.9660076, 1252: 0.9491712, 567: 0.9668773, 819: 0.9685485, 1210: 0.9476973, 763: 0.9646157, 489: 0.9638786, 254: 0.9637686, 1108: 0.8996135, 543: 0.9482058, 570: 0.9562686, 771: 0.9497052, 38: 0.96054924, 925: 0.9672357, 792: 0.9584611, 1600: 0.9511069, 399: 0.9523615, 22: 0.96185017, 1564: 0.96522266, 407: 0.9653234, 916: 0.96499157, 897: 0.9449231, 356: 0.9518073, 185: 0.96161884, 127: 0.9662191, 115: 0.94804454, 1512: 0.9662399, 1018: 0.97065747, 181: 0.9704851, 602: 0.96964633, 467: 0.9661706, 132: 0.94925624, 647: 0.95803463, 1424: 0.95382625, 1262: 0.9467834, 585: 0.9465268, 1690: 0.95986176, 755: 0.95638436, 938: 0.94923586, 1587: 0.9479626, 610: 0.94749737, 471: 0.9472922, 215: 0.96248055, 335: 0.95075023, 1013: 0.95416605, 1404: 0.9642679, 373: 0.9725395, 1223: 0.94842094, 1216: 0.9651037, 1438: 0.9635332, 60: 0.9684912, 689: 0.9493827, 109: 0.96713513, 1720: 0.9644842, 1702: 0.96611273, 306: 0.9522999, 1322: 0.9684798, 1158: 0.95925254, 1463: 0.956324, 433: 0.9485517, 375: 0.9516546, 465: 0.96415305, 620: 0.96579194, 23: 0.96005505, 754: 0.94863796, 1521: 0.96201617, 257: 0.9566912, 1286: 0.96829545, 264: 0.97120667, 1105: 0.96571755, 195: 0.9707366, 1318: 0.9471376, 833: 0.9642058, 597: 0.958992, 1294: 0.9552265, 481: 0.94920516, 204: 0.95494854, 737: 0.95546806, 1567: 0.9519293, 531: 0.95471555, 206: 0.9464027, 1281: 0.9641132, 1430: 0.94628763, 318: 0.9644578, 1267: 0.9546126, 1460: 0.95794886, 804: 0.9640314, 699: 0.9546168, 1361: 0.94443685, 490: 0.9486774, 53: 0.94780725, 887: 0.9480087, 568: 0.95242846, 1371: 0.94650906, 811: 0.95770806, 890: 0.9505014, 1532: 0.96883225, 164: 0.9471601, 782: 0.94844544, 769: 0.9569847, 1103: 0.9626235, 598: 0.9684956, 237: 0.94884694, 1547: 0.9510029, 592: 0.9617666, 1191: 0.95652133, 1447: 0.9667683, 654: 0.96750957, 596: 0.96640813, 1608: 0.9512495, 1695: 0.9485912, 1306: 0.9643012, 962: 0.96441746, 428: 0.96691126, 712: 0.96439946, 457: 0.94911957, 46: 0.9690279, 562: 0.9670269, 317: 0.9534685, 142: 0.9659439, 894: 0.95668125, 847: 0.9658807, 1125: 0.9642357, 1612: 0.95383847, 96: 0.96632195, 1127: 0.96469647, 1542: 0.9592113, 1227: 0.9661321, 90: 0.9554392, 1155: 0.9535514, 1516: 0.96875876, 321: 0.96268564, 1342: 0.9445906, 229: 0.9552009, 274: 0.9675854, 1285: 0.95623744, 709: 0.9560775, 1550: 0.94937366, 1211: 0.8939719, 1642: 0.94762063, 1301: 0.9437655, 593: 0.96652985, 1183: 0.96969473, 492: 0.95140594, 291: 0.9441466, 210: 0.9466013, 65: 0.968192, 547: 0.95586824, 544: 0.9513385, 186: 0.9695683, 1525: 0.96616924, 789: 0.9482225, 1480: 0.9540227, 124: 0.9486844, 1021: 0.95759106, 1472: 0.96509594, 1694: 0.9625371, 1005: 0.94643754, 91: 0.9632459, 1429: 0.948493, 738: 0.9510818, 1030: 0.9527793, 972: 0.95729965, 89: 0.951323, 826: 0.95006776, 171: 0.95195776, 1075: 0.96949637, 1282: 0.96367234, 853: 0.962958, 760: 0.9574012, 1514: 0.9609087, 932: 0.96576625, 162: 0.9561867, 880: 0.9497234, 777: 0.966037, 1325: 0.9678311, 1616: 0.9491424, 1627: 0.9474953, 207: 0.96533114, 1206: 0.9637885, 430: 0.95158327, 1566: 0.9551845, 669: 0.9686215, 762: 0.95167005, 1539: 0.9508773, 1459: 0.9669535, 151: 0.9562834, 1467: 0.9514109, 1017: 0.96348476, 1711: 0.96503264, 942: 0.9477808, 347: 0.9462601, 180: 0.94941795, 1703: 0.9686838, 1115: 0.9577289, 989: 0.96461785, 135: 0.95242196, 1387: 0.970492, 3: 0.94838643, 1592: 0.94772995, 1292: 0.96722054, 1270: 0.9649245, 1265: 0.9655703, 533: 0.9636394, 905: 0.94457734, 1649: 0.9514272, 372: 0.9479634, 1305: 0.9456878, 192: 0.96457547, 988: 0.9675513, 885: 0.9560491, 860: 0.9480665, 1302: 0.9580257, 1138: 0.96887994, 298: 0.96828854, 275: 0.9641278, 649: 0.95210546, 778: 0.9480517, 1528: 0.9681792, 1708: 0.9524725, 434: 0.9543769, 1111: 0.9495278, 1295: 0.96460384, 1574: 0.9656077, 820: 0.9644639, 947: 0.9646806, 1484: 0.962496, 165: 0.9668825, 101: 0.9651651, 1364: 0.9513453, 715: 0.96747935, 1629: 0.9463646, 794: 0.95300496, 285: 0.9649069, 571: 0.9681894, 64: 0.9579829, 1453: 0.95344615, 1581: 0.9651976, 911: 0.949994, 850: 0.9695067, 403: 0.96583295, 930: 0.96726805, 1055: 0.9639603, 1381: 0.95511883, 420: 0.95362186, 1259: 0.9660103, 556: 0.9624518, 459: 0.9501514, 1159: 0.96322066, 870: 0.9534533, 36: 0.9647643, 1046: 0.96414256, 1218: 0.95200086, 1540: 0.95423335, 1053: 0.9517344, 1456: 0.965003, 1636: 0.9514499, 355: 0.9651782, 1025: 0.9651809, 1119: 0.96682245, 904: 0.9640151, 1568: 0.9670136, 1335: 0.95122, 1704: 0.9644444, 1417: 0.9641542, 1040: 0.9524878, 1440: 0.96496904, 631: 0.96417445, 371: 0.9715128, 282: 0.9482531, 1144: 0.9664688, 834: 0.96443826, 697: 0.95046, 878: 0.9355423, 1122: 0.9676967, 452: 0.9524048, 466: 0.96369106, 408: 0.9498011, 242: 0.9661364, 1042: 0.94500864, 387: 0.9514291, 1329: 0.95017916, 247: 0.94699085, 157: 0.96749675, 1078: 0.9531595, 1316: 0.9508424, 442: 0.9535673, 624: 0.9612431, 1308: 0.96828264, 99: 0.9522037, 1683: 0.9653539, 1507: 0.96616846, 913: 0.96562284, 1498: 0.94960165, 652: 0.95088613, 595: 0.9554898, 296: 0.9583435, 27: 0.94831485, 299: 0.9479691, 1455: 0.9457037, 21: 0.96681154, 245: 0.92671955, 367: 0.9575982, 1610: 0.949603, 779: 0.9529913, 517: 0.95355237, 1297: 0.94590276, 174: 0.9637974, 1143: 0.96683294, 1398: 0.9596709, 1602: 0.9651715, 1715: 0.96908766, 406: 0.95123947, 1451: 0.96848285, 169: 0.9648108, 1599: 0.9674963, 440: 0.9456952, 910: 0.96648985, 405: 0.95406306, 1553: 0.95251423, 122: 0.96744734, 178: 0.94924295, 1506: 0.9687132, 346: 0.9665709, 246: 0.946765, 1572: 0.9482017, 1150: 0.952658, 427: 0.96926975, 153: 0.96206033, 1607: 0.94882894, 1337: 0.95751816, 1083: 0.9593379, 1076: 0.9654929, 908: 0.96472466, 44: 0.964216, 1527: 0.94419235, 77: 0.9505827, 1696: 0.9639615, 1001: 0.96834165, 147: 0.9590713, 1: 0.96229416, 1175: 0.9512301, 1107: 0.96497816, 82: 0.94799286, 389: 0.94763875, 1326: 0.96862596, 611: 0.9636244, 1691: 0.9483204, 955: 0.94666874, 1026: 0.9480138, 1353: 0.9652937, 1714: 0.951676, 845: 0.9683607, 1112: 0.9645797, 1358: 0.96483606, 482: 0.9490447, 1400: 0.95472604, 1137: 0.9504436, 822: 0.9689727, 1168: 0.96764475, 859: 0.9561403, 840: 0.9704823, 1718: 0.944565, 732: 0.9531544, 31: 0.95458496, 1045: 0.95230293, 409: 0.9668909, 973: 0.9550342, 1120: 0.96222574, 1686: 0.9606311, 1303: 0.96062523, 453: 0.9694958, 499: 0.96562487, 680: 0.9501935, 95: 0.95561767, 863: 0.96706486, 725: 0.951322, 308: 0.94997406, 844: 0.9580617, 107: 0.9562647, 1071: 0.9636126, 1132: 0.9640951, 519: 0.9598457, 550: 0.96825457, 666: 0.9654948, 1336: 0.94391495, 650: 0.96916616, 1289: 0.96522176, 1271: 0.9544048, 1047: 0.9659141, 1123: 0.94873506, 1716: 0.9642014, 444: 0.94955003, 731: 0.9604826, 212: 0.95163584, 594: 0.95497173, 872: 0.9473109, 145: 0.96573526, 477: 0.9532521, 268: 0.96768177, 59: 0.94685704, 1713: 0.9551185, 625: 0.9524962, 179: 0.9671942, 1491: 0.96599513, 739: 0.9629866, 609: 0.9706326, 218: 0.96872187, 723: 0.9660742, 431: 0.9673725, 472: 0.9500786, 1443: 0.9520002, 263: 0.95230865, 1029: 0.9641832, 980: 0.9542396, 222: 0.9484424, 1003: 0.9662448, 1523: 0.95262945, 1307: 0.9528288, 892: 0.95017415, 812: 0.9707675, 413: 0.953874, 572: 0.9642749, 1069: 0.9660787, 1419: 0.9638431, 915: 0.9547628, 163: 0.9638555, 1197: 0.9699553, 326: 0.94834644, 858: 0.95577395, 1239: 0.9658865, 131: 0.95738465, 358: 0.9702176, 48: 0.9640795, 1722: 0.97308844, 98: 0.9643447, 333: 0.9717576, 869: 0.9523259, 29: 0.9667217, 698: 0.96428263, 1367: 0.96577924, 526: 0.9484496, 1109: 0.953606, 1034: 0.9638062, 985: 0.94827354, 1130: 0.95055103, 1129: 0.94738615, 899: 0.9458479, 658: 0.9483789, 97: 0.9478865, 787: 0.94601744, 1618: 0.9584459, 485: 0.95347315, 1681: 0.9474596, 1350: 0.9457559, 441: 0.9476732, 1196: 0.96874475, 110: 0.9486342, 1556: 0.94975954, 532: 0.9636346, 991: 0.9645605, 634: 0.96586955, 1483: 0.9536906, 461: 0.95394003, 677: 0.9492148, 886: 0.96762645, 446: 0.964804, 646: 0.96348244, 1152: 0.953926, 1464: 0.96589404, 682: 0.96446323, 202: 0.94838053, 155: 0.9592764, 172: 0.9640889, 513: 0.9494823, 200: 0.9573676, 1121: 0.9537335, 1628: 0.9475683, 1375: 0.9506526, 744: 0.97009194, 1024: 0.9528845, 655: 0.9645729, 758: 0.95316666, 205: 0.9660117, 47: 0.96266, 382: 0.9489876, 1634: 0.9647028, 1351: 0.96365964, 718: 0.95302445, 1095: 0.9669799, 1508: 0.966994, 1091: 0.9638515, 601: 0.9667996, 1588: 0.96510893, 1432: 0.9671427, 868: 0.9537581, 566: 0.96374923, 1015: 0.944938, 1110: 0.9657258, 922: 0.9538862, 1468: 0.96835893, 1662: 0.96322334, 58: 0.96621275, 1090: 0.961477, 1249: 0.96658593, 719: 0.94899565, 1373: 0.96837413, 1157: 0.9551624, 1234: 0.94813734, 1237: 0.9681332, 936: 0.9158297, 548: 0.96332496, 1343: 0.9681425, 1061: 0.9663282, 1725: 0.9513314, 1277: 0.9517025, 78: 0.9514298, 302: 0.9632845, 1011: 0.95312536, 284: 0.9680551, 119: 0.9627501, 518: 0.9485181, 1149: 0.9491788, 823: 0.9530209, 1363: 0.94964236, 775: 0.931253, 133: 0.9466752, 287: 0.95091945, 424: 0.95790696, 1555: 0.9488331, 51: 0.9501912, 1388: 0.9689052, 1349: 0.94936305, 927: 0.9672417, 1006: 0.96292204, 139: 0.968088, 1442: 0.95114046, 230: 0.9504708, 104: 0.96403396, 508: 0.95545423, 1314: 0.961411, 1675: 0.9674649, 343: 0.96590406, 883: 0.9632752, 1139: 0.9578552, 1243: 0.94567925, 502: 0.9518644, 1101: 0.9487773, 1585: 0.9457812, 1058: 0.96192265, 1726: 0.9529894, 244: 0.96602905, 941: 0.96797657, 1671: 0.9511531, 278: 0.96164984, 711: 0.96630526, 1089: 0.95058775, 484: 0.9496291, 943: 0.95562834, 1096: 0.9621009, 856: 0.96363693, 1663: 0.95037496, 111: 0.9530548, 1039: 0.9599965, 710: 0.9560396, 1012: 0.96654606, 565: 0.9495292, 305: 0.94930667, 1392: 0.9675635, 177: 0.9471942, 1515: 0.95144856, 626: 0.9494041, 1457: 0.97018933, 232: 0.9517831, 817: 0.96285564, 1309: 0.9442115, 672: 0.9651437, 251: 0.9679672, 1530: 0.9519004, 241: 0.9459471, 63: 0.9650312, 199: 0.96895903, 622: 0.9618425, 209: 0.95650935, 1052: 0.96785766, 1082: 0.94920224, 1667: 0.9529465, 1266: 0.95768106, 216: 0.94838667, 965: 0.9607017, 39: 0.96415293, 1357: 0.96533316, 1461: 0.9528958, 1263: 0.96769685, 790: 0.9638432, 992: 0.9476303, 357: 0.95099723, 470: 0.9511118, 52: 0.9469295, 884: 0.9448183, 515: 0.9638656, 695: 0.9511275, 454: 0.9529792, 1561: 0.96575856, 855: 0.94840026}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "compute_tradeoffs(train_data=train_data_sample,\n",
    "                  budget_list=budget_list,\n",
    "                  name=name,\n",
    "                  service_names=service_names,\n",
    "                  skip=0, # you can manually skip the first few budgets if they have already been trained.\n",
    "                  MyCascade=MyCascade,\n",
    "                  cascade_depth=3,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2Uwzp8NIp3Or",
   "metadata": {
    "id": "2Uwzp8NIp3Or"
   },
   "source": [
    "## Step 3: Evaluate and save the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c947bcf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_raw</th>\n",
       "      <th>query</th>\n",
       "      <th>ref_answer</th>\n",
       "      <th>gpt-4o-mini</th>\n",
       "      <th>gpt-4o</th>\n",
       "      <th>llama-3-8B</th>\n",
       "      <th>llama-3-70B</th>\n",
       "      <th>mixtral-8x7B</th>\n",
       "      <th>gemini-1.5-flash-002</th>\n",
       "      <th>gemini-1.0-pro</th>\n",
       "      <th>gemini-1.5-pro-002</th>\n",
       "      <th>Phi-3.5-mini-instruct</th>\n",
       "      <th>Phi-3-small-8k-instruct</th>\n",
       "      <th>Phi-3-mini-4k-instruct</th>\n",
       "      <th>Phi-3-medium-4k-instruct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Context: we disapprove orange county v. sealy ...</td>\n",
       "      <td>Please determine whether a sentence is overrul...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Context: he also left the scene of the crime, ...</td>\n",
       "      <td>Please determine whether a sentence is overrul...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Context: contrary statements in our opinions a...</td>\n",
       "      <td>Please determine whether a sentence is overrul...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Context: \"\"[a] prima facie case of good faith ...</td>\n",
       "      <td>Please determine whether a sentence is overrul...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Context: as an intermediate appellate court, w...</td>\n",
       "      <td>Please determine whether a sentence is overrul...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           query_raw  \\\n",
       "0  Context: we disapprove orange county v. sealy ...   \n",
       "1  Context: he also left the scene of the crime, ...   \n",
       "2  Context: contrary statements in our opinions a...   \n",
       "3  Context: \"\"[a] prima facie case of good faith ...   \n",
       "4  Context: as an intermediate appellate court, w...   \n",
       "\n",
       "                                               query ref_answer gpt-4o-mini  \\\n",
       "0  Please determine whether a sentence is overrul...        yes         yes   \n",
       "1  Please determine whether a sentence is overrul...         no          no   \n",
       "2  Please determine whether a sentence is overrul...        yes         yes   \n",
       "3  Please determine whether a sentence is overrul...         no          no   \n",
       "4  Please determine whether a sentence is overrul...         no          no   \n",
       "\n",
       "  gpt-4o llama-3-8B llama-3-70B mixtral-8x7B gemini-1.5-flash-002  \\\n",
       "0    yes        yes         yes          yes                  yes   \n",
       "1     no         no          no           no                   no   \n",
       "2    yes        yes         yes          yes                  yes   \n",
       "3     no         no          no           no                   no   \n",
       "4     no         no          no           no                   no   \n",
       "\n",
       "  gemini-1.0-pro gemini-1.5-pro-002 Phi-3.5-mini-instruct  \\\n",
       "0            yes                yes                   yes   \n",
       "1             no                 no                    no   \n",
       "2            yes                yes                   yes   \n",
       "3             no                 no                    no   \n",
       "4             no                 no                    no   \n",
       "\n",
       "  Phi-3-small-8k-instruct Phi-3-mini-4k-instruct Phi-3-medium-4k-instruct  \n",
       "0                     yes                    yes                      yes  \n",
       "1                      no                     no                       no  \n",
       "2                     yes                     no                      yes  \n",
       "3                      no                     no                       no  \n",
       "4                      no                     no                       no  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read from data/{dataname}/Queried_{dataname}_all_models_clean_train.csv and data/{dataname}/Queried_{dataname}_all_models_clean_test.csv\n",
    "dataset_df_test = pd.read_csv(f'data/{dataname}/Queried_{dataname}_all_models_clean_test.csv', header=0)\n",
    "dataset_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b8ff8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "for index, row in dataset_df_test.iterrows():\n",
    "    query = row['query']\n",
    "    ref_answer = row['ref_answer']\n",
    "    _id = index\n",
    "    model_answer = {}\n",
    "    for model_name in supported_LLM_names:\n",
    "        model_answer[model_name] = row[model_name]\n",
    "    test_data.append([query, ref_answer, _id, model_answer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf98e672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Please determine whether a sentence is overruling a prior decision (Yes or No) in the following statements.\\n\\nContext: because jones/walker relates only to sufficiency of the evidence, we hereby disavow the language holding otherwise in sandoval.\\nQuestion: Is it overruling?\\nAnswer: Yes\\n\\nContext: according to napa auto parts, the straws drove the vehicle \"\"\"\"for approximately six [] weeks and [] for between 500 to 600 miles prior to the accident with no incidents.\"\"\"\"\\nQuestion: Is it overruling?\\nAnswer: No\\n\\nContext: \"\"[a] prima facie case of good faith purpose is achieved by the mere allegation . . . that the information sought is for a proper purpose.\"\"\\nQuestion: Is it overruling?\\nAnswer:',\n",
       " 'no',\n",
       " 3,\n",
       " {'gemini-1.5-flash-002': 'no',\n",
       "  'gemini-1.5-pro-002': 'no',\n",
       "  'gemini-1.0-pro': 'no',\n",
       "  'gpt-4o-mini': 'no',\n",
       "  'gpt-4o': 'no',\n",
       "  'Phi-3-mini-4k-instruct': 'no',\n",
       "  'Phi-3.5-mini-instruct': 'no',\n",
       "  'Phi-3-small-8k-instruct': 'no',\n",
       "  'Phi-3-medium-4k-instruct': 'no',\n",
       "  'llama-3-8B': 'no',\n",
       "  'llama-3-70B': 'no',\n",
       "  'mixtral-8x7B': 'no'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ea9a393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the answer of the model llama-3-8B\n",
    "test_data[3][3]['llama-3-8B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49b26403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432\n"
     ]
    }
   ],
   "source": [
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e7c920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataframe_from_cascade(MyCascade,budget_list, train_data, test_data, genparams,name):\n",
    "    # Initialize an empty list to store the rows for the DataFrame\n",
    "    data = []\n",
    "\n",
    "    # Iterate through the budget list\n",
    "    for budget in tqdm(budget_list):\n",
    "        # Load the strategy for the given budget\n",
    "        MyCascade.load(loadpath=f\"strategy/{name}/\", budget=budget)\n",
    "        print(\"loaded from path:\",f\"strategy/{name}/\")\n",
    "        print(\"now the budget is:\",budget)\n",
    "\n",
    "        # # Get the completion batch for train data\n",
    "        # print(\"start train data\")\n",
    "        # train_result = MyCascade.get_completion_batch(queries=train_data, genparams=genparams)\n",
    "        # print(\"train_result:\",train_result)\n",
    "        # # Compute the ACC and cost for train data\n",
    "        # train_acc_cost = FrugalGPT.compute_score(train_result)\n",
    "\n",
    "        # Get the completion batch for test data\n",
    "        test_result = MyCascade.get_completion_batch(queries=test_data, genparams=genparams)\n",
    "        print(\"cost\", test_result['cost'])\n",
    "\n",
    "        # Compute the ACC and cost for test data\n",
    "        # test_acc_cost = FrugalGPT.compute_score(test_result)\n",
    "\n",
    "        # Create a row with the schema\n",
    "        row = {\n",
    "            # \"Test_acc\": test_acc_cost['em'],\n",
    "            # \"Test_cost\": test_acc_cost['cost'],\n",
    "            \"Test_cost\": test_result['cost'],\n",
    "            \"Test_size\": len(test_data),\n",
    "            # \"Train_acc\": train_acc_cost['em'],\n",
    "            # \"Train_cost\": train_acc_cost['cost'],\n",
    "            \"Train_size\": len(train_data),\n",
    "            \"Budget\": budget,\n",
    "            \"Method\": \"FrugalGPT\",\n",
    "            \"Provider\": \"FrugalGPT\",\n",
    "            \"Marker\": 1,  # Marker is always 1 for this function\n",
    "        }\n",
    "\n",
    "        # Append the row to the data list\n",
    "        data.append(row)\n",
    "        display(row)\n",
    "\n",
    "    # Create the DataFrame from the data list\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rcyxrlVFp2UW",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1726726973432,
     "user": {
      "displayName": "Lingjiao Chen",
      "userId": "02137656603654057828"
     },
     "user_tz": 420
    },
    "id": "rcyxrlVFp2UW"
   },
   "outputs": [],
   "source": [
    "# def generate_dataframe_from_cascade(MyCascade,budget_list, train_data, test_data, genparams,name):\n",
    "#     # Initialize an empty list to store the rows for the DataFrame\n",
    "#     data = []\n",
    "\n",
    "#     # Iterate through the budget list\n",
    "#     for budget in tqdm(budget_list):\n",
    "#         # Load the strategy for the given budget\n",
    "#         MyCascade.load(loadpath=f\"strategy/{name}/\", budget=budget)\n",
    "#         print(\"loaded from path:\",f\"strategy/{name}/\")\n",
    "#         print(\"now the budget is:\",budget)\n",
    "\n",
    "#         # Get the completion batch for train data\n",
    "#         print(\"start train data\")\n",
    "#         train_result = MyCascade.get_completion_batch(queries=train_data, genparams=genparams)\n",
    "#         print(\"train_result:\",train_result)\n",
    "#         # Compute the ACC and cost for train data\n",
    "#         train_acc_cost = FrugalGPT.compute_score(train_result)\n",
    "\n",
    "#         # Get the completion batch for test data\n",
    "#         test_result = MyCascade.get_completion_batch(queries=test_data, genparams=genparams)\n",
    "\n",
    "#         # Compute the ACC and cost for test data\n",
    "#         test_acc_cost = FrugalGPT.compute_score(test_result)\n",
    "\n",
    "#         # Create a row with the schema\n",
    "#         row = {\n",
    "#             \"Test_acc\": test_acc_cost['em'],\n",
    "#             \"Test_cost\": test_acc_cost['cost'],\n",
    "#             \"Test_size\": len(test_data),\n",
    "#             \"Train_acc\": train_acc_cost['em'],\n",
    "#             \"Train_cost\": train_acc_cost['cost'],\n",
    "#             \"Train_size\": len(train_data),\n",
    "#             \"Budget\": budget,\n",
    "#             \"Method\": \"FrugalGPT\",\n",
    "#             \"Provider\": \"FrugalGPT\",\n",
    "#             \"Marker\": 1,  # Marker is always 1 for this function\n",
    "#         }\n",
    "\n",
    "#         # Append the row to the data list\n",
    "#         data.append(row)\n",
    "#         display(row)\n",
    "\n",
    "#     # Create the DataFrame from the data list\n",
    "#     df = pd.DataFrame(data)\n",
    "\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f81f6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = test_data\n",
    "llm_vanilla = FrugalGPT.llmvanilla.LLMVanilla()  # åˆ›å»º LLMVanilla ç±»çš„å®žä¾‹\n",
    "\n",
    "for i in range(len(data)):\n",
    "    for name in service_names:\n",
    "        service_name = name\n",
    "        query = data[i][0]\n",
    "        cost = llm_vanilla.compute_cost(input_text=query, output_text=\"no\", service_name=service_name)\n",
    "        print(\"data index is: \", data[i][2], \"and cost for\", service_name, \" is: \", cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "OOaA0c3SqHh9",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "OOaA0c3SqHh9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                            | 0/5 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 23.68 GiB of which 7.25 MiB is free. Including non-PyTorch memory, this process has 13.52 GiB memory in use. Process 1706292 has 10.14 GiB memory in use. Of the allocated memory 11.78 GiB is allocated by PyTorch, and 520.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m MyCascade_eval \u001b[38;5;241m=\u001b[39m FrugalGPT\u001b[38;5;241m.\u001b[39mLLMCascade()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# MyCascade_eval.prefix = prefix\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m frugalgpt_df \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_dataframe_from_cascade\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMyCascade_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mbudget_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m display(frugalgpt_df)\n\u001b[1;32m      8\u001b[0m frugalgpt_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary/summary_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_e8_frugalgpt_2024.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[19], line 8\u001b[0m, in \u001b[0;36mgenerate_dataframe_from_cascade\u001b[0;34m(MyCascade, budget_list, train_data, test_data, genparams, name)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Iterate through the budget list\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m budget \u001b[38;5;129;01min\u001b[39;00m tqdm(budget_list):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Load the strategy for the given budget\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mMyCascade\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloadpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrategy/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbudget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbudget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloaded from path:\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrategy/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnow the budget is:\u001b[39m\u001b[38;5;124m\"\u001b[39m,budget)\n",
      "File \u001b[0;32m~/My_FrugalGPT/src/FrugalGPT/llmcascade.py:51\u001b[0m, in \u001b[0;36mLLMCascade.load\u001b[0;34m(self, loadpath, budget)\u001b[0m\n\u001b[1;32m     49\u001b[0m     path1 \u001b[38;5;241m=\u001b[39m loadpath\u001b[38;5;241m+\u001b[39mname\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMyScores[name]\u001b[38;5;241m=\u001b[39mScore()\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMyScores\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscorer[name]  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMyScores[name]\u001b[38;5;241m.\u001b[39mget_model()\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m#print(\"scoer keys:\",self.scorer.keys())\u001b[39;00m\n",
      "File \u001b[0;32m~/My_FrugalGPT/src/FrugalGPT/scoring.py:230\u001b[0m, in \u001b[0;36mScore.load\u001b[0;34m(self, loadpath)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m,loadpath):\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m AutoModelForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(loadpath)\n\u001b[0;32m--> 230\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;66;03m#print(f\"device is {device}\")\u001b[39;00m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/transformers/modeling_utils.py:2958\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   2954\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2955\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2956\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2957\u001b[0m         )\n\u001b[0;32m-> 2958\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/modules/module.py:1174\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1172\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 780 (3 times)]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/modules/module.py:805\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 805\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/FrugalGPT/lib/python3.9/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1155\u001b[0m             device,\n\u001b[1;32m   1156\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m             non_blocking,\n\u001b[1;32m   1158\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1159\u001b[0m         )\n\u001b[0;32m-> 1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 23.68 GiB of which 7.25 MiB is free. Including non-PyTorch memory, this process has 13.52 GiB memory in use. Process 1706292 has 10.14 GiB memory in use. Of the allocated memory 11.78 GiB is allocated by PyTorch, and 520.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "MyCascade_eval = FrugalGPT.LLMCascade()\n",
    "# MyCascade_eval.prefix = prefix\n",
    "\n",
    "frugalgpt_df = generate_dataframe_from_cascade(MyCascade_eval,\n",
    "                                               budget_list, train_data, test_data, genparams,\n",
    "                                               name)\n",
    "display(frugalgpt_df)\n",
    "frugalgpt_df.to_csv(f\"summary/summary_{dataname}_e8_frugalgpt_2024.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mHUlxeaMrEkb",
   "metadata": {
    "id": "mHUlxeaMrEkb"
   },
   "source": [
    "Now let us save the results to local disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0gFONtq4aP",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "cb0gFONtq4aP"
   },
   "outputs": [],
   "source": [
    "display(frugalgpt_df)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "FrugalGPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01ba1534f0e24321affb134f795d4e68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "04153380e45f4bd39190e7f06a146954": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f54f210a63944dad95209d80eec931b8",
      "max": 4203,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3348916d837a4fe08a1141b9bc162e5b",
      "value": 4203
     }
    },
    "053caf30542a469a813960d9667201e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "096fd374c7524a5dbeee3e5d605c9665": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac1024e6ae3b46baada7f41991f97b26",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_37d46e069c944db19c6829acd353e7ef",
      "value": "config.json:â€‡100%"
     }
    },
    "0fd62e10a8304775b668ac30c834c744": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "10177f63d6c641f781a170ba164a92d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4df83d0181864010b119a90f1f3c1510",
      "max": 1355256,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_25b51e775790486995ec876caa1a8425",
      "value": 1355256
     }
    },
    "1121ce227c28404cb70b3d564d9fff34": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8f138918ef4147a6bbb2e883b5483404",
       "IPY_MODEL_d520483efb9743d9beb7904e0d5bd1f2",
       "IPY_MODEL_6163cdc600324da3b34143eff0a89062"
      ],
      "layout": "IPY_MODEL_ef30e9003568429da168e0377cf01a28"
     }
    },
    "126f421fe406465bb7c38a8cc4b6ddc5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c8a454e66b72445baeb4f743d46a1b1d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_9b29179ac60441618bedc3c54a1e3757",
      "value": "vocab.json:â€‡100%"
     }
    },
    "16384f4c115144b9a4c2ac3deaad020c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e2f03b213de4e19bc6e6731dc3f0ea6",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_233204505e5546408412acf06184eb74",
      "value": "merges.txt:â€‡100%"
     }
    },
    "16603ac956cf4785b85b066eb15c57a9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "198e61ba739348ae8efd1bebf69c5e5d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e410a2a741a44d6a8cd47b5dd3eb7ef7",
       "IPY_MODEL_86bc538415dc4728a615d140e8c5a7bb",
       "IPY_MODEL_aea323c0bc784f28b326e670c79a6089"
      ],
      "layout": "IPY_MODEL_d929d9d2d95f43afbd7519f2b70d258d"
     }
    },
    "202e0ca0c19240249a777b60592b1b93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "233204505e5546408412acf06184eb74": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "25b51e775790486995ec876caa1a8425": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "26165922ebf342fa9d1e72256fbc358d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "28233fdd8c0e43319bb0281c0cfc5181": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_39f4605651d14ed2b8c9f22d6e450639",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_f7a63610cb7e44d59aa54376946563f8",
      "value": "â€‡1.36M/1.36Mâ€‡[00:00&lt;00:00,â€‡5.38MB/s]"
     }
    },
    "29d56ff30c3649b0874a9ade76068080": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f32d751d66b94a8b8237be489ca730e0",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_3f8a0a44039d4b15916b789348b5a8d3",
      "value": "config.json:â€‡100%"
     }
    },
    "2e12ccbc230542488e81f8f7e6ac92a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2e2f03b213de4e19bc6e6731dc3f0ea6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3348916d837a4fe08a1141b9bc162e5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "361343d0e0914f5da3ae0c7382e67275": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "37d46e069c944db19c6829acd353e7ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "39726ecb41bb460fa8499f759f929d4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d6c92a69395e444393101f757bb18170",
       "IPY_MODEL_6fbce3f46d634714894ac48a34bd9673",
       "IPY_MODEL_d7b05915f7e84aba9c08f49a7945286d"
      ],
      "layout": "IPY_MODEL_42c2fddd7e474017b466caf2fa7d1739"
     }
    },
    "39f4605651d14ed2b8c9f22d6e450639": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c5649d7ccf8463daa1382cc1f800445": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3cba2b5c366540bb87c683c8b05f235e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3f8a0a44039d4b15916b789348b5a8d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "413363687f884591ab1f715d521b45a5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42c2fddd7e474017b466caf2fa7d1739": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47734a06243647daa17b5acacc894ccf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4df83d0181864010b119a90f1f3c1510": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "526502e08e2c412583523c9368c5adc9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "573b43335f1c452e989a92aa9864e7e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c48837d66fd4bffbd02c4346f9d64ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_884d725c16cf4fa4a9d2f3628c9b500d",
       "IPY_MODEL_04153380e45f4bd39190e7f06a146954",
       "IPY_MODEL_9e8cf0196c2c401b9039d828976cb99b"
      ],
      "layout": "IPY_MODEL_cad1d644948542b6a5b5f96cb2b9fdf8"
     }
    },
    "5c53ff8d30764fdcafb2573ccf698c13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6163cdc600324da3b34143eff0a89062": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_70c3558609ba45dba40cdb574c1ca383",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_47734a06243647daa17b5acacc894ccf",
      "value": "â€‡232k/232kâ€‡[00:00&lt;00:00,â€‡11.6MB/s]"
     }
    },
    "62324463a32d4d84b7a61ac28a2c4f63": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "63f02062ba3947ada798b8e53050cf20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_99ba0eea9790428b8010a5c6b04385be",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_85334857c24f4b00908ed430aefe3452",
      "value": "tokenizer_config.json:â€‡100%"
     }
    },
    "6677d1c18c884c44b4ba46c06c7d6cf4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_573b43335f1c452e989a92aa9864e7e1",
      "max": 1042301,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2e12ccbc230542488e81f8f7e6ac92a2",
      "value": 1042301
     }
    },
    "66b76867d66c43dabf018fc9d89e4e16": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_413363687f884591ab1f715d521b45a5",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_685b872d62b4440eafccc5fc1d1849b0",
      "value": "â€‡483/483â€‡[00:00&lt;00:00,â€‡46.7kB/s]"
     }
    },
    "685b872d62b4440eafccc5fc1d1849b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "69bda232590b4ace9661dd59c34385bb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ab1cfd5abe64ff2b32ea571966a7e62": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6fbce3f46d634714894ac48a34bd9673": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f5a0784952614ed095417339dd8a32ed",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_927bfd31257f4e1f823d7de0b9c04323",
      "value": 466062
     }
    },
    "70c3558609ba45dba40cdb574c1ca383": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "783932b329e24448840d1ddef11f3666": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8355d693b40d4184943ad8dd67298410": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_126f421fe406465bb7c38a8cc4b6ddc5",
       "IPY_MODEL_6677d1c18c884c44b4ba46c06c7d6cf4",
       "IPY_MODEL_f73ddef287e34cc08fe6cebcc1423253"
      ],
      "layout": "IPY_MODEL_62324463a32d4d84b7a61ac28a2c4f63"
     }
    },
    "85334857c24f4b00908ed430aefe3452": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "86bc538415dc4728a615d140e8c5a7bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_783932b329e24448840d1ddef11f3666",
      "max": 26,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_202e0ca0c19240249a777b60592b1b93",
      "value": 26
     }
    },
    "884d725c16cf4fa4a9d2f3628c9b500d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9835c5eb962b4af383a8e1f6d31ee7b6",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_960f38c7b6ca48e4aa893db669175640",
      "value": "Downloadingâ€‡builderâ€‡script:â€‡100%"
     }
    },
    "8927995718ea40cda9688f3ecf8954d8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f138918ef4147a6bbb2e883b5483404": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b502b1f40634456a9c1cbf94397fa8a6",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_cd5ec73e95f04410864a57dc034f9028",
      "value": "vocab.txt:â€‡100%"
     }
    },
    "8fedd80796b44f77a79dc64669c92a84": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "926dc2ca6f59429a9f897523e27cfccd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "927bfd31257f4e1f823d7de0b9c04323": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "933bb312e7f14bd4b698e899d2b3fe31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "960f38c7b6ca48e4aa893db669175640": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9835c5eb962b4af383a8e1f6d31ee7b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "98415b41a9244ca3886ef5bf9f06a3b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0fd62e10a8304775b668ac30c834c744",
      "max": 665,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_361343d0e0914f5da3ae0c7382e67275",
      "value": 665
     }
    },
    "98809b27fceb4a5cb320cb0fc481e0eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_63f02062ba3947ada798b8e53050cf20",
       "IPY_MODEL_9e9e0492628b43e9ae23d1ae18095012",
       "IPY_MODEL_cf49790d471e4a94a307d957aad9d959"
      ],
      "layout": "IPY_MODEL_a2d1adb0e70b4f31a023c1153acb05b9"
     }
    },
    "99ba0eea9790428b8010a5c6b04385be": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b29179ac60441618bedc3c54a1e3757": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9e8cf0196c2c401b9039d828976cb99b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bd6078f6bc8649e6a9e28ad13599c0c1",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_cb32f5d8454f428cad3c2c9c222e86f2",
      "value": "â€‡4.20k/4.20kâ€‡[00:00&lt;00:00,â€‡323kB/s]"
     }
    },
    "9e9e0492628b43e9ae23d1ae18095012": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b697d1f76c1f412e82f7d9124b837aeb",
      "max": 48,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ec432c87e0e24cf09f150e7d7b6bbe4e",
      "value": 48
     }
    },
    "a2d1adb0e70b4f31a023c1153acb05b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a329dc0ee292420eb305e9a5dbbc86c3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a5f0897e25e6479597371bc3ca2a5e6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ade558317099454a83def82ef00c8096",
      "max": 483,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_933bb312e7f14bd4b698e899d2b3fe31",
      "value": 483
     }
    },
    "ac1024e6ae3b46baada7f41991f97b26": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ade558317099454a83def82ef00c8096": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aea323c0bc784f28b326e670c79a6089": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_16603ac956cf4785b85b066eb15c57a9",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_926dc2ca6f59429a9f897523e27cfccd",
      "value": "â€‡26.0/26.0â€‡[00:00&lt;00:00,â€‡2.08kB/s]"
     }
    },
    "b31a7967f64d4e39851b178bb106299f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b502b1f40634456a9c1cbf94397fa8a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b697d1f76c1f412e82f7d9124b837aeb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc3841b572f94fbbb3e94a346fe3a751": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bd6078f6bc8649e6a9e28ad13599c0c1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c18d8c04c0724aa9adb7953f8dd227b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6ab1cfd5abe64ff2b32ea571966a7e62",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dbd23319ef6f4658bc9fafc21b68ea39",
      "value": 456318
     }
    },
    "c7d9896006bb4a0186f6a2760b0dd89d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e0be5a37122b455b82105d6ebee0116f",
       "IPY_MODEL_10177f63d6c641f781a170ba164a92d2",
       "IPY_MODEL_28233fdd8c0e43319bb0281c0cfc5181"
      ],
      "layout": "IPY_MODEL_a329dc0ee292420eb305e9a5dbbc86c3"
     }
    },
    "c8a454e66b72445baeb4f743d46a1b1d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca106182c2d94469a6828ecbbac57579": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c5649d7ccf8463daa1382cc1f800445",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_5c53ff8d30764fdcafb2573ccf698c13",
      "value": "â€‡665/665â€‡[00:00&lt;00:00,â€‡57.4kB/s]"
     }
    },
    "cad1d644948542b6a5b5f96cb2b9fdf8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "caf31996b679472b85291decba4e7331": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_526502e08e2c412583523c9368c5adc9",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_3cba2b5c366540bb87c683c8b05f235e",
      "value": "â€‡456k/456kâ€‡[00:00&lt;00:00,â€‡34.4MB/s]"
     }
    },
    "cb32f5d8454f428cad3c2c9c222e86f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cd5ec73e95f04410864a57dc034f9028": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cf49790d471e4a94a307d957aad9d959": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea91c4ac64e44e6e9e395f35c6ffebe5",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_26165922ebf342fa9d1e72256fbc358d",
      "value": "â€‡48.0/48.0â€‡[00:00&lt;00:00,â€‡4.45kB/s]"
     }
    },
    "cfccf7d931ac4fdc983bd7f761aba1e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d48ddfd24e324292b89485392a0deb17": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d4f3f3e7c397454e8663400b8cb5aff2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_16384f4c115144b9a4c2ac3deaad020c",
       "IPY_MODEL_c18d8c04c0724aa9adb7953f8dd227b1",
       "IPY_MODEL_caf31996b679472b85291decba4e7331"
      ],
      "layout": "IPY_MODEL_bc3841b572f94fbbb3e94a346fe3a751"
     }
    },
    "d520483efb9743d9beb7904e0d5bd1f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d88119d9073745dd86e0bbcdab414938",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_053caf30542a469a813960d9667201e7",
      "value": 231508
     }
    },
    "d6a4079bc7354089a57a88b761f50b48": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6c92a69395e444393101f757bb18170": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8927995718ea40cda9688f3ecf8954d8",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_01ba1534f0e24321affb134f795d4e68",
      "value": "tokenizer.json:â€‡100%"
     }
    },
    "d7b05915f7e84aba9c08f49a7945286d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eef407d665ae4c51813522c4c3c7890f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b31a7967f64d4e39851b178bb106299f",
      "value": "â€‡466k/466kâ€‡[00:00&lt;00:00,â€‡7.07MB/s]"
     }
    },
    "d88119d9073745dd86e0bbcdab414938": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d929d9d2d95f43afbd7519f2b70d258d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d92fd356422d41589dea2536ab671a4e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dbd23319ef6f4658bc9fafc21b68ea39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e0be5a37122b455b82105d6ebee0116f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69bda232590b4ace9661dd59c34385bb",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_d48ddfd24e324292b89485392a0deb17",
      "value": "tokenizer.json:â€‡100%"
     }
    },
    "e17d7f39a2984652b51deca4607626f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e410a2a741a44d6a8cd47b5dd3eb7ef7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d6a4079bc7354089a57a88b761f50b48",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_e17d7f39a2984652b51deca4607626f0",
      "value": "tokenizer_config.json:â€‡100%"
     }
    },
    "ea91c4ac64e44e6e9e395f35c6ffebe5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec432c87e0e24cf09f150e7d7b6bbe4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "eef407d665ae4c51813522c4c3c7890f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef30e9003568429da168e0377cf01a28": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f32d751d66b94a8b8237be489ca730e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3f817773990429cbf21d34dc0e99ea1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_29d56ff30c3649b0874a9ade76068080",
       "IPY_MODEL_a5f0897e25e6479597371bc3ca2a5e6d",
       "IPY_MODEL_66b76867d66c43dabf018fc9d89e4e16"
      ],
      "layout": "IPY_MODEL_8fedd80796b44f77a79dc64669c92a84"
     }
    },
    "f54f210a63944dad95209d80eec931b8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5a0784952614ed095417339dd8a32ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5ebf777e53145d1966f4fdc689b9d38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f73ddef287e34cc08fe6cebcc1423253": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cfccf7d931ac4fdc983bd7f761aba1e6",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_f5ebf777e53145d1966f4fdc689b9d38",
      "value": "â€‡1.04M/1.04Mâ€‡[00:00&lt;00:00,â€‡34.2MB/s]"
     }
    },
    "f7a63610cb7e44d59aa54376946563f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fe1d76c631f8440ea16bfcab640fe86a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_096fd374c7524a5dbeee3e5d605c9665",
       "IPY_MODEL_98415b41a9244ca3886ef5bf9f06a3b6",
       "IPY_MODEL_ca106182c2d94469a6828ecbbac57579"
      ],
      "layout": "IPY_MODEL_d92fd356422d41589dea2536ab671a4e"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
