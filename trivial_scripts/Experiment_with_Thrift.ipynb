{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys, json, copy\n",
    "import logging\n",
    "logging.disable(logging.CRITICAL)\n",
    "sys.path.append(\"src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sharkiefff/anaconda3/envs/dis-llm/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/Users/sharkiefff/anaconda3/envs/dis-llm/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supported LLMs: ['textsynth/gptneox_20B', 'textsynth/fairseq_gpt_13B', 'textsynth/gptj_6B', 'openai/text-davinci-002', 'openai/text-davinci-003', 'openai/text-curie-001', 'openai/text-babbage-001', 'openai/text-ada-001', 'openaichat/gpt-4o-mini', 'openaichat/gpt-4-turbo', 'openaichat/gpt-4o', 'openaichat/gpt-3.5-turbo', 'openaichat/gpt-4', 'ai21/j1-jumbo', 'ai21/j1-grande', 'ai21/j1-large', 'ai21/j2-ultra', 'ai21/j2-mid', 'ai21/j2-light', 'cohere/command', 'cohere/base', 'cohere/xlarge', 'cohere/medium', 'anthropic/claude-1', 'anthropic/claude-instant-1', 'anthropic/claude-1-100k']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = os.environ.get('OPENAI_API_KEY')\n",
    "os.environ['AI21_STUDIO_API_KEY'] = 'AI21_STUDIO_API_KEY'\n",
    "os.environ['COHERE_STUDIO_API_KEY'] = 'COHERE_STUDIO_API_KEY'\n",
    "os.environ['TEXTSYNTH_API_SECRET_KEY'] = 'TEXTSYNTH_API_SECRET_KEY'\n",
    "os.environ['ANTHROPIC_API_KEY'] = 'ANTHROPIC_API_KEY'\n",
    "os.environ['TOGETHER_API_KEY'] = 'TOGETHER_API_KEY'\n",
    "\n",
    "from IPython.display import display\n",
    "import FrugalGPT\n",
    "supported_LLM = FrugalGPT.getservicename()\n",
    "print(\"supported LLMs:\",supported_LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the key\n",
    "print(os.environ['ANTHROPIC_API_KEY'])\n",
    "print(os.environ['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a test of openai api\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            # \"content\": \"Write a haiku about recursion in programming.\"\n",
    "            \"content\": \"What is the purpose of life?\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice: remember to modify the name in config/serviceinfo_thrift.json to adjust the llm model you want to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataname = \"HEADLINES\"\n",
    "\n",
    "test_data = FrugalGPT.loadcsvdata(f\"data/{dataname}/test.csv\")\n",
    "prefix = open(f'config/prompt/{dataname}/prefix_e8.txt').read()\n",
    "test_data = FrugalGPT.formatdata(test_data,prefix)\n",
    "\n",
    "train_data = FrugalGPT.loadcsvdata(f\"data/{dataname}/train.csv\")\n",
    "prefix = open(f'config/prompt/{dataname}/prefix_e8.txt').read()\n",
    "train_data = FrugalGPT.formatdata(train_data,prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train a LLMCascade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the budget per query, and then train the model. Warning: This can take a while on large datasets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train and test size 4950 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sharkiefff/anaconda3/envs/dis-llm/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/Users/sharkiefff/anaconda3/envs/dis-llm/lib/python3.11/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad4400a63f04d9a8ef3e39b7e3671e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2232 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.733, 'grad_norm': 2.9268574714660645, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.03}\n",
      "{'loss': 0.7205, 'grad_norm': 3.7032692432403564, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.05}\n",
      "{'loss': 0.6916, 'grad_norm': 3.727867364883423, 'learning_rate': 3e-06, 'epoch': 0.08}\n",
      "{'loss': 0.6589, 'grad_norm': 3.131098985671997, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.11}\n",
      "{'loss': 0.6536, 'grad_norm': 2.136280059814453, 'learning_rate': 5e-06, 'epoch': 0.13}\n",
      "{'loss': 0.5324, 'grad_norm': 3.764906883239746, 'learning_rate': 6e-06, 'epoch': 0.16}\n",
      "{'loss': 0.5294, 'grad_norm': 2.3770830631256104, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.19}\n",
      "{'loss': 0.5636, 'grad_norm': 2.98032283782959, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.22}\n",
      "{'loss': 0.4954, 'grad_norm': 2.9582624435424805, 'learning_rate': 9e-06, 'epoch': 0.24}\n",
      "{'loss': 0.553, 'grad_norm': 8.271008491516113, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 0.4161, 'grad_norm': 2.466097354888916, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.3}\n",
      "{'loss': 0.5366, 'grad_norm': 5.948933124542236, 'learning_rate': 1.2e-05, 'epoch': 0.32}\n",
      "{'loss': 0.5263, 'grad_norm': 6.112679481506348, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.35}\n",
      "{'loss': 0.481, 'grad_norm': 3.6458241939544678, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.38}\n",
      "{'loss': 0.5301, 'grad_norm': 4.063752174377441, 'learning_rate': 1.5e-05, 'epoch': 0.4}\n",
      "{'loss': 0.429, 'grad_norm': 3.6084845066070557, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.43}\n",
      "{'loss': 0.5557, 'grad_norm': 5.411291599273682, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.46}\n",
      "{'loss': 0.4149, 'grad_norm': 4.39232873916626, 'learning_rate': 1.8e-05, 'epoch': 0.48}\n",
      "{'loss': 0.4325, 'grad_norm': 8.497316360473633, 'learning_rate': 1.9e-05, 'epoch': 0.51}\n",
      "{'loss': 0.435, 'grad_norm': 6.561130046844482, 'learning_rate': 2e-05, 'epoch': 0.54}\n",
      "{'loss': 0.469, 'grad_norm': 8.210631370544434, 'learning_rate': 2.1e-05, 'epoch': 0.56}\n",
      "{'loss': 0.4422, 'grad_norm': 4.436388969421387, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.59}\n",
      "{'loss': 0.3232, 'grad_norm': 1.315785527229309, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.62}\n",
      "{'loss': 0.4707, 'grad_norm': 4.767340183258057, 'learning_rate': 2.4e-05, 'epoch': 0.65}\n",
      "{'loss': 0.3706, 'grad_norm': 2.8342788219451904, 'learning_rate': 2.5e-05, 'epoch': 0.67}\n",
      "{'loss': 0.3578, 'grad_norm': 3.7030575275421143, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.7}\n",
      "{'loss': 0.4436, 'grad_norm': 1.5702531337738037, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.73}\n",
      "{'loss': 0.4052, 'grad_norm': 6.943115234375, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.75}\n",
      "{'loss': 0.4167, 'grad_norm': 3.4227356910705566, 'learning_rate': 2.9e-05, 'epoch': 0.78}\n",
      "{'loss': 0.3644, 'grad_norm': 15.18825626373291, 'learning_rate': 3e-05, 'epoch': 0.81}\n",
      "{'loss': 0.4432, 'grad_norm': 5.53553581237793, 'learning_rate': 3.1e-05, 'epoch': 0.83}\n",
      "{'loss': 0.4697, 'grad_norm': 2.6194634437561035, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.86}\n",
      "{'loss': 0.5784, 'grad_norm': 6.5779643058776855, 'learning_rate': 3.3e-05, 'epoch': 0.89}\n",
      "{'loss': 0.3522, 'grad_norm': 5.286133289337158, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.91}\n",
      "{'loss': 0.4079, 'grad_norm': 5.442041397094727, 'learning_rate': 3.5e-05, 'epoch': 0.94}\n",
      "{'loss': 0.3054, 'grad_norm': 4.797124862670898, 'learning_rate': 3.6e-05, 'epoch': 0.97}\n",
      "{'loss': 0.3699, 'grad_norm': 6.3687214851379395, 'learning_rate': 3.7e-05, 'epoch': 0.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcabbcdd91314620a4dbbcd91f2b1144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.31897372007369995, 'eval_accuracy': 0.8818181818181818, 'eval_runtime': 3.7871, 'eval_samples_per_second': 522.831, 'eval_steps_per_second': 8.186, 'epoch': 1.0}\n",
      "{'loss': 0.3433, 'grad_norm': 1.0830729007720947, 'learning_rate': 3.8e-05, 'epoch': 1.02}\n",
      "{'loss': 0.3607, 'grad_norm': 3.9435698986053467, 'learning_rate': 3.9000000000000006e-05, 'epoch': 1.05}\n",
      "{'loss': 0.3328, 'grad_norm': 11.5259370803833, 'learning_rate': 4e-05, 'epoch': 1.08}\n",
      "{'loss': 0.3376, 'grad_norm': 0.8684391379356384, 'learning_rate': 4.1e-05, 'epoch': 1.1}\n",
      "{'loss': 0.2855, 'grad_norm': 8.08171272277832, 'learning_rate': 4.2e-05, 'epoch': 1.13}\n",
      "{'loss': 0.1997, 'grad_norm': 4.750377655029297, 'learning_rate': 4.3e-05, 'epoch': 1.16}\n",
      "{'loss': 0.4272, 'grad_norm': 6.871905326843262, 'learning_rate': 4.4000000000000006e-05, 'epoch': 1.18}\n",
      "{'loss': 0.2511, 'grad_norm': 3.860391139984131, 'learning_rate': 4.5e-05, 'epoch': 1.21}\n",
      "{'loss': 0.345, 'grad_norm': 1.4481611251831055, 'learning_rate': 4.600000000000001e-05, 'epoch': 1.24}\n",
      "{'loss': 0.4017, 'grad_norm': 2.5138556957244873, 'learning_rate': 4.7e-05, 'epoch': 1.26}\n",
      "{'loss': 0.4655, 'grad_norm': 49.56171798706055, 'learning_rate': 4.8e-05, 'epoch': 1.29}\n",
      "{'loss': 0.3243, 'grad_norm': 33.479976654052734, 'learning_rate': 4.9e-05, 'epoch': 1.32}\n",
      "{'loss': 0.3702, 'grad_norm': 2.318615674972534, 'learning_rate': 5e-05, 'epoch': 1.34}\n",
      "{'loss': 0.4529, 'grad_norm': 5.421811580657959, 'learning_rate': 4.971131639722864e-05, 'epoch': 1.37}\n",
      "{'loss': 0.2719, 'grad_norm': 26.047515869140625, 'learning_rate': 4.942263279445728e-05, 'epoch': 1.4}\n",
      "{'loss': 0.3081, 'grad_norm': 1.4730814695358276, 'learning_rate': 4.9133949191685915e-05, 'epoch': 1.42}\n",
      "{'loss': 0.3467, 'grad_norm': 8.180501937866211, 'learning_rate': 4.884526558891455e-05, 'epoch': 1.45}\n",
      "{'loss': 0.4548, 'grad_norm': 3.9853546619415283, 'learning_rate': 4.855658198614319e-05, 'epoch': 1.48}\n",
      "{'loss': 0.3969, 'grad_norm': 5.313158988952637, 'learning_rate': 4.826789838337183e-05, 'epoch': 1.51}\n",
      "{'loss': 0.3559, 'grad_norm': 4.479809761047363, 'learning_rate': 4.797921478060046e-05, 'epoch': 1.53}\n",
      "{'loss': 0.2267, 'grad_norm': 24.266260147094727, 'learning_rate': 4.7690531177829104e-05, 'epoch': 1.56}\n",
      "{'loss': 0.526, 'grad_norm': 17.174026489257812, 'learning_rate': 4.740184757505774e-05, 'epoch': 1.59}\n",
      "{'loss': 0.5302, 'grad_norm': 0.49853211641311646, 'learning_rate': 4.711316397228638e-05, 'epoch': 1.61}\n",
      "{'loss': 0.3517, 'grad_norm': 2.8783822059631348, 'learning_rate': 4.682448036951501e-05, 'epoch': 1.64}\n",
      "{'loss': 0.3045, 'grad_norm': 2.8779428005218506, 'learning_rate': 4.653579676674365e-05, 'epoch': 1.67}\n",
      "{'loss': 0.1872, 'grad_norm': 0.4367218315601349, 'learning_rate': 4.6247113163972286e-05, 'epoch': 1.69}\n",
      "{'loss': 0.364, 'grad_norm': 0.5860313177108765, 'learning_rate': 4.595842956120093e-05, 'epoch': 1.72}\n",
      "{'loss': 0.2708, 'grad_norm': 0.5473061800003052, 'learning_rate': 4.566974595842957e-05, 'epoch': 1.75}\n",
      "{'loss': 0.3705, 'grad_norm': 15.766804695129395, 'learning_rate': 4.53810623556582e-05, 'epoch': 1.77}\n",
      "{'loss': 0.1826, 'grad_norm': 3.9990642070770264, 'learning_rate': 4.5092378752886836e-05, 'epoch': 1.8}\n",
      "{'loss': 0.3128, 'grad_norm': 9.062145233154297, 'learning_rate': 4.4803695150115474e-05, 'epoch': 1.83}\n",
      "{'loss': 0.4038, 'grad_norm': 0.457433819770813, 'learning_rate': 4.451501154734412e-05, 'epoch': 1.85}\n",
      "{'loss': 0.2699, 'grad_norm': 26.063798904418945, 'learning_rate': 4.422632794457275e-05, 'epoch': 1.88}\n",
      "{'loss': 0.2404, 'grad_norm': 23.17481231689453, 'learning_rate': 4.393764434180139e-05, 'epoch': 1.91}\n",
      "{'loss': 0.5188, 'grad_norm': 22.9111385345459, 'learning_rate': 4.3648960739030025e-05, 'epoch': 1.94}\n",
      "{'loss': 0.3211, 'grad_norm': 29.988691329956055, 'learning_rate': 4.336027713625866e-05, 'epoch': 1.96}\n",
      "{'loss': 0.6486, 'grad_norm': 15.392111778259277, 'learning_rate': 4.30715935334873e-05, 'epoch': 1.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "665a747f67754c7db888946560259e28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.32425233721733093, 'eval_accuracy': 0.8722222222222222, 'eval_runtime': 2.7152, 'eval_samples_per_second': 729.235, 'eval_steps_per_second': 11.417, 'epoch': 2.0}\n",
      "{'loss': 0.2402, 'grad_norm': 4.452128887176514, 'learning_rate': 4.278290993071594e-05, 'epoch': 2.02}\n",
      "{'loss': 0.2184, 'grad_norm': 4.215424537658691, 'learning_rate': 4.2494226327944576e-05, 'epoch': 2.04}\n",
      "{'loss': 0.2888, 'grad_norm': 4.09763240814209, 'learning_rate': 4.220554272517321e-05, 'epoch': 2.07}\n",
      "{'loss': 0.2398, 'grad_norm': 0.4521341025829315, 'learning_rate': 4.1916859122401844e-05, 'epoch': 2.1}\n",
      "{'loss': 0.2301, 'grad_norm': 27.6639404296875, 'learning_rate': 4.162817551963049e-05, 'epoch': 2.12}\n",
      "{'loss': 0.3118, 'grad_norm': 10.15308666229248, 'learning_rate': 4.1339491916859126e-05, 'epoch': 2.15}\n",
      "{'loss': 0.3549, 'grad_norm': 12.467772483825684, 'learning_rate': 4.1050808314087764e-05, 'epoch': 2.18}\n",
      "{'loss': 0.3962, 'grad_norm': 1.602459192276001, 'learning_rate': 4.07621247113164e-05, 'epoch': 2.2}\n",
      "{'loss': 0.1722, 'grad_norm': 29.762208938598633, 'learning_rate': 4.047344110854503e-05, 'epoch': 2.23}\n",
      "{'loss': 0.2808, 'grad_norm': 4.936279773712158, 'learning_rate': 4.018475750577367e-05, 'epoch': 2.26}\n",
      "{'loss': 0.1445, 'grad_norm': 4.774464130401611, 'learning_rate': 3.9896073903002315e-05, 'epoch': 2.28}\n",
      "{'loss': 0.208, 'grad_norm': 15.411846160888672, 'learning_rate': 3.960739030023095e-05, 'epoch': 2.31}\n",
      "{'loss': 0.6026, 'grad_norm': 0.28221771121025085, 'learning_rate': 3.931870669745958e-05, 'epoch': 2.34}\n",
      "{'loss': 0.2483, 'grad_norm': 1.7202292680740356, 'learning_rate': 3.903002309468822e-05, 'epoch': 2.37}\n",
      "{'loss': 0.2131, 'grad_norm': 3.5081961154937744, 'learning_rate': 3.874133949191686e-05, 'epoch': 2.39}\n",
      "{'loss': 0.1585, 'grad_norm': 2.6708645820617676, 'learning_rate': 3.84526558891455e-05, 'epoch': 2.42}\n",
      "{'loss': 0.1508, 'grad_norm': 11.448250770568848, 'learning_rate': 3.8163972286374134e-05, 'epoch': 2.45}\n",
      "{'loss': 0.5566, 'grad_norm': 0.25100621581077576, 'learning_rate': 3.787528868360277e-05, 'epoch': 2.47}\n",
      "{'loss': 0.1739, 'grad_norm': 0.5319437980651855, 'learning_rate': 3.758660508083141e-05, 'epoch': 2.5}\n",
      "{'loss': 0.177, 'grad_norm': 3.660736560821533, 'learning_rate': 3.729792147806005e-05, 'epoch': 2.53}\n",
      "{'loss': 0.4383, 'grad_norm': 14.668680191040039, 'learning_rate': 3.7009237875288685e-05, 'epoch': 2.55}\n",
      "{'loss': 0.3672, 'grad_norm': 0.2529573440551758, 'learning_rate': 3.672055427251732e-05, 'epoch': 2.58}\n",
      "{'loss': 0.2626, 'grad_norm': 2.7089436054229736, 'learning_rate': 3.643187066974596e-05, 'epoch': 2.61}\n",
      "{'loss': 0.2217, 'grad_norm': 0.8763887882232666, 'learning_rate': 3.61431870669746e-05, 'epoch': 2.63}\n",
      "{'loss': 0.4283, 'grad_norm': 17.307401657104492, 'learning_rate': 3.5854503464203236e-05, 'epoch': 2.66}\n",
      "{'loss': 0.3534, 'grad_norm': 1.3885871171951294, 'learning_rate': 3.556581986143187e-05, 'epoch': 2.69}\n",
      "{'loss': 0.0491, 'grad_norm': 0.15253835916519165, 'learning_rate': 3.527713625866051e-05, 'epoch': 2.72}\n",
      "{'loss': 0.1088, 'grad_norm': 13.03456974029541, 'learning_rate': 3.498845265588915e-05, 'epoch': 2.74}\n",
      "{'loss': 0.4312, 'grad_norm': 19.552175521850586, 'learning_rate': 3.4699769053117786e-05, 'epoch': 2.77}\n",
      "{'loss': 0.1373, 'grad_norm': 20.771242141723633, 'learning_rate': 3.441108545034642e-05, 'epoch': 2.8}\n",
      "{'loss': 0.2547, 'grad_norm': 3.8617539405822754, 'learning_rate': 3.412240184757506e-05, 'epoch': 2.82}\n",
      "{'loss': 0.2774, 'grad_norm': 0.14846664667129517, 'learning_rate': 3.38337182448037e-05, 'epoch': 2.85}\n",
      "{'loss': 0.3618, 'grad_norm': 0.17905746400356293, 'learning_rate': 3.354503464203234e-05, 'epoch': 2.88}\n",
      "{'loss': 0.1489, 'grad_norm': 0.31706181168556213, 'learning_rate': 3.325635103926097e-05, 'epoch': 2.9}\n",
      "{'loss': 0.2998, 'grad_norm': 0.28877803683280945, 'learning_rate': 3.2967667436489606e-05, 'epoch': 2.93}\n",
      "{'loss': 0.2866, 'grad_norm': 58.700218200683594, 'learning_rate': 3.2678983833718243e-05, 'epoch': 2.96}\n",
      "{'loss': 0.0976, 'grad_norm': 0.18247854709625244, 'learning_rate': 3.239030023094689e-05, 'epoch': 2.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e2e346d29ee4e779b3ce9a9a2e5a2c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.40840810537338257, 'eval_accuracy': 0.8828282828282829, 'eval_runtime': 2.6429, 'eval_samples_per_second': 749.182, 'eval_steps_per_second': 11.73, 'epoch': 3.0}\n",
      "{'loss': 0.0942, 'grad_norm': 21.021940231323242, 'learning_rate': 3.2101616628175526e-05, 'epoch': 3.01}\n",
      "{'loss': 0.0979, 'grad_norm': 0.1331941783428192, 'learning_rate': 3.1812933025404156e-05, 'epoch': 3.04}\n",
      "{'loss': 0.1892, 'grad_norm': 1.484173059463501, 'learning_rate': 3.1524249422632794e-05, 'epoch': 3.06}\n",
      "{'loss': 0.1956, 'grad_norm': 1.8538806438446045, 'learning_rate': 3.123556581986143e-05, 'epoch': 3.09}\n",
      "{'loss': 0.1181, 'grad_norm': 52.90111541748047, 'learning_rate': 3.0946882217090076e-05, 'epoch': 3.12}\n",
      "{'loss': 0.1002, 'grad_norm': 21.60057258605957, 'learning_rate': 3.065819861431871e-05, 'epoch': 3.15}\n",
      "{'loss': 0.2809, 'grad_norm': 3.5137298107147217, 'learning_rate': 3.0369515011547345e-05, 'epoch': 3.17}\n",
      "{'loss': 0.3528, 'grad_norm': 0.14449787139892578, 'learning_rate': 3.0080831408775983e-05, 'epoch': 3.2}\n",
      "{'loss': 0.1158, 'grad_norm': 0.1682118922472, 'learning_rate': 2.9792147806004624e-05, 'epoch': 3.23}\n",
      "{'loss': 0.1744, 'grad_norm': 19.93886375427246, 'learning_rate': 2.9503464203233255e-05, 'epoch': 3.25}\n",
      "{'loss': 0.2126, 'grad_norm': 0.36660513281822205, 'learning_rate': 2.9214780600461896e-05, 'epoch': 3.28}\n",
      "{'loss': 0.076, 'grad_norm': 0.17171548306941986, 'learning_rate': 2.8926096997690533e-05, 'epoch': 3.31}\n",
      "{'loss': 0.139, 'grad_norm': 1.0644835233688354, 'learning_rate': 2.863741339491917e-05, 'epoch': 3.33}\n",
      "{'loss': 0.1036, 'grad_norm': 0.07545029371976852, 'learning_rate': 2.834872979214781e-05, 'epoch': 3.36}\n",
      "{'loss': 0.1564, 'grad_norm': 12.133374214172363, 'learning_rate': 2.8060046189376443e-05, 'epoch': 3.39}\n",
      "{'loss': 0.1076, 'grad_norm': 0.08529003709554672, 'learning_rate': 2.777136258660508e-05, 'epoch': 3.41}\n",
      "{'loss': 0.0233, 'grad_norm': 0.7045477032661438, 'learning_rate': 2.7482678983833722e-05, 'epoch': 3.44}\n",
      "{'loss': 0.2453, 'grad_norm': 0.11090021580457687, 'learning_rate': 2.719399538106236e-05, 'epoch': 3.47}\n",
      "{'loss': 0.2044, 'grad_norm': 0.16324694454669952, 'learning_rate': 2.6905311778290994e-05, 'epoch': 3.49}\n",
      "{'loss': 0.2865, 'grad_norm': 0.10070820152759552, 'learning_rate': 2.661662817551963e-05, 'epoch': 3.52}\n",
      "{'loss': 0.1517, 'grad_norm': 2.0402538776397705, 'learning_rate': 2.632794457274827e-05, 'epoch': 3.55}\n",
      "{'loss': 0.1432, 'grad_norm': 2.149744749069214, 'learning_rate': 2.6039260969976907e-05, 'epoch': 3.58}\n",
      "{'loss': 0.0647, 'grad_norm': 0.08411040157079697, 'learning_rate': 2.575057736720554e-05, 'epoch': 3.6}\n",
      "{'loss': 0.1927, 'grad_norm': 0.06680656224489212, 'learning_rate': 2.546189376443418e-05, 'epoch': 3.63}\n",
      "{'loss': 0.0984, 'grad_norm': 31.72606658935547, 'learning_rate': 2.517321016166282e-05, 'epoch': 3.66}\n",
      "{'loss': 0.2383, 'grad_norm': 0.0713079571723938, 'learning_rate': 2.4884526558891454e-05, 'epoch': 3.68}\n",
      "{'loss': 0.2223, 'grad_norm': 6.613436222076416, 'learning_rate': 2.4595842956120095e-05, 'epoch': 3.71}\n",
      "{'loss': 0.1013, 'grad_norm': 0.7828752994537354, 'learning_rate': 2.430715935334873e-05, 'epoch': 3.74}\n",
      "{'loss': 0.3144, 'grad_norm': 0.09123249351978302, 'learning_rate': 2.4018475750577367e-05, 'epoch': 3.76}\n",
      "{'loss': 0.3477, 'grad_norm': 6.061562538146973, 'learning_rate': 2.372979214780601e-05, 'epoch': 3.79}\n",
      "{'loss': 0.1275, 'grad_norm': 0.20437569916248322, 'learning_rate': 2.3441108545034643e-05, 'epoch': 3.82}\n",
      "{'loss': 0.0099, 'grad_norm': 0.07214341312646866, 'learning_rate': 2.315242494226328e-05, 'epoch': 3.84}\n",
      "{'loss': 0.0693, 'grad_norm': 0.08215570449829102, 'learning_rate': 2.2863741339491918e-05, 'epoch': 3.87}\n",
      "{'loss': 0.2583, 'grad_norm': 59.302337646484375, 'learning_rate': 2.2575057736720556e-05, 'epoch': 3.9}\n",
      "{'loss': 0.2976, 'grad_norm': 34.52314758300781, 'learning_rate': 2.2286374133949193e-05, 'epoch': 3.92}\n",
      "{'loss': 0.0256, 'grad_norm': 0.09029816836118698, 'learning_rate': 2.199769053117783e-05, 'epoch': 3.95}\n",
      "{'loss': 0.1734, 'grad_norm': 15.739653587341309, 'learning_rate': 2.1709006928406465e-05, 'epoch': 3.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c3d37d7c7ce42378df4e797b8d42a55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.467580646276474, 'eval_accuracy': 0.8878787878787879, 'eval_runtime': 2.6192, 'eval_samples_per_second': 755.943, 'eval_steps_per_second': 11.835, 'epoch': 4.0}\n",
      "{'loss': 0.0351, 'grad_norm': 0.07322902232408524, 'learning_rate': 2.1420323325635107e-05, 'epoch': 4.01}\n",
      "{'loss': 0.03, 'grad_norm': 36.649295806884766, 'learning_rate': 2.113163972286374e-05, 'epoch': 4.03}\n",
      "{'loss': 0.0053, 'grad_norm': 0.07328525185585022, 'learning_rate': 2.084295612009238e-05, 'epoch': 4.06}\n",
      "{'loss': 0.0658, 'grad_norm': 0.25959160923957825, 'learning_rate': 2.0554272517321016e-05, 'epoch': 4.09}\n",
      "{'loss': 0.1338, 'grad_norm': 6.289260387420654, 'learning_rate': 2.0265588914549654e-05, 'epoch': 4.11}\n",
      "{'loss': 0.1074, 'grad_norm': 49.256370544433594, 'learning_rate': 1.997690531177829e-05, 'epoch': 4.14}\n",
      "{'loss': 0.0633, 'grad_norm': 0.07163897156715393, 'learning_rate': 1.968822170900693e-05, 'epoch': 4.17}\n",
      "{'loss': 0.2159, 'grad_norm': 30.809186935424805, 'learning_rate': 1.9399538106235567e-05, 'epoch': 4.19}\n",
      "{'loss': 0.258, 'grad_norm': 3.758679151535034, 'learning_rate': 1.9110854503464205e-05, 'epoch': 4.22}\n",
      "{'loss': 0.1292, 'grad_norm': 0.2323426604270935, 'learning_rate': 1.8822170900692842e-05, 'epoch': 4.25}\n",
      "{'loss': 0.0577, 'grad_norm': 0.13583452999591827, 'learning_rate': 1.853348729792148e-05, 'epoch': 4.27}\n",
      "{'loss': 0.0509, 'grad_norm': 0.17794786393642426, 'learning_rate': 1.8244803695150118e-05, 'epoch': 4.3}\n",
      "{'loss': 0.1105, 'grad_norm': 0.1543125957250595, 'learning_rate': 1.7956120092378752e-05, 'epoch': 4.33}\n",
      "{'loss': 0.0395, 'grad_norm': 0.0616629458963871, 'learning_rate': 1.7667436489607393e-05, 'epoch': 4.35}\n",
      "{'loss': 0.165, 'grad_norm': 0.041476406157016754, 'learning_rate': 1.7378752886836027e-05, 'epoch': 4.38}\n",
      "{'loss': 0.0693, 'grad_norm': 0.04852311313152313, 'learning_rate': 1.7090069284064665e-05, 'epoch': 4.41}\n",
      "{'loss': 0.0656, 'grad_norm': 0.04536686837673187, 'learning_rate': 1.6801385681293303e-05, 'epoch': 4.44}\n",
      "{'loss': 0.1099, 'grad_norm': 0.16858665645122528, 'learning_rate': 1.651270207852194e-05, 'epoch': 4.46}\n",
      "{'loss': 0.077, 'grad_norm': 7.755302429199219, 'learning_rate': 1.6224018475750578e-05, 'epoch': 4.49}\n",
      "{'loss': 0.0141, 'grad_norm': 0.4682474434375763, 'learning_rate': 1.5935334872979216e-05, 'epoch': 4.52}\n",
      "{'loss': 0.0511, 'grad_norm': 0.029159056022763252, 'learning_rate': 1.564665127020785e-05, 'epoch': 4.54}\n",
      "{'loss': 0.1025, 'grad_norm': 1.067376971244812, 'learning_rate': 1.535796766743649e-05, 'epoch': 4.57}\n",
      "{'loss': 0.0875, 'grad_norm': 0.03265964239835739, 'learning_rate': 1.5069284064665129e-05, 'epoch': 4.6}\n",
      "{'loss': 0.1384, 'grad_norm': 0.03567827120423317, 'learning_rate': 1.4780600461893765e-05, 'epoch': 4.62}\n",
      "{'loss': 0.0831, 'grad_norm': 0.05823789909482002, 'learning_rate': 1.4491916859122404e-05, 'epoch': 4.65}\n",
      "{'loss': 0.1767, 'grad_norm': 0.05769208446145058, 'learning_rate': 1.420323325635104e-05, 'epoch': 4.68}\n",
      "{'loss': 0.2001, 'grad_norm': 0.03514900058507919, 'learning_rate': 1.3914549653579678e-05, 'epoch': 4.7}\n",
      "{'loss': 0.085, 'grad_norm': 0.12683236598968506, 'learning_rate': 1.3625866050808314e-05, 'epoch': 4.73}\n",
      "{'loss': 0.0064, 'grad_norm': 0.50525963306427, 'learning_rate': 1.3337182448036953e-05, 'epoch': 4.76}\n",
      "{'loss': 0.0608, 'grad_norm': 0.10121865570545197, 'learning_rate': 1.304849884526559e-05, 'epoch': 4.78}\n",
      "{'loss': 0.066, 'grad_norm': 8.012331008911133, 'learning_rate': 1.2759815242494227e-05, 'epoch': 4.81}\n",
      "{'loss': 0.0627, 'grad_norm': 0.044404301792383194, 'learning_rate': 1.2471131639722865e-05, 'epoch': 4.84}\n",
      "{'loss': 0.0844, 'grad_norm': 0.03332182765007019, 'learning_rate': 1.2182448036951502e-05, 'epoch': 4.87}\n",
      "{'loss': 0.0492, 'grad_norm': 0.08151649683713913, 'learning_rate': 1.189376443418014e-05, 'epoch': 4.89}\n",
      "{'loss': 0.1099, 'grad_norm': 0.14439143240451813, 'learning_rate': 1.1605080831408776e-05, 'epoch': 4.92}\n",
      "{'loss': 0.0793, 'grad_norm': 8.927081108093262, 'learning_rate': 1.1316397228637414e-05, 'epoch': 4.95}\n",
      "{'loss': 0.0541, 'grad_norm': 0.07407240569591522, 'learning_rate': 1.1027713625866051e-05, 'epoch': 4.97}\n",
      "{'loss': 0.0095, 'grad_norm': 0.4219866394996643, 'learning_rate': 1.0739030023094689e-05, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fede67bf26b041f5b8d3c3e2fd9cf08b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5196784138679504, 'eval_accuracy': 0.8934343434343435, 'eval_runtime': 2.7869, 'eval_samples_per_second': 710.477, 'eval_steps_per_second': 11.124, 'epoch': 5.0}\n",
      "{'loss': 0.0468, 'grad_norm': 0.057662397623062134, 'learning_rate': 1.0450346420323325e-05, 'epoch': 5.03}\n",
      "{'loss': 0.0428, 'grad_norm': 0.031790196895599365, 'learning_rate': 1.0161662817551963e-05, 'epoch': 5.05}\n",
      "{'loss': 0.1127, 'grad_norm': 14.367451667785645, 'learning_rate': 9.8729792147806e-06, 'epoch': 5.08}\n",
      "{'loss': 0.1412, 'grad_norm': 13.23043441772461, 'learning_rate': 9.584295612009238e-06, 'epoch': 5.11}\n",
      "{'loss': 0.0994, 'grad_norm': 0.033957589417696, 'learning_rate': 9.295612009237876e-06, 'epoch': 5.13}\n",
      "{'loss': 0.0293, 'grad_norm': 0.027305850759148598, 'learning_rate': 9.006928406466514e-06, 'epoch': 5.16}\n",
      "{'loss': 0.0021, 'grad_norm': 0.02560787834227085, 'learning_rate': 8.718244803695151e-06, 'epoch': 5.19}\n",
      "{'loss': 0.0852, 'grad_norm': 0.036879103630781174, 'learning_rate': 8.429561200923789e-06, 'epoch': 5.22}\n",
      "{'loss': 0.0026, 'grad_norm': 0.04167528077960014, 'learning_rate': 8.140877598152425e-06, 'epoch': 5.24}\n",
      "{'loss': 0.1355, 'grad_norm': 0.03853757306933403, 'learning_rate': 7.852193995381063e-06, 'epoch': 5.27}\n",
      "{'loss': 0.0025, 'grad_norm': 0.039251185953617096, 'learning_rate': 7.5635103926097e-06, 'epoch': 5.3}\n",
      "{'loss': 0.1212, 'grad_norm': 3.137803077697754, 'learning_rate': 7.274826789838338e-06, 'epoch': 5.32}\n",
      "{'loss': 0.003, 'grad_norm': 0.03566431999206543, 'learning_rate': 6.986143187066975e-06, 'epoch': 5.35}\n",
      "{'loss': 0.002, 'grad_norm': 0.8707502484321594, 'learning_rate': 6.6974595842956126e-06, 'epoch': 5.38}\n",
      "{'loss': 0.0164, 'grad_norm': 0.032231878489255905, 'learning_rate': 6.408775981524249e-06, 'epoch': 5.4}\n",
      "{'loss': 0.0875, 'grad_norm': 0.03654089942574501, 'learning_rate': 6.120092378752887e-06, 'epoch': 5.43}\n",
      "{'loss': 0.0812, 'grad_norm': 0.027446802705526352, 'learning_rate': 5.831408775981524e-06, 'epoch': 5.46}\n",
      "{'loss': 0.0148, 'grad_norm': 0.02739465981721878, 'learning_rate': 5.5427251732101625e-06, 'epoch': 5.48}\n",
      "{'loss': 0.0034, 'grad_norm': 1.1110895872116089, 'learning_rate': 5.254041570438799e-06, 'epoch': 5.51}\n",
      "{'loss': 0.0541, 'grad_norm': 0.027026072144508362, 'learning_rate': 4.965357967667437e-06, 'epoch': 5.54}\n",
      "{'loss': 0.0081, 'grad_norm': 0.02893655188381672, 'learning_rate': 4.676674364896074e-06, 'epoch': 5.56}\n",
      "{'loss': 0.1238, 'grad_norm': 19.64409828186035, 'learning_rate': 4.3879907621247115e-06, 'epoch': 5.59}\n",
      "{'loss': 0.1068, 'grad_norm': 0.03039339743554592, 'learning_rate': 4.099307159353348e-06, 'epoch': 5.62}\n",
      "{'loss': 0.0067, 'grad_norm': 0.04012851417064667, 'learning_rate': 3.810623556581986e-06, 'epoch': 5.65}\n",
      "{'loss': 0.0855, 'grad_norm': 0.0844329372048378, 'learning_rate': 3.521939953810624e-06, 'epoch': 5.67}\n",
      "{'loss': 0.0038, 'grad_norm': 0.07330571860074997, 'learning_rate': 3.2332563510392614e-06, 'epoch': 5.7}\n",
      "{'loss': 0.0807, 'grad_norm': 0.036727339029312134, 'learning_rate': 2.9445727482678987e-06, 'epoch': 5.73}\n",
      "{'loss': 0.079, 'grad_norm': 0.04575709253549576, 'learning_rate': 2.655889145496536e-06, 'epoch': 5.75}\n",
      "{'loss': 0.1134, 'grad_norm': 3.732750177383423, 'learning_rate': 2.3672055427251732e-06, 'epoch': 5.78}\n",
      "{'loss': 0.0114, 'grad_norm': 0.03351660445332527, 'learning_rate': 2.0785219399538105e-06, 'epoch': 5.81}\n",
      "{'loss': 0.0024, 'grad_norm': 0.02357456088066101, 'learning_rate': 1.7898383371824482e-06, 'epoch': 5.83}\n",
      "{'loss': 0.0024, 'grad_norm': 0.028606338426470757, 'learning_rate': 1.5011547344110855e-06, 'epoch': 5.86}\n",
      "{'loss': 0.0019, 'grad_norm': 0.0402899794280529, 'learning_rate': 1.212471131639723e-06, 'epoch': 5.89}\n",
      "{'loss': 0.0028, 'grad_norm': 0.03928496688604355, 'learning_rate': 9.237875288683603e-07, 'epoch': 5.91}\n",
      "{'loss': 0.0029, 'grad_norm': 0.042188603430986404, 'learning_rate': 6.351039260969977e-07, 'epoch': 5.94}\n",
      "{'loss': 0.0017, 'grad_norm': 0.028437139466404915, 'learning_rate': 3.4642032332563515e-07, 'epoch': 5.97}\n",
      "{'loss': 0.0016, 'grad_norm': 0.02792827971279621, 'learning_rate': 5.773672055427252e-08, 'epoch': 5.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f264b2dac0a444a9b9b9423b837d2afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5322539210319519, 'eval_accuracy': 0.896969696969697, 'eval_runtime': 2.743, 'eval_samples_per_second': 721.847, 'eval_steps_per_second': 11.302, 'epoch': 6.0}\n",
      "{'train_runtime': 221.4487, 'train_samples_per_second': 80.47, 'train_steps_per_second': 10.079, 'train_loss': 0.2328433177580366, 'epoch': 6.0}\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "MyCascade = FrugalGPT.LLMCascade()\n",
    "service_names = ['ai21/j1-large'] \n",
    "# 'openaichat/gpt-4-turbo', 'openaichat/gpt-4o', 'openaichat/gpt-4o-mini'\n",
    "# 'ai21/j1-large','textsynth/gptj_6B'\n",
    "\n",
    "result = MyCascade.train(train_data,budget=100,service_names=service_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to disk\n",
    "MyCascade.save(savepath=\"strategy/EXPERIMENT/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyCascade = FrugalGPT.LLMCascade()\n",
    "MyCascade.load(loadpath=\"strategy/EXPERIMENT/\",budget=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test data size:\",len(test_data))\n",
    "MyCascade = FrugalGPT.LLMCascade()\n",
    "MyCascade.load(loadpath=\"strategy/HEADLINES/\",budget=0.000665)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dis-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
